[2025-05-28T07:48:33.893+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:48:33.896+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:48:33.903+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:48:33.902+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:48:39.175+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:48:39.839+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:48:39.838+0000] {override.py:1858} INFO - Created Permission View: can delete on DAG:postgres_to_bigquery
[2025-05-28T07:48:39.886+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:48:39.886+0000] {override.py:1858} INFO - Created Permission View: can read on DAG:postgres_to_bigquery
[2025-05-28T07:48:39.908+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:48:39.908+0000] {override.py:1858} INFO - Created Permission View: can edit on DAG:postgres_to_bigquery
[2025-05-28T07:48:39.910+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:48:39.909+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:48:39.930+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:48:39.929+0000] {dag.py:3111} INFO - Creating ORM DAG for postgres_to_bigquery
[2025-05-28T07:48:39.947+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:48:39.947+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:48:39.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.106 seconds
[2025-05-28T07:49:10.570+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:49:10.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:49:10.588+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:49:10.587+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:49:14.492+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:49:14.699+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:49:14.698+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:49:14.862+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:49:14.861+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:49:15.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.500 seconds
[2025-05-28T07:49:45.872+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:49:45.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:49:45.886+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:49:45.885+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:49:48.443+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:49:48.539+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:49:48.538+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:49:48.621+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:49:48.621+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:49:48.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.811 seconds
[2025-05-28T07:50:18.981+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:50:18.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:50:18.987+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:50:18.986+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:50:21.679+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:50:21.888+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:50:21.886+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:50:21.991+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:50:21.990+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:50:22.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.131 seconds
[2025-05-28T07:50:52.558+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:50:52.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:50:52.583+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:50:52.578+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:50:54.017+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:50:54.080+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:50:54.079+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:50:54.146+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:50:54.146+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:50:54.200+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.681 seconds
[2025-05-28T07:51:24.339+0000] {processor.py:161} INFO - Started process (PID=269) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:51:24.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:51:24.354+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:51:24.353+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:51:25.639+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:51:25.686+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:51:25.685+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:51:25.719+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:51:25.718+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:51:25.757+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.438 seconds
[2025-05-28T07:51:56.224+0000] {processor.py:161} INFO - Started process (PID=287) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:51:56.225+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:51:56.229+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:51:56.228+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:51:57.507+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:51:57.554+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:51:57.553+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:51:57.604+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:51:57.604+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:51:57.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.429 seconds
[2025-05-28T07:52:28.228+0000] {processor.py:161} INFO - Started process (PID=306) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:52:28.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:52:28.232+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:52:28.232+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:52:29.195+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:52:29.233+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:52:29.233+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:52:29.263+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:52:29.263+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:52:29.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.083 seconds
[2025-05-28T07:52:59.568+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:52:59.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:52:59.573+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:52:59.572+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:53:00.605+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:53:00.640+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:53:00.639+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:53:00.668+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:53:00.668+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:53:00.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.151 seconds
[2025-05-28T07:53:31.078+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:53:31.087+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:53:31.093+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:53:31.092+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:53:32.635+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:53:32.679+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:53:32.679+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:53:32.708+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:53:32.707+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:53:32.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.692 seconds
[2025-05-28T07:54:03.474+0000] {processor.py:161} INFO - Started process (PID=361) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:54:03.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:54:03.480+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:54:03.479+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:54:05.043+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:54:05.082+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:54:05.081+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:54:05.121+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:54:05.120+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:54:05.159+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.713 seconds
[2025-05-28T07:54:35.546+0000] {processor.py:161} INFO - Started process (PID=380) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:54:35.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:54:35.552+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:54:35.551+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:54:37.045+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:54:37.094+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:54:37.093+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:54:37.143+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:54:37.143+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:54:37.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.645 seconds
[2025-05-28T07:55:07.677+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:55:07.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:55:07.682+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:55:07.682+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:55:08.932+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:55:08.978+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:55:08.977+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:55:09.016+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:55:09.015+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:55:09.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.386 seconds
[2025-05-28T07:55:39.559+0000] {processor.py:161} INFO - Started process (PID=417) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:55:39.561+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:55:39.565+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:55:39.565+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:55:40.784+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:55:40.817+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:55:40.816+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:55:40.844+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:55:40.843+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:55:40.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.327 seconds
[2025-05-28T07:56:11.300+0000] {processor.py:161} INFO - Started process (PID=435) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:56:11.303+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:56:11.309+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:56:11.308+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:56:12.611+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:56:12.651+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:56:12.650+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:56:12.689+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:56:12.689+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:56:12.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.444 seconds
[2025-05-28T07:56:42.901+0000] {processor.py:161} INFO - Started process (PID=453) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:56:42.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:56:42.908+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:56:42.907+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:56:43.987+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:56:44.024+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:56:44.023+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:56:44.049+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:56:44.049+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:56:44.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.201 seconds
[2025-05-28T07:57:14.563+0000] {processor.py:161} INFO - Started process (PID=471) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:57:14.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:57:14.570+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:57:14.569+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:57:15.815+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:57:15.854+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:57:15.854+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:57:15.884+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:57:15.884+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:57:15.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.383 seconds
[2025-05-28T07:57:46.322+0000] {processor.py:161} INFO - Started process (PID=489) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:57:46.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:57:46.326+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:57:46.326+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:57:47.404+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:57:47.441+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:57:47.441+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:57:47.472+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:57:47.472+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:57:47.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.195 seconds
[2025-05-28T07:58:17.813+0000] {processor.py:161} INFO - Started process (PID=507) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:58:17.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:58:17.819+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:58:17.819+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:58:18.809+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:58:18.846+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:58:18.846+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:58:18.880+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:58:18.880+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:58:18.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.118 seconds
[2025-05-28T07:58:49.291+0000] {processor.py:161} INFO - Started process (PID=525) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:58:49.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:58:49.297+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:58:49.296+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:58:50.490+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:58:50.524+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:58:50.523+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:58:50.559+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:58:50.559+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:58:50.608+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.335 seconds
[2025-05-28T07:59:21.152+0000] {processor.py:161} INFO - Started process (PID=543) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:59:21.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:59:21.158+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:59:21.157+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:59:23.181+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:59:23.250+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:59:23.248+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:59:23.304+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:59:23.304+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:59:23.352+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.211 seconds
[2025-05-28T07:59:54.096+0000] {processor.py:161} INFO - Started process (PID=561) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:59:54.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T07:59:54.102+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:59:54.102+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:59:56.664+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T07:59:56.712+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:59:56.711+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T07:59:56.752+0000] {logging_mixin.py:188} INFO - [2025-05-28T07:59:56.751+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T07:59:56.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.715 seconds
[2025-05-28T08:00:27.445+0000] {processor.py:161} INFO - Started process (PID=585) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:00:27.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:00:27.459+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:00:27.459+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:00:30.178+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:00:30.292+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:00:30.291+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:00:30.368+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:00:30.367+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:00:30.478+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.069 seconds
[2025-05-28T08:01:01.210+0000] {processor.py:161} INFO - Started process (PID=603) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:01:01.212+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:01:01.216+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:01:01.215+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:01:02.796+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:01:02.846+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:01:02.846+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:01:02.949+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:01:02.948+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:01:03.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.877 seconds
[2025-05-28T08:01:33.392+0000] {processor.py:161} INFO - Started process (PID=621) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:01:33.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:01:33.409+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:01:33.408+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:01:34.895+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:01:35.033+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:01:35.032+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:01:35.130+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:01:35.129+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:01:35.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.850 seconds
[2025-05-28T08:02:06.087+0000] {processor.py:161} INFO - Started process (PID=638) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:02:06.093+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:02:06.098+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:02:06.097+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:02:13.240+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:02:13.402+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:02:13.401+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:02:13.577+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:02:13.576+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:02:13.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 7.762 seconds
[2025-05-28T08:02:44.711+0000] {processor.py:161} INFO - Started process (PID=657) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:02:44.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:02:44.727+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:02:44.726+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:02:48.554+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:02:48.645+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:02:48.644+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:02:48.733+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:02:48.732+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:02:48.804+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.127 seconds
[2025-05-28T08:03:19.414+0000] {processor.py:161} INFO - Started process (PID=676) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:03:19.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:03:19.426+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:03:19.425+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:03:21.286+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:03:21.344+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:03:21.343+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:03:21.462+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:03:21.460+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:03:21.558+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.186 seconds
[2025-05-28T08:03:52.136+0000] {processor.py:161} INFO - Started process (PID=694) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:03:52.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:03:52.167+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:03:52.166+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:03:55.523+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:03:55.572+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:03:55.571+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:03:55.615+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:03:55.615+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:03:55.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.610 seconds
[2025-05-28T08:04:26.441+0000] {processor.py:161} INFO - Started process (PID=722) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:04:26.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:04:26.447+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:04:26.446+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:04:28.260+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:04:28.305+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:04:28.305+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:04:28.346+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:04:28.346+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:04:28.397+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.976 seconds
[2025-05-28T08:04:58.893+0000] {processor.py:161} INFO - Started process (PID=740) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:04:58.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:04:58.911+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:04:58.910+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:05:04.650+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:05:04.724+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:05:04.722+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:05:04.770+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:05:04.769+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:05:04.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.969 seconds
[2025-05-28T08:05:35.331+0000] {processor.py:161} INFO - Started process (PID=760) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:05:35.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:05:35.362+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:05:35.360+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:05:37.451+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:05:37.553+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:05:37.551+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:05:37.611+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:05:37.610+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:05:37.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.363 seconds
[2025-05-28T08:06:07.991+0000] {processor.py:161} INFO - Started process (PID=778) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:06:07.993+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:06:08.002+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:06:08.000+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:06:10.117+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:06:10.184+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:06:10.182+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:06:10.285+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:06:10.284+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:06:10.432+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.462 seconds
[2025-05-28T08:06:41.331+0000] {processor.py:161} INFO - Started process (PID=796) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:06:41.347+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:06:41.363+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:06:41.362+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:06:44.900+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:06:44.971+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:06:44.968+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:06:45.073+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:06:45.072+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:06:45.161+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.865 seconds
[2025-05-28T08:07:15.407+0000] {processor.py:161} INFO - Started process (PID=814) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:07:15.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:07:15.417+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:07:15.416+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:07:17.281+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:07:17.332+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:07:17.332+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:07:17.373+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:07:17.372+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:07:17.433+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.081 seconds
[2025-05-28T08:07:48.327+0000] {processor.py:161} INFO - Started process (PID=832) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:07:48.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:07:48.336+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:07:48.335+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:07:50.602+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:07:50.681+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:07:50.680+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:07:50.751+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:07:50.750+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:07:50.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.525 seconds
[2025-05-28T08:08:21.593+0000] {processor.py:161} INFO - Started process (PID=850) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:08:21.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:08:21.596+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:08:21.596+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:08:23.531+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:08:23.569+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:08:23.568+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:08:23.598+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:08:23.598+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:08:23.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.060 seconds
[2025-05-28T08:08:53.811+0000] {processor.py:161} INFO - Started process (PID=868) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:08:53.812+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:08:53.814+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:08:53.814+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:08:54.727+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:08:54.762+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:08:54.761+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:08:54.789+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:08:54.788+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:08:54.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.021 seconds
[2025-05-28T08:09:24.993+0000] {processor.py:161} INFO - Started process (PID=886) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:09:24.995+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:09:24.998+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:09:24.997+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:09:26.186+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:09:26.217+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:09:26.217+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:09:26.242+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:09:26.241+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:09:26.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.290 seconds
[2025-05-28T08:09:56.959+0000] {processor.py:161} INFO - Started process (PID=910) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:09:56.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:09:56.987+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:09:56.987+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:09:58.211+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:09:58.269+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:09:58.268+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:09:58.315+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:09:58.315+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:09:58.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.414 seconds
[2025-05-28T08:10:29.329+0000] {processor.py:161} INFO - Started process (PID=928) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:10:29.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:10:29.335+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:10:29.334+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:10:30.508+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:10:30.549+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:10:30.548+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:10:30.579+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:10:30.579+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:10:30.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.294 seconds
[2025-05-28T08:11:00.708+0000] {processor.py:161} INFO - Started process (PID=946) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:11:00.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:11:00.714+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:11:00.713+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:11:02.967+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:11:03.063+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:11:03.062+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:11:03.150+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:11:03.149+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:11:03.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.569 seconds
[2025-05-28T08:11:33.691+0000] {processor.py:161} INFO - Started process (PID=964) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:11:33.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:11:33.695+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:11:33.694+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:11:35.171+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:11:35.203+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:11:35.202+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:11:35.226+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:11:35.225+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:11:35.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.570 seconds
[2025-05-28T08:12:05.821+0000] {processor.py:161} INFO - Started process (PID=983) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:12:05.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:12:05.829+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:12:05.827+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:12:07.427+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:12:07.510+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:12:07.509+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:12:07.574+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:12:07.574+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:12:07.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.814 seconds
[2025-05-28T08:12:38.176+0000] {processor.py:161} INFO - Started process (PID=1001) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:12:38.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:12:38.221+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:12:38.220+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:12:39.533+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:12:39.561+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:12:39.561+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:12:39.588+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:12:39.588+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:12:39.622+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.473 seconds
[2025-05-28T08:13:10.558+0000] {processor.py:161} INFO - Started process (PID=1019) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:13:10.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:13:10.565+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:13:10.564+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:13:14.016+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:13:14.217+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:13:14.216+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:13:14.351+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:13:14.350+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:13:14.432+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.896 seconds
[2025-05-28T08:13:45.347+0000] {processor.py:161} INFO - Started process (PID=1037) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:13:45.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:13:45.362+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:13:45.362+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:13:46.398+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:13:46.430+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:13:46.430+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:13:46.458+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:13:46.458+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:13:46.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.162 seconds
[2025-05-28T08:14:17.685+0000] {processor.py:161} INFO - Started process (PID=1055) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:14:17.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:14:17.703+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:14:17.702+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:14:20.967+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:14:21.084+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:14:21.077+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:14:21.155+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:14:21.154+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:14:21.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.562 seconds
[2025-05-28T08:22:27.552+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:22:27.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:22:27.630+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:22:27.629+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:22:36.462+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:22:37.039+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:22:37.038+0000] {override.py:1858} INFO - Created Permission View: can edit on DAG:postgres_to_bigquery
[2025-05-28T08:22:37.075+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:22:37.074+0000] {override.py:1858} INFO - Created Permission View: can read on DAG:postgres_to_bigquery
[2025-05-28T08:22:37.106+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:22:37.104+0000] {override.py:1858} INFO - Created Permission View: can delete on DAG:postgres_to_bigquery
[2025-05-28T08:22:37.113+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:22:37.112+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:22:37.148+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:22:37.147+0000] {dag.py:3111} INFO - Creating ORM DAG for postgres_to_bigquery
[2025-05-28T08:22:37.187+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:22:37.187+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:22:37.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 9.733 seconds
[2025-05-28T08:23:07.804+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:23:07.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:23:07.832+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:23:07.831+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:23:09.288+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:23:09.322+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:23:09.322+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:23:09.358+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:23:09.357+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:23:09.395+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.620 seconds
[2025-05-28T08:23:39.691+0000] {processor.py:161} INFO - Started process (PID=222) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:23:39.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:23:39.696+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:23:39.695+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:23:40.865+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:23:40.893+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:23:40.893+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:23:40.938+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:23:40.937+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:23:40.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.293 seconds
[2025-05-28T08:24:11.275+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:24:11.277+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:24:11.279+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:24:11.279+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:24:12.248+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:24:12.289+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:24:12.288+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:24:12.318+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:24:12.318+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:24:12.355+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.088 seconds
[2025-05-28T08:24:42.629+0000] {processor.py:161} INFO - Started process (PID=257) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:24:42.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:24:42.634+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:24:42.633+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:24:43.542+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:24:43.588+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:24:43.587+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:24:43.630+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:24:43.629+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:24:43.670+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.050 seconds
[2025-05-28T08:25:13.948+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:25:13.950+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:25:13.953+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:25:13.952+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:25:14.983+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:25:15.032+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:25:15.031+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:25:15.071+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:25:15.071+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:25:15.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.180 seconds
[2025-05-28T08:25:45.398+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:25:45.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:25:45.402+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:25:45.401+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:25:46.259+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:25:46.286+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:25:46.285+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:25:46.310+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:25:46.310+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:25:46.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.949 seconds
[2025-05-28T08:26:16.642+0000] {processor.py:161} INFO - Started process (PID=316) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:26:16.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:26:16.648+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:26:16.648+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:26:17.837+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:26:17.897+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:26:17.896+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:26:17.940+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:26:17.940+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:26:17.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.361 seconds
[2025-05-28T08:26:48.275+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:26:48.276+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:26:48.279+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:26:48.279+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:26:49.130+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:26:49.160+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:26:49.159+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:26:49.200+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:26:49.199+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:26:49.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.971 seconds
[2025-05-28T08:27:19.328+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:27:19.329+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:27:19.333+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:27:19.332+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:27:20.726+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:27:20.762+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:27:20.762+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:27:20.793+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:27:20.793+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:27:20.824+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.503 seconds
[2025-05-28T08:27:51.103+0000] {processor.py:161} INFO - Started process (PID=369) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:27:51.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:27:51.107+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:27:51.107+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:27:52.028+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:27:52.057+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:27:52.056+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:27:52.083+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:27:52.083+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:27:52.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.022 seconds
[2025-05-28T08:28:22.369+0000] {processor.py:161} INFO - Started process (PID=388) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:28:22.371+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:28:22.374+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:28:22.373+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:28:23.383+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:28:23.416+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:28:23.416+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:28:23.448+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:28:23.447+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:28:23.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.122 seconds
[2025-05-28T08:28:53.747+0000] {processor.py:161} INFO - Started process (PID=406) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:28:53.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:28:53.751+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:28:53.750+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:28:54.531+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:28:54.565+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:28:54.564+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:28:54.591+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:28:54.591+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:28:54.615+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.876 seconds
[2025-05-28T08:29:24.887+0000] {processor.py:161} INFO - Started process (PID=424) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:29:24.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:29:24.892+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:29:24.891+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:29:25.687+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:29:25.717+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:29:25.716+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:29:25.741+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:29:25.741+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:29:25.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.902 seconds
[2025-05-28T08:29:56.241+0000] {processor.py:161} INFO - Started process (PID=442) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:29:56.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:29:56.246+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:29:56.244+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:29:57.046+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:29:57.075+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:29:57.074+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:29:57.101+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:29:57.101+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:29:57.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.894 seconds
[2025-05-28T08:30:27.432+0000] {processor.py:161} INFO - Started process (PID=460) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:30:27.433+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:30:27.437+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:30:27.436+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:30:28.388+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:30:28.420+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:30:28.419+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:30:28.444+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:30:28.443+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:30:28.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.053 seconds
[2025-05-28T08:30:58.748+0000] {processor.py:161} INFO - Started process (PID=478) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:30:58.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:30:58.751+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:30:58.751+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:30:59.556+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:30:59.590+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:30:59.589+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:30:59.633+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:30:59.632+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:30:59.666+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.925 seconds
[2025-05-28T08:31:29.953+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:31:29.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:31:29.957+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:31:29.957+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:31:30.878+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:31:30.907+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:31:30.906+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:31:30.929+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:31:30.929+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:31:30.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.022 seconds
[2025-05-28T08:32:01.253+0000] {processor.py:161} INFO - Started process (PID=515) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:32:01.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:32:01.257+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:32:01.256+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:32:02.379+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:32:02.412+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:32:02.412+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:32:02.443+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:32:02.443+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:32:02.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.233 seconds
[2025-05-28T08:32:32.872+0000] {processor.py:161} INFO - Started process (PID=533) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:32:32.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:32:32.878+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:32:32.877+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:32:33.937+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:32:33.975+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:32:33.975+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:32:34.002+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:32:34.002+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:32:34.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.163 seconds
[2025-05-28T08:33:04.391+0000] {processor.py:161} INFO - Started process (PID=550) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:33:04.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:33:04.398+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:33:04.398+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:33:05.709+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:33:05.744+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:33:05.743+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:33:05.773+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:33:05.772+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:33:05.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.436 seconds
[2025-05-28T08:33:36.208+0000] {processor.py:161} INFO - Started process (PID=568) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:33:36.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:33:36.212+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:33:36.212+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:33:37.405+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:33:37.460+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:33:37.459+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:33:37.523+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:33:37.522+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:33:37.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.423 seconds
[2025-05-28T08:34:08.560+0000] {processor.py:161} INFO - Started process (PID=586) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:34:08.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:34:08.566+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:34:08.566+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:34:10.120+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:34:10.175+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:34:10.174+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:34:10.221+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:34:10.220+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:34:10.267+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.729 seconds
[2025-05-28T08:34:41.054+0000] {processor.py:161} INFO - Started process (PID=604) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:34:41.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:34:41.065+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:34:41.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:34:42.164+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:34:42.195+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:34:42.195+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:34:42.218+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:34:42.218+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:34:42.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.223 seconds
[2025-05-28T08:35:12.376+0000] {processor.py:161} INFO - Started process (PID=621) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:35:12.378+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:35:12.385+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:35:12.384+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:35:13.508+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:35:13.635+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:35:13.634+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T08:35:13.756+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:35:13.756+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T08:35:13.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.500 seconds
[2025-05-28T08:35:44.254+0000] {processor.py:161} INFO - Started process (PID=639) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:35:44.255+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:35:44.259+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:35:44.258+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:35:46.278+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:35:46.268+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:35:46.279+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:35:46.306+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.062 seconds
[2025-05-28T08:36:16.800+0000] {processor.py:161} INFO - Started process (PID=658) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:36:16.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:36:16.805+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:36:16.805+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:36:18.032+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:36:18.011+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:36:18.035+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:36:18.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.292 seconds
[2025-05-28T08:36:48.681+0000] {processor.py:161} INFO - Started process (PID=682) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:36:48.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:36:48.686+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:36:48.685+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:36:50.026+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:36:50.020+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:36:50.028+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:36:50.047+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.385 seconds
[2025-05-28T08:37:20.384+0000] {processor.py:161} INFO - Started process (PID=700) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:37:20.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:37:20.388+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:37:20.387+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:37:21.217+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:37:21.212+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:37:21.218+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:37:21.243+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.867 seconds
[2025-05-28T08:37:51.566+0000] {processor.py:161} INFO - Started process (PID=718) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:37:51.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:37:51.570+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:37:51.569+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:37:52.522+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:37:52.519+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:37:52.523+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:37:52.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.071 seconds
[2025-05-28T08:38:22.915+0000] {processor.py:161} INFO - Started process (PID=736) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:38:22.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:38:22.918+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:38:22.918+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:38:23.871+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:38:23.865+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:38:23.872+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:38:23.901+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.993 seconds
[2025-05-28T08:38:54.169+0000] {processor.py:161} INFO - Started process (PID=754) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:38:54.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:38:54.172+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:38:54.171+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:38:54.977+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:38:54.971+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:38:54.978+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:38:55.003+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.841 seconds
[2025-05-28T08:39:25.278+0000] {processor.py:161} INFO - Started process (PID=772) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:39:25.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:39:25.281+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:39:25.281+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:39:26.059+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:39:26.053+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:39:26.060+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:39:26.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.817 seconds
[2025-05-28T08:39:56.380+0000] {processor.py:161} INFO - Started process (PID=790) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:39:56.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:39:56.383+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:39:56.382+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:39:57.417+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:39:57.411+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:39:57.419+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:39:57.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.075 seconds
[2025-05-28T08:40:27.724+0000] {processor.py:161} INFO - Started process (PID=808) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:40:27.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:40:27.727+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:40:27.727+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:40:28.860+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:40:28.856+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:40:28.861+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:40:28.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.184 seconds
[2025-05-28T08:40:59.145+0000] {processor.py:161} INFO - Started process (PID=827) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:40:59.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:40:59.148+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:40:59.147+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:40:59.914+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:40:59.908+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:40:59.915+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:40:59.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.805 seconds
[2025-05-28T08:41:30.226+0000] {processor.py:161} INFO - Started process (PID=846) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:41:30.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:41:30.231+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:41:30.230+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:41:31.114+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:41:31.109+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:41:31.116+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:41:31.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.924 seconds
[2025-05-28T08:42:01.460+0000] {processor.py:161} INFO - Started process (PID=863) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:42:01.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:42:01.464+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:42:01.463+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:42:02.322+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:42:02.317+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:42:02.323+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:42:02.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.901 seconds
[2025-05-28T08:42:32.524+0000] {processor.py:161} INFO - Started process (PID=881) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:42:32.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:42:32.526+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:42:32.526+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:42:33.305+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:42:33.298+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:42:33.306+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:42:33.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.815 seconds
[2025-05-28T08:43:03.874+0000] {processor.py:161} INFO - Started process (PID=899) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:43:03.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:43:03.876+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:43:03.876+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:43:04.722+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:43:04.718+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:43:04.723+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:43:04.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.883 seconds
[2025-05-28T08:43:35.098+0000] {processor.py:161} INFO - Started process (PID=917) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:43:35.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:43:35.100+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:43:35.100+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:43:35.862+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:43:35.854+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:43:35.868+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:43:35.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.797 seconds
[2025-05-28T08:44:06.691+0000] {processor.py:161} INFO - Started process (PID=935) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:44:06.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:44:06.694+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:44:06.694+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:44:07.896+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:44:07.891+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:44:07.897+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:44:07.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.244 seconds
[2025-05-28T08:44:38.205+0000] {processor.py:161} INFO - Started process (PID=954) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:44:38.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:44:38.210+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:44:38.209+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:44:39.276+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:44:39.271+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:44:39.277+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:44:39.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.120 seconds
[2025-05-28T08:45:09.582+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:45:09.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:45:09.586+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:45:09.586+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:45:10.451+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:45:10.446+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:45:10.452+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:45:10.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.914 seconds
[2025-05-28T08:45:40.774+0000] {processor.py:161} INFO - Started process (PID=990) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:45:40.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:45:40.777+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:45:40.777+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:45:41.646+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:45:41.639+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:45:41.647+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:45:41.683+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.916 seconds
[2025-05-28T08:46:12.109+0000] {processor.py:161} INFO - Started process (PID=1008) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:46:12.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:46:12.111+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:46:12.111+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:46:13.068+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:46:13.062+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:46:13.069+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:46:13.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.003 seconds
[2025-05-28T08:46:43.376+0000] {processor.py:161} INFO - Started process (PID=1026) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:46:43.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:46:43.379+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:46:43.379+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:46:44.193+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:46:44.187+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:46:44.195+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:46:44.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.856 seconds
[2025-05-28T08:47:14.496+0000] {processor.py:161} INFO - Started process (PID=1044) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:47:14.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:47:14.499+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:47:14.498+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:47:15.424+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:47:15.405+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:47:15.426+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:47:15.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.985 seconds
[2025-05-28T08:47:45.822+0000] {processor.py:161} INFO - Started process (PID=1062) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:47:45.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:47:45.826+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:47:45.825+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:47:46.862+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:47:46.857+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:47:46.863+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:47:46.892+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.081 seconds
[2025-05-28T08:48:17.226+0000] {processor.py:161} INFO - Started process (PID=1080) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:48:17.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:48:17.230+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:48:17.230+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:48:18.079+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:48:18.073+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:48:18.080+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:48:18.105+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.896 seconds
[2025-05-28T08:48:48.432+0000] {processor.py:161} INFO - Started process (PID=1098) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:48:48.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:48:48.435+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:48:48.434+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:48:49.488+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:48:49.484+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:48:49.490+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:48:49.513+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.095 seconds
[2025-05-28T08:49:19.832+0000] {processor.py:161} INFO - Started process (PID=1122) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:49:19.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:49:19.834+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:49:19.834+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:49:20.880+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:49:20.873+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:49:20.881+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:49:20.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.089 seconds
[2025-05-28T08:49:51.186+0000] {processor.py:161} INFO - Started process (PID=1140) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:49:51.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:49:51.192+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:49:51.191+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:49:52.434+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:49:52.429+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:49:52.435+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:49:52.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.283 seconds
[2025-05-28T08:50:22.663+0000] {processor.py:161} INFO - Started process (PID=1158) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:50:22.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:50:22.679+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:50:22.678+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:50:23.963+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:50:23.956+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:50:23.965+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:50:24.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.360 seconds
[2025-05-28T08:50:54.278+0000] {processor.py:161} INFO - Started process (PID=1177) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:50:54.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:50:54.281+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:50:54.281+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:50:55.152+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:50:55.146+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:50:55.154+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:50:55.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.909 seconds
[2025-05-28T08:51:25.533+0000] {processor.py:161} INFO - Started process (PID=1195) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:51:25.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:51:25.536+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:51:25.536+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:51:26.375+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:51:26.368+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:51:26.376+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:51:26.395+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.869 seconds
[2025-05-28T08:51:56.708+0000] {processor.py:161} INFO - Started process (PID=1213) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:51:56.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:51:56.711+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:51:56.710+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:51:57.577+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:51:57.571+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:51:57.578+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:51:57.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.898 seconds
[2025-05-28T08:52:27.863+0000] {processor.py:161} INFO - Started process (PID=1231) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:52:27.864+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:52:27.866+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:52:27.866+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:52:28.808+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:52:28.785+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:52:28.810+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:52:28.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.020 seconds
[2025-05-28T08:52:59.840+0000] {processor.py:161} INFO - Started process (PID=1249) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:52:59.844+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:52:59.859+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:52:59.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:53:01.528+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:53:01.522+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:53:01.530+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:53:01.558+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.734 seconds
[2025-05-28T08:53:31.712+0000] {processor.py:161} INFO - Started process (PID=1267) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:53:31.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:53:31.716+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:53:31.716+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:53:33.897+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:53:33.887+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:53:33.899+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:53:33.947+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.263 seconds
[2025-05-28T08:54:04.400+0000] {processor.py:161} INFO - Started process (PID=1285) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:54:04.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:54:04.406+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:54:04.406+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:54:06.041+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:54:06.035+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:54:06.042+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:54:06.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.709 seconds
[2025-05-28T08:54:36.286+0000] {processor.py:161} INFO - Started process (PID=1303) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:54:36.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:54:36.288+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:54:36.288+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:54:37.835+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:54:37.829+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:54:37.836+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:54:37.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.585 seconds
[2025-05-28T08:55:08.211+0000] {processor.py:161} INFO - Started process (PID=1321) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:55:08.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:55:08.215+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:55:08.214+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:55:09.736+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:55:09.729+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:55:09.738+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:55:09.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.585 seconds
[2025-05-28T08:55:40.137+0000] {processor.py:161} INFO - Started process (PID=1339) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:55:40.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:55:40.140+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:55:40.140+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:55:41.158+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:55:41.151+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:55:41.159+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:55:41.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.056 seconds
[2025-05-28T08:56:11.336+0000] {processor.py:161} INFO - Started process (PID=1357) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:56:11.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:56:11.341+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:56:11.340+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:56:12.512+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:56:12.507+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:56:12.513+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:56:12.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.225 seconds
[2025-05-28T08:56:42.903+0000] {processor.py:161} INFO - Started process (PID=1375) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:56:42.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:56:42.905+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:56:42.905+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:56:43.861+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:56:43.850+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:56:43.863+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:56:43.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.019 seconds
[2025-05-28T08:57:14.246+0000] {processor.py:161} INFO - Started process (PID=1394) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:57:14.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:57:14.250+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:57:14.249+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:57:15.346+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:57:15.339+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:57:15.348+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:57:15.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.165 seconds
[2025-05-28T08:57:45.578+0000] {processor.py:161} INFO - Started process (PID=1412) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:57:45.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:57:45.580+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:57:45.580+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:57:46.513+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:57:46.507+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:57:46.514+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:57:46.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.970 seconds
[2025-05-28T08:58:17.004+0000] {processor.py:161} INFO - Started process (PID=1430) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:58:17.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:58:17.021+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:58:17.021+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:58:18.760+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:58:18.748+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:58:18.762+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:58:18.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.887 seconds
[2025-05-28T08:58:48.965+0000] {processor.py:161} INFO - Started process (PID=1448) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:58:48.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:58:48.969+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:58:48.968+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:58:50.260+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:58:50.251+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:58:50.262+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:58:50.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.364 seconds
[2025-05-28T08:59:20.675+0000] {processor.py:161} INFO - Started process (PID=1466) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:59:20.676+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:59:20.677+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:59:20.677+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:59:22.076+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:59:22.067+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:59:22.079+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:59:22.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.456 seconds
[2025-05-28T08:59:52.441+0000] {processor.py:161} INFO - Started process (PID=1489) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:59:52.442+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T08:59:52.444+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:59:52.443+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:59:53.601+0000] {logging_mixin.py:188} INFO - [2025-05-28T08:59:53.590+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T08:59:53.604+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T08:59:53.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.215 seconds
[2025-05-28T09:00:23.820+0000] {processor.py:161} INFO - Started process (PID=1508) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:00:23.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:00:23.824+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:00:23.823+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:00:24.998+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:00:24.992+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:00:24.999+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:00:25.031+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.222 seconds
[2025-05-28T09:00:55.149+0000] {processor.py:161} INFO - Started process (PID=1526) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:00:55.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:00:55.153+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:00:55.152+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:00:56.542+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:00:56.535+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:00:56.543+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:00:56.564+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.425 seconds
[2025-05-28T09:01:26.864+0000] {processor.py:161} INFO - Started process (PID=1544) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:01:26.865+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:01:26.874+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:01:26.866+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:01:28.278+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:01:28.272+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:01:28.279+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:01:28.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.451 seconds
[2025-05-28T09:01:58.583+0000] {processor.py:161} INFO - Started process (PID=1567) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:01:58.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:01:58.586+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:01:58.585+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:01:59.524+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:01:59.519+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:01:59.525+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:01:59.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.975 seconds
[2025-05-28T09:02:29.907+0000] {processor.py:161} INFO - Started process (PID=1586) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:02:29.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:02:29.913+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:02:29.912+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:02:30.956+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:02:30.951+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:02:30.957+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:02:30.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.086 seconds
[2025-05-28T09:03:01.195+0000] {processor.py:161} INFO - Started process (PID=1600) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:03:01.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:03:01.202+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:03:01.201+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:03:02.534+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:03:02.528+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:03:02.536+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:03:02.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.405 seconds
[2025-05-28T09:03:32.994+0000] {processor.py:161} INFO - Started process (PID=1623) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:03:32.995+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:03:32.997+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:03:32.996+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:03:33.940+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:03:33.932+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:03:33.942+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:03:33.967+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.983 seconds
[2025-05-28T09:04:04.296+0000] {processor.py:161} INFO - Started process (PID=1637) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:04:04.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:04:04.303+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:04:04.302+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:04:05.854+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:04:05.849+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:04:05.855+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:04:05.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.622 seconds
[2025-05-28T09:04:36.246+0000] {processor.py:161} INFO - Started process (PID=1659) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:04:36.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:04:36.249+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:04:36.248+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:04:37.446+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:04:37.439+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:04:37.448+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:04:37.500+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.264 seconds
[2025-05-28T09:05:07.770+0000] {processor.py:161} INFO - Started process (PID=1677) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:05:07.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:05:07.774+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:05:07.773+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:05:08.974+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:05:08.909+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:05:08.976+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:05:09.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.251 seconds
[2025-05-28T09:05:39.288+0000] {processor.py:161} INFO - Started process (PID=1698) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:05:39.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:05:39.291+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:05:39.290+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:05:40.241+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:05:40.206+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:05:40.243+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:05:40.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.993 seconds
[2025-05-28T09:06:10.604+0000] {processor.py:161} INFO - Started process (PID=1715) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:06:10.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:06:10.608+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:06:10.607+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:06:11.922+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:06:11.916+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:06:11.923+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:06:11.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.362 seconds
[2025-05-28T09:06:42.246+0000] {processor.py:161} INFO - Started process (PID=1735) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:06:42.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:06:42.248+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:06:42.248+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:06:43.410+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:06:43.405+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:06:43.411+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:06:43.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.193 seconds
[2025-05-28T09:07:13.697+0000] {processor.py:161} INFO - Started process (PID=1753) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:07:13.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:07:13.700+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:07:13.700+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:07:14.825+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:07:14.818+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:07:14.827+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:07:14.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.185 seconds
[2025-05-28T09:07:45.153+0000] {processor.py:161} INFO - Started process (PID=1772) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:07:45.154+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:07:45.155+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:07:45.155+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:07:46.003+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:07:45.996+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:07:46.004+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:07:46.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.893 seconds
[2025-05-28T09:08:16.355+0000] {processor.py:161} INFO - Started process (PID=1790) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:08:16.357+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:08:16.359+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:08:16.358+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:08:17.456+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:08:17.448+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:08:17.458+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:08:17.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.191 seconds
[2025-05-28T09:08:47.822+0000] {processor.py:161} INFO - Started process (PID=1808) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:08:47.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:08:47.825+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:08:47.825+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:08:48.562+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:08:48.556+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:08:48.563+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:08:48.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.788 seconds
[2025-05-28T09:09:18.911+0000] {processor.py:161} INFO - Started process (PID=1826) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:09:18.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:09:18.915+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:09:18.914+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:09:19.745+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:09:19.739+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:09:19.746+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:09:19.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.869 seconds
[2025-05-28T09:09:50.054+0000] {processor.py:161} INFO - Started process (PID=1844) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:09:50.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:09:50.068+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:09:50.067+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:09:51.037+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:09:51.031+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:09:51.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:09:51.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.025 seconds
[2025-05-28T09:10:21.294+0000] {processor.py:161} INFO - Started process (PID=1860) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:10:21.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:10:21.297+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:10:21.297+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:10:22.359+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:10:22.354+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:10:22.360+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:10:22.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.094 seconds
[2025-05-28T09:10:52.464+0000] {processor.py:161} INFO - Started process (PID=1886) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:10:52.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:10:52.467+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:10:52.467+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:10:53.451+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:10:53.439+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:10:53.452+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:10:53.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.037 seconds
[2025-05-28T09:11:23.719+0000] {processor.py:161} INFO - Started process (PID=1904) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:11:23.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:11:23.725+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:11:23.723+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:11:24.595+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:11:24.561+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:11:24.599+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:11:24.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.942 seconds
[2025-05-28T09:11:54.897+0000] {processor.py:161} INFO - Started process (PID=1922) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:11:54.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:11:54.903+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:11:54.902+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:11:56.016+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:11:56.008+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:11:56.017+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:11:56.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.171 seconds
[2025-05-28T09:12:26.337+0000] {processor.py:161} INFO - Started process (PID=1939) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:12:26.339+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:12:26.340+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:12:26.340+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:12:27.168+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:12:27.162+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:12:27.169+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:12:27.195+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.865 seconds
[2025-05-28T09:12:57.457+0000] {processor.py:161} INFO - Started process (PID=1957) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:12:57.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:12:57.460+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:12:57.460+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:12:58.757+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:12:58.751+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:12:58.758+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:12:58.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.336 seconds
[2025-05-28T09:13:29.090+0000] {processor.py:161} INFO - Started process (PID=1975) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:13:29.092+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:13:29.093+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:13:29.093+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:13:29.879+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:13:29.873+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:13:29.880+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:13:29.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.832 seconds
[2025-05-28T09:14:00.224+0000] {processor.py:161} INFO - Started process (PID=1993) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:14:00.226+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:14:00.227+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:14:00.227+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:14:01.638+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:14:01.633+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:14:01.640+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:14:01.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.443 seconds
[2025-05-28T09:14:31.810+0000] {processor.py:161} INFO - Started process (PID=2011) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:14:31.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:14:31.813+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:14:31.812+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:14:32.535+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:14:32.530+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:14:32.537+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:14:32.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.766 seconds
[2025-05-28T09:15:02.715+0000] {processor.py:161} INFO - Started process (PID=2029) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:15:02.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:15:02.719+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:15:02.718+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:15:03.717+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:15:03.712+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:15:03.718+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:15:03.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.043 seconds
[2025-05-28T09:15:34.033+0000] {processor.py:161} INFO - Started process (PID=2047) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:15:34.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:15:34.036+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:15:34.035+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:15:34.957+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:15:34.949+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:15:34.960+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:15:35.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.984 seconds
[2025-05-28T09:16:05.214+0000] {processor.py:161} INFO - Started process (PID=2065) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:16:05.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:16:05.218+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:16:05.218+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:16:06.238+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:16:06.224+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:16:06.240+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:16:06.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.075 seconds
[2025-05-28T09:16:36.388+0000] {processor.py:161} INFO - Started process (PID=2083) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:16:36.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:16:36.392+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:16:36.391+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:16:37.201+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:16:37.195+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:16:37.203+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:16:37.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.856 seconds
[2025-05-28T09:17:07.556+0000] {processor.py:161} INFO - Started process (PID=2101) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:17:07.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:17:07.560+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:17:07.559+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:17:09.322+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:17:09.316+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:17:09.324+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:17:09.355+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.810 seconds
[2025-05-28T09:17:39.438+0000] {processor.py:161} INFO - Started process (PID=2119) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:17:39.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:17:39.441+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:17:39.440+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:17:40.215+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:17:40.209+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:17:40.216+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:17:40.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.805 seconds
[2025-05-28T09:18:10.482+0000] {processor.py:161} INFO - Started process (PID=2137) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:18:10.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:18:10.487+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:18:10.486+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:18:11.576+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:18:11.567+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:18:11.577+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:18:11.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.146 seconds
[2025-05-28T09:18:41.950+0000] {processor.py:161} INFO - Started process (PID=2155) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:18:41.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:18:41.954+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:18:41.953+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:18:42.806+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:18:42.800+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:18:42.808+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:18:42.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.902 seconds
[2025-05-28T09:19:13.156+0000] {processor.py:161} INFO - Started process (PID=2174) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:19:13.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:19:13.160+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:19:13.160+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:19:14.122+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:19:14.115+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:19:14.125+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:19:14.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.004 seconds
[2025-05-28T09:19:44.423+0000] {processor.py:161} INFO - Started process (PID=2192) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:19:44.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:19:44.426+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:19:44.425+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:19:45.360+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:19:45.355+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:19:45.361+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:19:45.377+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.964 seconds
[2025-05-28T09:20:15.636+0000] {processor.py:161} INFO - Started process (PID=2210) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:20:15.638+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:20:15.640+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:20:15.639+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:20:16.574+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:20:16.567+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:20:16.575+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:20:16.605+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.979 seconds
[2025-05-28T09:20:46.893+0000] {processor.py:161} INFO - Started process (PID=2228) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:20:46.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:20:46.895+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:20:46.895+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:20:47.736+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:20:47.729+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:20:47.738+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:20:47.764+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.878 seconds
[2025-05-28T09:21:18.114+0000] {processor.py:161} INFO - Started process (PID=2246) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:21:18.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:21:18.118+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:21:18.117+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:21:19.216+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:21:19.210+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:21:19.218+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:21:19.267+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.166 seconds
[2025-05-28T09:21:49.565+0000] {processor.py:161} INFO - Started process (PID=2264) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:21:49.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:21:49.569+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:21:49.568+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:21:50.263+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:21:50.257+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:21:50.264+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:21:50.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.728 seconds
[2025-05-28T09:22:20.655+0000] {processor.py:161} INFO - Started process (PID=2282) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:22:20.657+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:22:20.660+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:22:20.659+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:22:21.987+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:22:21.982+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:22:21.988+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:22:22.023+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.384 seconds
[2025-05-28T09:22:52.290+0000] {processor.py:161} INFO - Started process (PID=2300) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:22:52.292+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:22:52.293+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:22:52.293+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:22:53.169+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:22:53.164+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:22:53.170+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:22:53.194+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.911 seconds
[2025-05-28T09:23:23.507+0000] {processor.py:161} INFO - Started process (PID=2324) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:23:23.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:23:23.510+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:23:23.510+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:23:24.282+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:23:24.276+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:23:24.283+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:23:24.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.834 seconds
[2025-05-28T09:23:54.637+0000] {processor.py:161} INFO - Started process (PID=2342) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:23:54.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:23:54.641+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:23:54.640+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:23:55.524+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:23:55.519+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:23:55.525+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:23:55.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.924 seconds
[2025-05-28T09:24:26.042+0000] {processor.py:161} INFO - Started process (PID=2360) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:24:26.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:24:26.045+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:24:26.044+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:24:26.887+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:24:26.881+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:24:26.888+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:24:26.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.879 seconds
[2025-05-28T09:24:57.199+0000] {processor.py:161} INFO - Started process (PID=2378) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:24:57.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:24:57.203+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:24:57.202+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:24:57.953+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:24:57.947+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:24:57.954+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:24:57.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.794 seconds
[2025-05-28T09:25:28.320+0000] {processor.py:161} INFO - Started process (PID=2396) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:25:28.322+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:25:28.324+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:25:28.323+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:25:29.122+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:25:29.117+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:25:29.122+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:25:29.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.842 seconds
[2025-05-28T09:25:59.620+0000] {processor.py:161} INFO - Started process (PID=2414) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:25:59.621+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:25:59.622+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:25:59.622+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:26:00.452+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:26:00.447+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:26:00.453+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:26:00.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.909 seconds
[2025-05-28T09:26:30.959+0000] {processor.py:161} INFO - Started process (PID=2432) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:26:30.963+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:26:30.973+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:26:30.972+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:26:34.550+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:26:34.535+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:26:34.555+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:26:34.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.685 seconds
[2025-05-28T09:27:04.867+0000] {processor.py:161} INFO - Started process (PID=2450) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:27:04.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:27:04.880+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:27:04.879+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:27:09.347+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:27:09.320+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:27:09.349+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:27:09.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.577 seconds
[2025-05-28T09:27:39.742+0000] {processor.py:161} INFO - Started process (PID=2468) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:27:39.745+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:27:39.747+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:27:39.746+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:27:42.854+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:27:42.801+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:27:42.856+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:27:42.956+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.232 seconds
[2025-05-28T09:28:13.977+0000] {processor.py:161} INFO - Started process (PID=2486) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:28:13.984+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:28:13.989+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:28:13.988+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:28:17.751+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:28:17.736+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:28:17.762+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:28:17.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.918 seconds
[2025-05-28T09:28:48.160+0000] {processor.py:161} INFO - Started process (PID=2504) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:28:48.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:28:48.164+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:28:48.163+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:28:49.645+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:28:49.632+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:28:49.647+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:28:49.693+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.551 seconds
[2025-05-28T09:29:20.146+0000] {processor.py:161} INFO - Started process (PID=2522) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:29:20.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:29:20.150+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:29:20.150+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:29:21.714+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:29:21.705+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:29:21.717+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:29:21.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.613 seconds
[2025-05-28T09:29:52.083+0000] {processor.py:161} INFO - Started process (PID=2540) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:29:52.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:29:52.086+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:29:52.086+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:29:53.606+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:29:53.598+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:29:53.607+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:29:53.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.575 seconds
[2025-05-28T09:30:24.298+0000] {processor.py:161} INFO - Started process (PID=2558) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:30:24.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:30:24.302+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:30:24.302+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:30:27.126+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:30:27.118+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:30:27.128+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:30:27.167+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.888 seconds
[2025-05-28T09:30:57.655+0000] {processor.py:161} INFO - Started process (PID=2581) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:30:57.657+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:30:57.659+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:30:57.658+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:30:59.073+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:30:59.066+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:30:59.074+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:30:59.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.476 seconds
[2025-05-28T09:31:29.546+0000] {processor.py:161} INFO - Started process (PID=2599) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:31:29.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:31:29.550+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:31:29.549+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:31:31.165+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:31:31.158+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:31:31.167+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:31:31.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.660 seconds
[2025-05-28T09:32:01.454+0000] {processor.py:161} INFO - Started process (PID=2617) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:32:01.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:32:01.458+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:32:01.457+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:32:02.893+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:32:02.886+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:32:02.895+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:32:02.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.487 seconds
[2025-05-28T09:32:33.319+0000] {processor.py:161} INFO - Started process (PID=2636) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:32:33.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:32:33.324+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:32:33.323+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:32:34.421+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:32:34.416+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:32:34.423+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:32:34.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.136 seconds
[2025-05-28T09:33:04.647+0000] {processor.py:161} INFO - Started process (PID=2655) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:33:04.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:33:04.651+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:33:04.650+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:33:07.127+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:33:07.120+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:33:07.129+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:33:07.178+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.544 seconds
[2025-05-28T09:33:37.722+0000] {processor.py:161} INFO - Started process (PID=2673) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:33:37.726+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:33:37.738+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:33:37.738+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:33:39.474+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:33:39.463+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:33:39.476+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:33:39.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.822 seconds
[2025-05-28T09:34:09.854+0000] {processor.py:161} INFO - Started process (PID=2691) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:34:09.855+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:34:09.857+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:34:09.857+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:34:11.991+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:34:11.983+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:34:11.993+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:34:12.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.211 seconds
[2025-05-28T09:34:42.154+0000] {processor.py:161} INFO - Started process (PID=2709) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:34:42.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:34:42.157+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:34:42.156+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:34:43.217+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:34:43.209+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:34:43.219+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:34:43.242+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.099 seconds
[2025-05-28T09:35:13.498+0000] {processor.py:161} INFO - Started process (PID=2727) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:35:13.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:35:13.512+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:35:13.512+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:35:16.005+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:35:15.998+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:35:16.014+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:35:16.048+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.570 seconds
[2025-05-28T09:35:46.196+0000] {processor.py:161} INFO - Started process (PID=2745) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:35:46.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:35:46.199+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:35:46.199+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:35:47.537+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:35:47.524+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:35:47.539+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:35:47.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.405 seconds
[2025-05-28T09:36:17.971+0000] {processor.py:161} INFO - Started process (PID=2763) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:36:17.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:36:17.975+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:36:17.974+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:36:18.734+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:36:18.728+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:36:18.734+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:36:18.766+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.809 seconds
[2025-05-28T09:36:49.301+0000] {processor.py:161} INFO - Started process (PID=2781) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:36:49.302+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:36:49.304+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:36:49.303+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:36:50.017+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:36:50.011+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:36:50.018+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:36:50.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.751 seconds
[2025-05-28T09:37:20.320+0000] {processor.py:161} INFO - Started process (PID=2799) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:37:20.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:37:20.323+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:37:20.322+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:37:21.565+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:37:21.558+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:37:21.567+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:37:21.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.279 seconds
[2025-05-28T09:37:51.921+0000] {processor.py:161} INFO - Started process (PID=2817) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:37:51.923+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:37:51.925+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:37:51.924+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:37:52.817+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:37:52.810+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:37:52.818+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:37:52.843+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.932 seconds
[2025-05-28T09:38:23.124+0000] {processor.py:161} INFO - Started process (PID=2835) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:38:23.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:38:23.128+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:38:23.127+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:38:24.185+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:38:24.179+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:38:24.186+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:38:24.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.106 seconds
[2025-05-28T09:38:54.505+0000] {processor.py:161} INFO - Started process (PID=2853) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:38:54.507+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:38:54.508+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:38:54.508+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:38:55.334+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:38:55.330+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:38:55.335+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:38:55.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.867 seconds
[2025-05-28T09:39:25.700+0000] {processor.py:161} INFO - Started process (PID=2872) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:39:25.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:39:25.704+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:39:25.704+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:39:27.180+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:39:27.171+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:39:27.182+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:39:27.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.535 seconds
[2025-05-28T09:39:57.455+0000] {processor.py:161} INFO - Started process (PID=2890) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:39:57.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:39:57.458+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:39:57.458+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:39:58.536+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:39:58.530+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:39:58.537+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:39:58.562+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.118 seconds
[2025-05-28T09:40:28.915+0000] {processor.py:161} INFO - Started process (PID=2914) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:40:28.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:40:28.918+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:40:28.917+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:40:29.836+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:40:29.806+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:40:29.837+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:40:29.875+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.970 seconds
[2025-05-28T09:41:00.189+0000] {processor.py:161} INFO - Started process (PID=2932) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:41:00.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:41:00.192+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:41:00.192+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:41:01.687+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:41:01.682+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:41:01.688+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:41:01.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.537 seconds
[2025-05-28T09:41:32.148+0000] {processor.py:161} INFO - Started process (PID=2951) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:41:32.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:41:32.151+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:41:32.151+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:41:32.889+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:41:32.884+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:41:32.890+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:41:32.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.774 seconds
[2025-05-28T09:42:03.231+0000] {processor.py:161} INFO - Started process (PID=2969) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:42:03.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:42:03.237+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:42:03.236+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:42:04.373+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:42:04.368+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:42:04.374+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:42:04.403+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.184 seconds
[2025-05-28T09:42:34.683+0000] {processor.py:161} INFO - Started process (PID=2988) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:42:34.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:42:34.691+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:42:34.690+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:42:35.557+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:42:35.550+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:42:35.558+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:42:35.583+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.907 seconds
[2025-05-28T09:43:05.856+0000] {processor.py:161} INFO - Started process (PID=3006) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:43:05.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:43:05.859+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:43:05.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:43:06.915+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:43:06.911+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:43:06.916+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:43:06.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.095 seconds
[2025-05-28T09:43:37.360+0000] {processor.py:161} INFO - Started process (PID=3024) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:43:37.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:43:37.363+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:43:37.363+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:43:38.380+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:43:38.373+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:43:38.381+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:43:38.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.059 seconds
[2025-05-28T09:44:08.688+0000] {processor.py:161} INFO - Started process (PID=3041) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:44:08.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:44:08.692+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:44:08.691+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:44:09.547+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:44:09.542+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:44:09.548+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:44:09.579+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.905 seconds
[2025-05-28T09:44:39.909+0000] {processor.py:161} INFO - Started process (PID=3059) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:44:39.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:44:39.912+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:44:39.911+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:44:40.611+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:44:40.605+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:44:40.612+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:44:40.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.736 seconds
[2025-05-28T09:45:10.957+0000] {processor.py:161} INFO - Started process (PID=3077) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:45:10.959+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:45:10.960+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:45:10.960+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:45:11.978+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:45:11.972+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:45:11.979+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:45:12.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.112 seconds
[2025-05-28T09:45:42.435+0000] {processor.py:161} INFO - Started process (PID=3095) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:45:42.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:45:42.439+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:45:42.438+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:45:43.293+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:45:43.287+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:45:43.294+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:45:43.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.893 seconds
[2025-05-28T09:46:13.599+0000] {processor.py:161} INFO - Started process (PID=3113) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:46:13.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:46:13.603+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:46:13.602+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:46:14.738+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:46:14.733+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:46:14.739+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:46:14.764+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.176 seconds
[2025-05-28T09:46:45.063+0000] {processor.py:161} INFO - Started process (PID=3131) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:46:45.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:46:45.066+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:46:45.065+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:46:45.886+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:46:45.873+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:46:45.889+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:46:45.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.868 seconds
[2025-05-28T09:47:16.231+0000] {processor.py:161} INFO - Started process (PID=3149) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:47:16.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:47:16.234+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:47:16.234+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:47:17.036+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:47:17.031+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:47:17.037+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:47:17.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.848 seconds
[2025-05-28T09:47:47.329+0000] {processor.py:161} INFO - Started process (PID=3167) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:47:47.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:47:47.332+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:47:47.331+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:47:48.027+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:47:48.021+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:47:48.029+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:47:48.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.733 seconds
[2025-05-28T09:48:18.330+0000] {processor.py:161} INFO - Started process (PID=3185) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:48:18.332+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:48:18.334+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:48:18.333+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:48:19.207+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:48:19.201+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:48:19.208+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:48:19.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.917 seconds
[2025-05-28T09:48:49.559+0000] {processor.py:161} INFO - Started process (PID=3204) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:48:49.561+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:48:49.563+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:48:49.562+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:48:50.326+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:48:50.320+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:48:50.327+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:48:50.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.805 seconds
[2025-05-28T09:49:20.476+0000] {processor.py:161} INFO - Started process (PID=3222) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:49:20.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:49:20.479+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:49:20.479+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:49:21.345+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:49:21.323+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:49:21.347+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:49:21.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.912 seconds
[2025-05-28T09:49:52.059+0000] {processor.py:161} INFO - Started process (PID=3240) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:49:52.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:49:52.062+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:49:52.061+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:49:53.030+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:49:53.022+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:49:53.032+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:49:53.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.014 seconds
[2025-05-28T09:50:23.385+0000] {processor.py:161} INFO - Started process (PID=3258) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:50:23.387+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:50:23.388+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:50:23.387+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:50:24.652+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:50:24.646+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:50:24.653+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:50:24.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.308 seconds
[2025-05-28T09:50:54.950+0000] {processor.py:161} INFO - Started process (PID=3276) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:50:54.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:50:54.953+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:50:54.953+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:50:55.708+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:50:55.699+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:50:55.710+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:50:55.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.802 seconds
[2025-05-28T09:51:26.018+0000] {processor.py:161} INFO - Started process (PID=3295) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:51:26.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:51:26.021+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:51:26.021+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:51:26.714+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:51:26.708+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:51:26.715+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:51:26.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.731 seconds
[2025-05-28T09:51:57.004+0000] {processor.py:161} INFO - Started process (PID=3313) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:51:57.005+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:51:57.006+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:51:57.006+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:51:57.694+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:51:57.688+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:51:57.695+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:51:57.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.727 seconds
[2025-05-28T09:52:27.999+0000] {processor.py:161} INFO - Started process (PID=3331) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:52:28.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:52:28.002+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:52:28.001+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:52:28.773+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:52:28.767+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:52:28.774+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:52:28.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.801 seconds
[2025-05-28T09:52:59.120+0000] {processor.py:161} INFO - Started process (PID=3349) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:52:59.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:52:59.122+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:52:59.122+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:52:59.996+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:52:59.989+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:52:59.997+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:53:00.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.923 seconds
[2025-05-28T09:53:30.183+0000] {processor.py:161} INFO - Started process (PID=3374) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:53:30.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:53:30.186+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:53:30.185+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:53:30.984+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:53:30.980+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:53:30.985+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:53:31.005+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.829 seconds
[2025-05-28T09:54:01.641+0000] {processor.py:161} INFO - Started process (PID=3392) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:54:01.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:54:01.654+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:54:01.653+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:54:02.518+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:54:02.512+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:54:02.519+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:54:02.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.928 seconds
[2025-05-28T09:54:32.829+0000] {processor.py:161} INFO - Started process (PID=3410) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:54:32.831+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:54:32.832+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:54:32.832+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:54:33.636+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:54:33.631+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:54:33.637+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:54:33.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.839 seconds
[2025-05-28T09:55:04.420+0000] {processor.py:161} INFO - Started process (PID=3428) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:55:04.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:55:04.423+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:55:04.423+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:55:05.490+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:55:05.484+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:55:05.491+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:55:05.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.106 seconds
[2025-05-28T09:55:35.768+0000] {processor.py:161} INFO - Started process (PID=3446) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:55:35.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:55:35.771+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:55:35.771+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:55:36.598+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:55:36.593+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:55:36.600+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:55:36.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.863 seconds
[2025-05-28T09:56:06.951+0000] {processor.py:161} INFO - Started process (PID=3464) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:56:06.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:56:06.955+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:56:06.954+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:56:09.502+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:56:09.494+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:56:09.503+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:56:09.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.599 seconds
[2025-05-28T09:56:39.860+0000] {processor.py:161} INFO - Started process (PID=3482) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:56:39.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:56:39.865+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:56:39.864+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:56:40.730+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:56:40.724+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:56:40.731+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:56:40.761+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.916 seconds
[2025-05-28T09:57:11.251+0000] {processor.py:161} INFO - Started process (PID=3500) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:57:11.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:57:11.255+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:57:11.254+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:57:12.947+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:57:12.942+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:57:12.949+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:57:12.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.731 seconds
[2025-05-28T09:57:43.391+0000] {processor.py:161} INFO - Started process (PID=3518) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:57:43.393+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:57:43.394+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:57:43.394+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:57:44.125+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:57:44.119+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:57:44.126+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:57:44.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.769 seconds
[2025-05-28T09:58:14.807+0000] {processor.py:161} INFO - Started process (PID=3536) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:58:14.808+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:58:14.810+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:58:14.809+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:58:15.635+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:58:15.629+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:58:15.636+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:58:15.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.869 seconds
[2025-05-28T09:58:45.916+0000] {processor.py:161} INFO - Started process (PID=3554) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:58:45.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:58:45.919+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:58:45.918+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:58:46.689+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:58:46.684+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:58:46.691+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:58:46.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.822 seconds
[2025-05-28T09:59:17.557+0000] {processor.py:161} INFO - Started process (PID=3572) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:59:17.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:59:17.560+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:59:17.559+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:59:18.371+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:59:18.366+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:59:18.372+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:59:18.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.850 seconds
[2025-05-28T09:59:48.721+0000] {processor.py:161} INFO - Started process (PID=3590) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:59:48.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T09:59:48.727+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:59:48.726+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:59:49.530+0000] {logging_mixin.py:188} INFO - [2025-05-28T09:59:49.524+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T09:59:49.531+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T09:59:49.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.841 seconds
[2025-05-28T10:00:19.975+0000] {processor.py:161} INFO - Started process (PID=3608) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:00:19.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:00:19.978+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:00:19.977+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:00:21.061+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:00:21.053+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:00:21.062+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:00:21.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.150 seconds
[2025-05-28T10:00:51.411+0000] {processor.py:161} INFO - Started process (PID=3627) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:00:51.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:00:51.418+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:00:51.417+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:00:52.397+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:00:52.393+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:00:52.398+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:00:52.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.020 seconds
[2025-05-28T10:01:22.517+0000] {processor.py:161} INFO - Started process (PID=3645) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:01:22.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:01:22.520+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:01:22.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:01:23.346+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:01:23.341+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:01:23.347+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:01:23.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.863 seconds
[2025-05-28T10:01:53.483+0000] {processor.py:161} INFO - Started process (PID=3663) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:01:53.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:01:53.488+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:01:53.488+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:01:54.647+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:01:54.644+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:01:54.649+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:01:54.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.221 seconds
[2025-05-28T10:02:25.109+0000] {processor.py:161} INFO - Started process (PID=3686) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:02:25.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:02:25.115+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:02:25.114+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:02:25.991+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:02:25.984+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:02:25.992+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:02:26.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.922 seconds
[2025-05-28T10:02:56.308+0000] {processor.py:161} INFO - Started process (PID=3703) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:02:56.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:02:56.344+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:02:56.343+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:02:57.263+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:02:57.256+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:02:57.263+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:02:57.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.004 seconds
[2025-05-28T10:03:27.541+0000] {processor.py:161} INFO - Started process (PID=3717) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:03:27.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:03:27.544+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:03:27.543+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:03:28.404+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:03:28.399+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:03:28.405+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:03:28.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.899 seconds
[2025-05-28T10:03:58.529+0000] {processor.py:161} INFO - Started process (PID=3736) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:03:58.531+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:03:58.535+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:03:58.533+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:03:59.848+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:03:59.841+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:03:59.850+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:03:59.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.362 seconds
[2025-05-28T10:04:30.160+0000] {processor.py:161} INFO - Started process (PID=3758) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:04:30.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:04:30.163+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:04:30.163+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:04:31.097+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:04:31.090+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:04:31.098+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:04:31.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.965 seconds
[2025-05-28T10:05:01.404+0000] {processor.py:161} INFO - Started process (PID=3782) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:05:01.405+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:05:01.407+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:05:01.406+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:05:02.727+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:05:02.718+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:05:02.729+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:05:02.813+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.421 seconds
[2025-05-28T10:05:33.076+0000] {processor.py:161} INFO - Started process (PID=3802) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:05:33.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:05:33.080+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:05:33.079+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:05:33.899+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:05:33.892+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:05:33.901+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:05:33.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.871 seconds
[2025-05-28T10:06:04.227+0000] {processor.py:161} INFO - Started process (PID=3820) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:06:04.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:06:04.230+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:06:04.229+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:06:05.381+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:06:05.375+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:06:05.382+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:06:05.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.189 seconds
[2025-05-28T10:06:35.703+0000] {processor.py:161} INFO - Started process (PID=3838) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:06:35.704+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:06:35.707+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:06:35.706+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:06:36.440+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:06:36.434+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:06:36.441+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:06:36.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.776 seconds
[2025-05-28T10:07:06.697+0000] {processor.py:161} INFO - Started process (PID=3853) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:07:06.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:07:06.703+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:07:06.702+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:07:08.117+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:07:08.108+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:07:08.119+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:07:08.171+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.491 seconds
[2025-05-28T10:07:38.495+0000] {processor.py:161} INFO - Started process (PID=3873) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:07:38.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:07:38.499+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:07:38.498+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:07:39.747+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:07:39.742+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:07:39.748+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:07:39.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.304 seconds
[2025-05-28T10:08:09.972+0000] {processor.py:161} INFO - Started process (PID=3891) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:08:09.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:08:09.976+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:08:09.975+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:08:11.183+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:08:11.178+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:08:11.184+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:08:11.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.251 seconds
[2025-05-28T10:08:41.604+0000] {processor.py:161} INFO - Started process (PID=3909) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:08:41.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:08:41.608+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:08:41.607+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:08:42.666+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:08:42.662+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:08:42.667+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:08:42.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.089 seconds
[2025-05-28T10:09:12.761+0000] {processor.py:161} INFO - Started process (PID=3927) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:09:12.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:09:12.764+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:09:12.763+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:09:13.693+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:09:13.682+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:09:13.694+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:09:13.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.973 seconds
[2025-05-28T10:09:44.012+0000] {processor.py:161} INFO - Started process (PID=3945) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:09:44.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:09:44.015+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:09:44.015+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:09:44.802+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:09:44.795+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:09:44.803+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:09:44.828+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.825 seconds
[2025-05-28T10:10:15.576+0000] {processor.py:161} INFO - Started process (PID=3962) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:10:15.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:10:15.580+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:10:15.579+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:10:16.577+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:10:16.572+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:10:16.579+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:10:16.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.046 seconds
[2025-05-28T10:10:46.877+0000] {processor.py:161} INFO - Started process (PID=3980) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:10:46.878+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:10:46.879+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:10:46.879+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:10:47.532+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:10:47.526+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:10:47.534+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:10:47.562+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.693 seconds
[2025-05-28T10:11:17.870+0000] {processor.py:161} INFO - Started process (PID=3998) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:11:17.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:11:17.873+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:11:17.873+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:11:18.790+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:11:18.783+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:11:18.791+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:11:18.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.959 seconds
[2025-05-28T10:11:49.010+0000] {processor.py:161} INFO - Started process (PID=4016) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:11:49.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:11:49.013+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:11:49.012+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:11:49.728+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:11:49.721+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:11:49.730+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:11:49.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.757 seconds
[2025-05-28T10:12:20.061+0000] {processor.py:161} INFO - Started process (PID=4034) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:12:20.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:12:20.069+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:12:20.068+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:12:20.886+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:12:20.880+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:12:20.888+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:12:20.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.875 seconds
[2025-05-28T10:12:51.179+0000] {processor.py:161} INFO - Started process (PID=4052) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:12:51.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:12:51.182+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:12:51.181+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:12:52.016+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:12:52.011+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:12:52.017+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:12:52.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.883 seconds
[2025-05-28T10:13:22.315+0000] {processor.py:161} INFO - Started process (PID=4071) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:13:22.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:13:22.317+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:13:22.317+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:13:23.106+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:13:23.101+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:13:23.108+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:13:23.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.853 seconds
[2025-05-28T10:13:53.672+0000] {processor.py:161} INFO - Started process (PID=4089) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:13:53.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:13:53.675+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:13:53.675+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:13:54.516+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:13:54.510+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:13:54.517+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:13:54.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.880 seconds
[2025-05-28T10:14:24.858+0000] {processor.py:161} INFO - Started process (PID=4107) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:14:24.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:14:24.861+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:14:24.860+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:14:25.530+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:14:25.517+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:14:25.532+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:14:25.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.747 seconds
[2025-05-28T10:14:55.770+0000] {processor.py:161} INFO - Started process (PID=4125) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:14:55.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:14:55.776+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:14:55.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:14:56.526+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:14:56.519+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:14:56.527+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:14:56.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.798 seconds
[2025-05-28T10:15:26.857+0000] {processor.py:161} INFO - Started process (PID=4144) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:15:26.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:15:26.860+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:15:26.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:15:27.559+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:15:27.553+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:15:27.561+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:15:27.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.747 seconds
[2025-05-28T10:15:57.862+0000] {processor.py:161} INFO - Started process (PID=4162) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:15:57.864+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:15:57.866+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:15:57.866+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:15:58.562+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:15:58.558+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:15:58.563+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:15:58.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.752 seconds
[2025-05-28T10:16:28.903+0000] {processor.py:161} INFO - Started process (PID=4180) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:16:28.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:16:28.906+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:16:28.906+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:16:29.605+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:16:29.600+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:16:29.606+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:16:29.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.740 seconds
[2025-05-28T10:16:59.860+0000] {processor.py:161} INFO - Started process (PID=4198) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:16:59.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:16:59.865+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:16:59.864+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:17:00.689+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:17:00.683+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:17:00.691+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:17:00.725+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.893 seconds
[2025-05-28T10:17:30.844+0000] {processor.py:161} INFO - Started process (PID=4216) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:17:30.845+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:17:30.847+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:17:30.846+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:17:31.459+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:17:31.454+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:17:31.460+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:17:31.487+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.650 seconds
[2025-05-28T10:18:01.851+0000] {processor.py:161} INFO - Started process (PID=4234) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:18:01.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:18:01.870+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:18:01.869+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:18:03.382+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:18:03.367+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:18:03.384+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:18:03.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.656 seconds
[2025-05-28T10:18:33.838+0000] {processor.py:161} INFO - Started process (PID=4259) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:18:33.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:18:33.842+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:18:33.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:18:34.610+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:18:34.605+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:18:34.611+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:18:34.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.807 seconds
[2025-05-28T10:19:04.808+0000] {processor.py:161} INFO - Started process (PID=4277) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:19:04.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:19:04.811+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:19:04.810+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:19:05.670+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:19:05.656+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:19:05.673+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:19:05.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.936 seconds
[2025-05-28T10:19:36.454+0000] {processor.py:161} INFO - Started process (PID=4295) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:19:36.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:19:36.458+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:19:36.457+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:19:37.130+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:19:37.123+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:19:37.131+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:19:37.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.715 seconds
[2025-05-28T10:20:07.433+0000] {processor.py:161} INFO - Started process (PID=4314) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:20:07.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:20:07.436+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:20:07.436+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:20:08.289+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:20:08.277+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:20:08.291+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:20:08.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.904 seconds
[2025-05-28T10:20:38.817+0000] {processor.py:161} INFO - Started process (PID=4332) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:20:38.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:20:38.821+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:20:38.821+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:20:39.448+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:20:39.441+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:20:39.450+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:20:39.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.688 seconds
[2025-05-28T10:21:09.776+0000] {processor.py:161} INFO - Started process (PID=4350) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:21:09.778+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:21:09.779+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:21:09.779+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:21:10.662+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:21:10.652+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:21:10.663+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:21:10.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.956 seconds
[2025-05-28T10:21:41.104+0000] {processor.py:161} INFO - Started process (PID=4368) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:21:41.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:21:41.106+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:21:41.106+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:21:41.698+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:21:41.693+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:21:41.699+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:21:41.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.630 seconds
[2025-05-28T10:22:12.046+0000] {processor.py:161} INFO - Started process (PID=4386) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:22:12.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:22:12.049+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:22:12.048+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:22:12.869+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:22:12.857+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:22:12.874+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:22:12.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.876 seconds
[2025-05-28T10:22:43.334+0000] {processor.py:161} INFO - Started process (PID=4404) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:22:43.336+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:22:43.337+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:22:43.337+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:22:43.979+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:22:43.974+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:22:43.980+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:22:44.031+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.708 seconds
[2025-05-28T10:23:14.406+0000] {processor.py:161} INFO - Started process (PID=4422) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:23:14.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:23:14.409+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:23:14.408+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:23:15.559+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:23:15.555+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:23:15.560+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:23:15.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.190 seconds
[2025-05-28T10:23:45.862+0000] {processor.py:161} INFO - Started process (PID=4440) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:23:45.864+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:23:45.866+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:23:45.865+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:23:46.997+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:23:46.991+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:23:46.998+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:23:47.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.186 seconds
[2025-05-28T10:24:17.307+0000] {processor.py:161} INFO - Started process (PID=4458) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:24:17.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:24:17.310+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:24:17.309+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:24:18.151+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:24:18.145+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:24:18.152+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:24:18.179+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.881 seconds
[2025-05-28T10:24:48.443+0000] {processor.py:161} INFO - Started process (PID=4476) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:24:48.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:24:48.446+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:24:48.446+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:24:49.212+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:24:49.207+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:24:49.213+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:24:49.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.810 seconds
[2025-05-28T10:25:19.546+0000] {processor.py:161} INFO - Started process (PID=4494) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:25:19.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:25:19.549+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:25:19.548+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:25:20.614+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:25:20.607+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:25:20.616+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:25:20.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.110 seconds
[2025-05-28T10:25:50.890+0000] {processor.py:161} INFO - Started process (PID=4512) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:25:50.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:25:50.894+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:25:50.893+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:25:51.473+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:25:51.468+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:25:51.474+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:25:51.504+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.624 seconds
[2025-05-28T10:26:21.847+0000] {processor.py:161} INFO - Started process (PID=4530) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:26:21.848+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:26:21.849+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:26:21.849+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:26:22.546+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:26:22.540+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:26:22.547+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:26:22.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.736 seconds
[2025-05-28T10:26:52.819+0000] {processor.py:161} INFO - Started process (PID=4548) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:26:52.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:26:52.821+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:26:52.821+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:26:53.660+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:26:53.655+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:26:53.661+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:26:53.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.880 seconds
[2025-05-28T10:27:23.997+0000] {processor.py:161} INFO - Started process (PID=4566) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:27:23.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:27:24.000+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:27:24.000+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:27:24.632+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:27:24.623+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:27:24.634+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:27:24.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.672 seconds
[2025-05-28T10:27:54.941+0000] {processor.py:161} INFO - Started process (PID=4585) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:27:54.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:27:54.945+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:27:54.945+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:27:55.612+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:27:55.604+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:27:55.616+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:27:55.666+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.738 seconds
[2025-05-28T10:28:25.989+0000] {processor.py:161} INFO - Started process (PID=4603) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:28:25.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:28:25.992+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:28:25.992+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:28:26.788+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:28:26.780+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:28:26.789+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:28:26.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.837 seconds
[2025-05-28T10:28:57.316+0000] {processor.py:161} INFO - Started process (PID=4621) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:28:57.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:28:57.319+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:28:57.318+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:28:58.107+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:28:58.101+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:28:58.108+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:28:58.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.838 seconds
[2025-05-28T10:29:28.984+0000] {processor.py:161} INFO - Started process (PID=4639) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:29:28.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:29:28.986+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:29:28.986+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:29:29.726+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:29:29.721+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:29:29.727+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:29:29.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.777 seconds
[2025-05-28T10:30:00.372+0000] {processor.py:161} INFO - Started process (PID=4658) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:30:00.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:30:00.377+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:30:00.376+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:30:01.831+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:30:01.819+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:30:01.836+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:30:01.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.522 seconds
[2025-05-28T10:30:32.145+0000] {processor.py:161} INFO - Started process (PID=4676) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:30:32.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:30:32.147+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:30:32.147+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:30:32.715+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:30:32.708+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:30:32.716+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:30:32.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.605 seconds
[2025-05-28T10:31:03.003+0000] {processor.py:161} INFO - Started process (PID=4693) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:31:03.005+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:31:03.006+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:31:03.006+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:31:04.103+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:31:04.097+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:31:04.104+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:31:04.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.150 seconds
[2025-05-28T10:31:34.471+0000] {processor.py:161} INFO - Started process (PID=4717) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:31:34.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:31:34.474+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:31:34.473+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:31:35.181+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:31:35.175+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:31:35.182+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:31:35.210+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.747 seconds
[2025-05-28T10:32:05.513+0000] {processor.py:161} INFO - Started process (PID=4735) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:32:05.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:32:05.517+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:32:05.516+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:32:06.533+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:32:06.513+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:32:06.536+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:32:06.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.097 seconds
[2025-05-28T10:32:36.775+0000] {processor.py:161} INFO - Started process (PID=4753) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:32:36.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:32:36.778+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:32:36.778+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:32:37.478+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:32:37.472+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:32:37.479+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:32:37.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.743 seconds
[2025-05-28T10:33:08.079+0000] {processor.py:161} INFO - Started process (PID=4771) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:33:08.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:33:08.081+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:33:08.081+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:33:08.836+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:33:08.832+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:33:08.837+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:33:08.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.818 seconds
[2025-05-28T10:33:39.161+0000] {processor.py:161} INFO - Started process (PID=4789) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:33:39.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:33:39.166+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:33:39.165+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:33:39.875+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:33:39.870+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:33:39.876+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:33:39.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.745 seconds
[2025-05-28T10:34:10.166+0000] {processor.py:161} INFO - Started process (PID=4807) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:34:10.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:34:10.169+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:34:10.169+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:34:11.197+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:34:11.192+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:34:11.198+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:34:11.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.069 seconds
[2025-05-28T10:34:41.511+0000] {processor.py:161} INFO - Started process (PID=4825) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:34:41.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:34:41.514+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:34:41.513+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:34:42.374+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:34:42.368+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:34:42.375+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:34:42.405+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.901 seconds
[2025-05-28T10:35:12.774+0000] {processor.py:161} INFO - Started process (PID=4843) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:35:12.775+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:35:12.777+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:35:12.776+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:35:13.649+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:35:13.639+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:35:13.651+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:35:13.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.953 seconds
[2025-05-28T10:35:44.108+0000] {processor.py:161} INFO - Started process (PID=4861) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:35:44.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:35:44.111+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:35:44.110+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:35:44.702+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:35:44.694+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:35:44.703+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:35:44.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.649 seconds
[2025-05-28T10:36:15.049+0000] {processor.py:161} INFO - Started process (PID=4879) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:36:15.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:36:15.053+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:36:15.052+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:36:15.890+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:36:15.884+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:36:15.891+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:36:15.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.883 seconds
[2025-05-28T10:36:46.209+0000] {processor.py:161} INFO - Started process (PID=4897) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:36:46.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:36:46.213+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:36:46.212+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:36:47.109+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:36:47.105+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:36:47.110+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:36:47.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.936 seconds
[2025-05-28T10:37:17.462+0000] {processor.py:161} INFO - Started process (PID=4915) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:37:17.464+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:37:17.465+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:37:17.465+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:37:18.156+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:37:18.150+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:37:18.158+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:37:18.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.734 seconds
[2025-05-28T10:37:49.085+0000] {processor.py:161} INFO - Started process (PID=4933) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:37:49.087+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:37:49.088+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:37:49.088+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:37:49.804+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:37:49.798+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:37:49.805+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:37:49.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.753 seconds
[2025-05-28T10:38:20.255+0000] {processor.py:161} INFO - Started process (PID=4952) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:38:20.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:38:20.257+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:38:20.257+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:38:21.148+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:38:21.136+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:38:21.150+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:38:21.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.947 seconds
[2025-05-28T10:38:51.572+0000] {processor.py:161} INFO - Started process (PID=4970) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:38:51.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:38:51.576+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:38:51.575+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:38:52.199+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:38:52.192+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:38:52.200+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:38:52.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.663 seconds
[2025-05-28T10:39:22.670+0000] {processor.py:161} INFO - Started process (PID=4989) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:39:22.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:39:22.674+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:39:22.673+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:39:24.007+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:39:23.996+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:39:24.011+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:39:24.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.407 seconds
[2025-05-28T10:39:54.179+0000] {processor.py:161} INFO - Started process (PID=5007) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:39:54.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:39:54.184+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:39:54.183+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:39:54.931+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:39:54.922+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:39:54.933+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:39:54.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.829 seconds
[2025-05-28T10:40:25.449+0000] {processor.py:161} INFO - Started process (PID=5026) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:40:25.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:40:25.454+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:40:25.453+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:40:26.397+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:40:26.387+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:40:26.400+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:40:26.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.015 seconds
[2025-05-28T10:40:56.921+0000] {processor.py:161} INFO - Started process (PID=5044) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:40:56.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:40:56.928+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:40:56.927+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:40:58.228+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:40:58.220+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:40:58.229+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:40:58.258+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.353 seconds
[2025-05-28T10:41:28.357+0000] {processor.py:161} INFO - Started process (PID=5062) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:41:28.359+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:41:28.360+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:41:28.360+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:41:29.236+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:41:29.229+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:41:29.238+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:41:29.270+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.924 seconds
[2025-05-28T10:41:59.732+0000] {processor.py:161} INFO - Started process (PID=5080) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:41:59.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:41:59.743+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:41:59.742+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:42:01.034+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:42:01.026+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:42:01.035+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:42:01.078+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.363 seconds
[2025-05-28T10:42:31.496+0000] {processor.py:161} INFO - Started process (PID=5098) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:42:31.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:42:31.500+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:42:31.499+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:42:32.545+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:42:32.536+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:42:32.546+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:42:32.590+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.107 seconds
[2025-05-28T10:43:02.978+0000] {processor.py:161} INFO - Started process (PID=5116) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:43:02.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:43:02.982+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:43:02.982+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:43:03.870+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:43:03.861+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:43:03.872+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:43:03.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.943 seconds
[2025-05-28T10:43:34.333+0000] {processor.py:161} INFO - Started process (PID=5134) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:43:34.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:43:34.337+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:43:34.336+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:43:35.427+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:43:35.405+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:43:35.431+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:43:35.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.207 seconds
[2025-05-28T10:44:06.090+0000] {processor.py:161} INFO - Started process (PID=5159) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:44:06.092+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:44:06.094+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:44:06.093+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:44:07.507+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:44:07.501+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:44:07.508+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:44:07.541+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.473 seconds
[2025-05-28T10:44:38.001+0000] {processor.py:161} INFO - Started process (PID=5177) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:44:38.003+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:44:38.005+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:44:38.004+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:44:38.891+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:44:38.884+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:44:38.892+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:44:38.936+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.942 seconds
[2025-05-28T10:45:09.365+0000] {processor.py:161} INFO - Started process (PID=5195) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:45:09.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:45:09.368+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:45:09.368+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:45:10.129+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:45:10.123+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:45:10.130+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:45:10.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.803 seconds
[2025-05-28T10:45:40.410+0000] {processor.py:161} INFO - Started process (PID=5213) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:45:40.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:45:40.414+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:45:40.413+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:45:41.552+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:45:41.545+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:45:41.553+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:45:41.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.209 seconds
[2025-05-28T10:46:12.017+0000] {processor.py:161} INFO - Started process (PID=5231) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:46:12.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:46:12.021+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:46:12.020+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:46:12.997+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:46:12.987+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:46:12.999+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:46:13.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.055 seconds
[2025-05-28T10:46:43.545+0000] {processor.py:161} INFO - Started process (PID=5249) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:46:43.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:46:43.550+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:46:43.549+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:46:44.777+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:46:44.769+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:46:44.779+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:46:44.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.274 seconds
[2025-05-28T10:47:14.895+0000] {processor.py:161} INFO - Started process (PID=5267) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:47:14.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:47:14.898+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:47:14.898+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:47:15.851+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:47:15.845+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:47:15.852+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:47:15.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.994 seconds
[2025-05-28T10:47:46.100+0000] {processor.py:161} INFO - Started process (PID=5285) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:47:46.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:47:46.104+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:47:46.103+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:47:47.083+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:47:47.074+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:47:47.085+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:47:47.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.045 seconds
[2025-05-28T10:48:17.517+0000] {processor.py:161} INFO - Started process (PID=5303) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:48:17.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:48:17.520+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:48:17.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:48:18.551+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:48:18.543+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:48:18.552+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:48:18.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.077 seconds
[2025-05-28T10:48:48.946+0000] {processor.py:161} INFO - Started process (PID=5322) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:48:48.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:48:48.949+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:48:48.949+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:48:49.893+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:48:49.886+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:48:49.894+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:48:49.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.991 seconds
[2025-05-28T10:49:20.356+0000] {processor.py:161} INFO - Started process (PID=5340) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:49:20.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:49:20.360+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:49:20.359+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:49:21.980+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:49:21.973+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:49:21.982+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:49:22.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.686 seconds
[2025-05-28T10:49:52.115+0000] {processor.py:161} INFO - Started process (PID=5358) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:49:52.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:49:52.120+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:49:52.119+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:49:53.024+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:49:53.016+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:49:53.025+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:49:53.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.952 seconds
[2025-05-28T10:50:23.156+0000] {processor.py:161} INFO - Started process (PID=5376) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:50:23.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:50:23.159+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:50:23.159+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:50:24.175+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:50:24.168+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:50:24.177+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:50:24.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.057 seconds
[2025-05-28T10:50:54.415+0000] {processor.py:161} INFO - Started process (PID=5394) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:50:54.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:50:54.420+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:50:54.419+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:50:55.536+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:50:55.529+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:50:55.537+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:50:55.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.161 seconds
[2025-05-28T10:51:26.034+0000] {processor.py:161} INFO - Started process (PID=5412) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:51:26.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:51:26.038+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:51:26.038+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:51:27.029+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:51:27.021+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:51:27.031+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:51:27.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.044 seconds
[2025-05-28T10:51:57.486+0000] {processor.py:161} INFO - Started process (PID=5430) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:51:57.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:51:57.506+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:51:57.505+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:51:58.510+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:51:58.501+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:51:58.512+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:51:58.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.086 seconds
[2025-05-28T10:52:29.084+0000] {processor.py:161} INFO - Started process (PID=5448) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:52:29.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:52:29.087+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:52:29.087+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:52:30.042+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:52:30.035+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:52:30.044+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:52:30.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.012 seconds
[2025-05-28T10:53:00.595+0000] {processor.py:161} INFO - Started process (PID=5466) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:53:00.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:53:00.599+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:53:00.598+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:53:01.640+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:53:01.630+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:53:01.642+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:53:01.700+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.116 seconds
[2025-05-28T10:53:31.895+0000] {processor.py:161} INFO - Started process (PID=5485) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:53:31.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:53:31.900+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:53:31.899+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:53:32.984+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:53:32.976+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:53:32.985+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:53:33.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.132 seconds
[2025-05-28T10:54:03.486+0000] {processor.py:161} INFO - Started process (PID=5503) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:54:03.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:54:03.492+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:54:03.491+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:54:04.803+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:54:04.771+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:54:04.805+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:54:04.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.430 seconds
[2025-05-28T10:54:35.428+0000] {processor.py:161} INFO - Started process (PID=5520) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:54:35.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:54:35.431+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:54:35.430+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:54:36.576+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:54:36.570+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:54:36.577+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:54:36.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.187 seconds
[2025-05-28T10:55:06.794+0000] {processor.py:161} INFO - Started process (PID=5543) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:55:06.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:55:06.797+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:55:06.796+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:55:07.811+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:55:07.800+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:55:07.815+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:55:07.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.062 seconds
[2025-05-28T10:55:38.009+0000] {processor.py:161} INFO - Started process (PID=5561) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:55:38.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:55:38.013+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:55:38.012+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:55:39.140+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:55:39.133+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:55:39.141+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:55:39.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.172 seconds
[2025-05-28T10:56:09.614+0000] {processor.py:161} INFO - Started process (PID=5580) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:56:09.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:56:09.617+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:56:09.617+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:56:10.816+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:56:10.807+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:56:10.817+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:56:10.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.239 seconds
[2025-05-28T10:56:41.099+0000] {processor.py:161} INFO - Started process (PID=5598) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:56:41.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:56:41.102+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:56:41.102+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:56:42.172+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:56:42.164+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:56:42.175+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:56:42.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.126 seconds
[2025-05-28T10:57:12.296+0000] {processor.py:161} INFO - Started process (PID=5616) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:57:12.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:57:12.299+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:57:12.298+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:57:13.409+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:57:13.401+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:57:13.411+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:57:13.440+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.154 seconds
[2025-05-28T10:57:43.590+0000] {processor.py:161} INFO - Started process (PID=5634) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:57:43.593+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:57:43.595+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:57:43.595+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:57:44.488+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:57:44.480+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:57:44.490+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:57:44.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.963 seconds
[2025-05-28T10:58:14.798+0000] {processor.py:161} INFO - Started process (PID=5652) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:58:14.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:58:14.801+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:58:14.800+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:58:15.771+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:58:15.763+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:58:15.772+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:58:15.805+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.019 seconds
[2025-05-28T10:58:46.153+0000] {processor.py:161} INFO - Started process (PID=5671) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:58:46.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:58:46.156+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:58:46.156+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:58:47.099+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:58:47.087+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:58:47.101+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:58:47.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.016 seconds
[2025-05-28T10:59:17.630+0000] {processor.py:161} INFO - Started process (PID=5689) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:59:17.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:59:17.633+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:59:17.633+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:59:19.199+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:59:19.193+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:59:19.200+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:59:19.242+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.623 seconds
[2025-05-28T10:59:49.710+0000] {processor.py:161} INFO - Started process (PID=5707) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:59:49.711+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T10:59:49.713+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:59:49.712+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:59:50.666+0000] {logging_mixin.py:188} INFO - [2025-05-28T10:59:50.660+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T10:59:50.667+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T10:59:50.700+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.004 seconds
[2025-05-28T11:00:21.199+0000] {processor.py:161} INFO - Started process (PID=5725) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:00:21.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:00:21.203+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:00:21.203+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:00:22.574+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:00:22.567+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:00:22.575+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:00:22.605+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.419 seconds
[2025-05-28T11:00:52.889+0000] {processor.py:161} INFO - Started process (PID=5744) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:00:52.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:00:52.893+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:00:52.892+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:00:53.884+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:00:53.876+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:00:53.885+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:00:53.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.037 seconds
[2025-05-28T11:01:24.439+0000] {processor.py:161} INFO - Started process (PID=5766) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:01:24.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:01:24.444+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:01:24.443+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:01:26.366+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:01:26.360+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:01:26.368+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:01:26.403+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.980 seconds
[2025-05-28T11:01:56.503+0000] {processor.py:161} INFO - Started process (PID=5785) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:01:56.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:01:56.507+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:01:56.506+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:01:57.506+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:01:57.499+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:01:57.507+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:01:57.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.041 seconds
[2025-05-28T11:02:28.014+0000] {processor.py:161} INFO - Started process (PID=5803) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:02:28.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:02:28.022+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:02:28.021+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:02:29.170+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:02:29.162+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:02:29.171+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:02:29.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.203 seconds
[2025-05-28T11:02:59.667+0000] {processor.py:161} INFO - Started process (PID=5821) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:02:59.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:02:59.680+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:02:59.680+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:03:00.693+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:03:00.684+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:03:00.694+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:03:00.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.080 seconds
[2025-05-28T11:03:30.925+0000] {processor.py:161} INFO - Started process (PID=5839) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:03:30.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:03:30.929+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:03:30.928+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:03:31.728+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:03:31.720+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:03:31.730+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:03:31.751+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.840 seconds
[2025-05-28T11:04:02.007+0000] {processor.py:161} INFO - Started process (PID=5857) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:04:02.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:04:02.010+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:04:02.010+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:04:03.160+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:04:03.152+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:04:03.161+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:04:03.189+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.191 seconds
[2025-05-28T11:04:33.430+0000] {processor.py:161} INFO - Started process (PID=5875) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:04:33.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:04:33.434+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:04:33.433+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:04:34.514+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:04:34.507+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:04:34.516+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:04:34.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.130 seconds
[2025-05-28T11:05:04.814+0000] {processor.py:161} INFO - Started process (PID=5893) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:05:04.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:05:04.817+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:05:04.817+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:05:06.227+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:05:06.221+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:05:06.228+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:05:06.258+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.453 seconds
[2025-05-28T11:05:36.719+0000] {processor.py:161} INFO - Started process (PID=5911) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:05:36.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:05:36.722+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:05:36.721+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:05:37.702+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:05:37.694+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:05:37.704+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:05:37.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.037 seconds
[2025-05-28T11:06:08.005+0000] {processor.py:161} INFO - Started process (PID=5935) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:06:08.007+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:06:08.008+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:06:08.008+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:06:08.997+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:06:08.990+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:06:08.999+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:06:09.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.032 seconds
[2025-05-28T11:06:39.380+0000] {processor.py:161} INFO - Started process (PID=5954) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:06:39.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:06:39.383+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:06:39.383+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:06:40.407+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:06:40.400+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:06:40.408+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:06:40.431+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.059 seconds
[2025-05-28T11:07:10.755+0000] {processor.py:161} INFO - Started process (PID=5972) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:07:10.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:07:10.761+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:07:10.760+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:07:11.685+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:07:11.678+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:07:11.687+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:07:11.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.986 seconds
[2025-05-28T11:07:41.904+0000] {processor.py:161} INFO - Started process (PID=5990) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:07:41.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:07:41.908+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:07:41.907+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:07:42.865+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:07:42.859+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:07:42.867+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:07:42.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.011 seconds
[2025-05-28T11:08:13.121+0000] {processor.py:161} INFO - Started process (PID=6008) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:08:13.123+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:08:13.125+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:08:13.124+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:08:14.066+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:08:14.057+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:08:14.067+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:08:14.097+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.988 seconds
[2025-05-28T11:08:44.242+0000] {processor.py:161} INFO - Started process (PID=6026) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:08:44.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:08:44.245+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:08:44.244+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:08:45.308+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:08:45.301+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:08:45.309+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:08:45.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.116 seconds
[2025-05-28T11:09:15.636+0000] {processor.py:161} INFO - Started process (PID=6045) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:09:15.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:09:15.642+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:09:15.641+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:09:16.639+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:09:16.633+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:09:16.641+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:09:16.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.057 seconds
[2025-05-28T11:09:47.048+0000] {processor.py:161} INFO - Started process (PID=6063) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:09:47.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:09:47.062+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:09:47.058+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:09:50.516+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:09:50.503+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:09:50.520+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:09:50.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.556 seconds
[2025-05-28T11:10:21.282+0000] {processor.py:161} INFO - Started process (PID=6081) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:10:21.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:10:21.286+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:10:21.285+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:10:22.760+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:10:22.750+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:10:22.762+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:10:22.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.548 seconds
[2025-05-28T11:10:53.373+0000] {processor.py:161} INFO - Started process (PID=6099) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:10:53.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:10:53.377+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:10:53.377+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:10:54.252+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:10:54.246+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:10:54.254+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:10:54.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.919 seconds
[2025-05-28T11:11:24.465+0000] {processor.py:161} INFO - Started process (PID=6116) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:11:24.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:11:24.468+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:11:24.467+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:11:25.427+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:11:25.419+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:11:25.429+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:11:25.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.016 seconds
[2025-05-28T11:11:55.824+0000] {processor.py:161} INFO - Started process (PID=6134) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:11:55.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:11:55.834+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:11:55.828+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:11:57.057+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:11:57.051+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:11:57.059+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:11:57.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.289 seconds
[2025-05-28T11:12:27.369+0000] {processor.py:161} INFO - Started process (PID=6152) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:12:27.371+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:12:27.372+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:12:27.372+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:12:28.493+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:12:28.486+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:12:28.494+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:12:28.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.168 seconds
[2025-05-28T11:12:58.708+0000] {processor.py:161} INFO - Started process (PID=6170) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:12:58.711+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:12:58.713+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:12:58.712+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:12:59.756+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:12:59.751+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:12:59.757+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:12:59.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.094 seconds
[2025-05-28T11:13:30.070+0000] {processor.py:161} INFO - Started process (PID=6188) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:13:30.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:13:30.074+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:13:30.073+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:13:31.224+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:13:31.213+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:13:31.231+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:13:31.308+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.246 seconds
[2025-05-28T11:14:01.785+0000] {processor.py:161} INFO - Started process (PID=6206) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:14:01.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:14:01.788+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:14:01.787+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:14:03.034+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:14:03.019+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:14:03.036+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:14:03.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.317 seconds
[2025-05-28T11:14:33.323+0000] {processor.py:161} INFO - Started process (PID=6224) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:14:33.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:14:33.326+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:14:33.325+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:14:34.637+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:14:34.632+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:14:34.638+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:14:34.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.350 seconds
[2025-05-28T11:15:05.144+0000] {processor.py:161} INFO - Started process (PID=6242) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:15:05.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:15:05.149+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:15:05.148+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:15:07.252+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:15:07.245+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:15:07.253+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:15:07.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.170 seconds
[2025-05-28T11:15:37.698+0000] {processor.py:161} INFO - Started process (PID=6260) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:15:37.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:15:37.702+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:15:37.701+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:15:38.576+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:15:38.569+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:15:38.577+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:15:38.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.915 seconds
[2025-05-28T11:16:09.157+0000] {processor.py:161} INFO - Started process (PID=6278) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:16:09.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:16:09.160+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:16:09.160+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:16:10.144+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:16:10.138+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:16:10.145+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:16:10.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.026 seconds
[2025-05-28T11:16:40.410+0000] {processor.py:161} INFO - Started process (PID=6301) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:16:40.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:16:40.414+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:16:40.413+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:16:41.205+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:16:41.197+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:16:41.206+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:16:41.235+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.834 seconds
[2025-05-28T11:17:11.405+0000] {processor.py:161} INFO - Started process (PID=6319) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:17:11.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:17:11.408+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:17:11.407+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:17:12.420+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:17:12.412+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:17:12.422+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:17:12.450+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.053 seconds
[2025-05-28T11:17:42.572+0000] {processor.py:161} INFO - Started process (PID=6337) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:17:42.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:17:42.576+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:17:42.576+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:17:43.769+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:17:43.759+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:17:43.770+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:17:43.799+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.242 seconds
[2025-05-28T11:18:14.015+0000] {processor.py:161} INFO - Started process (PID=6355) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:18:14.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:18:14.018+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:18:14.018+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:18:14.830+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:18:14.824+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:18:14.832+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:18:14.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.854 seconds
[2025-05-28T11:18:45.158+0000] {processor.py:161} INFO - Started process (PID=6373) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:18:45.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:18:45.161+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:18:45.160+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:18:46.257+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:18:46.249+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:18:46.258+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:18:46.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.159 seconds
[2025-05-28T11:19:16.515+0000] {processor.py:161} INFO - Started process (PID=6391) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:19:16.517+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:19:16.519+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:19:16.518+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:19:17.552+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:19:17.543+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:19:17.553+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:19:17.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.075 seconds
[2025-05-28T11:19:47.882+0000] {processor.py:161} INFO - Started process (PID=6410) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:19:47.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:19:47.887+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:19:47.886+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:19:48.918+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:19:48.911+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:19:48.920+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:19:48.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.095 seconds
[2025-05-28T11:20:19.163+0000] {processor.py:161} INFO - Started process (PID=6428) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:20:19.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:20:19.167+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:20:19.167+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:20:20.257+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:20:20.245+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:20:20.262+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:20:20.296+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.148 seconds
[2025-05-28T11:20:50.791+0000] {processor.py:161} INFO - Started process (PID=6446) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:20:50.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:20:50.807+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:20:50.805+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:20:51.882+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:20:51.874+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:20:51.883+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:20:51.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.165 seconds
[2025-05-28T11:21:22.155+0000] {processor.py:161} INFO - Started process (PID=6464) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:21:22.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:21:22.159+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:21:22.159+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:21:23.055+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:21:23.048+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:21:23.056+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:21:23.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.941 seconds
[2025-05-28T11:21:53.648+0000] {processor.py:161} INFO - Started process (PID=6482) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:21:53.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:21:53.651+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:21:53.651+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:21:54.577+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:21:54.566+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:21:54.579+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:21:54.624+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.984 seconds
[2025-05-28T11:22:25.078+0000] {processor.py:161} INFO - Started process (PID=6500) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:22:25.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:22:25.082+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:22:25.082+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:22:26.305+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:22:26.296+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:22:26.306+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:22:26.369+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.304 seconds
[2025-05-28T11:22:56.926+0000] {processor.py:161} INFO - Started process (PID=6518) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:22:56.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:22:56.930+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:22:56.929+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:22:57.790+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:22:57.783+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:22:57.791+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:22:57.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.905 seconds
[2025-05-28T11:23:28.267+0000] {processor.py:161} INFO - Started process (PID=6536) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:23:28.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:23:28.271+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:23:28.271+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:23:29.087+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:23:29.078+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:23:29.088+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:23:29.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.860 seconds
[2025-05-28T11:23:59.599+0000] {processor.py:161} INFO - Started process (PID=6554) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:23:59.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:23:59.604+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:23:59.603+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:24:00.900+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:24:00.895+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:24:00.901+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:24:00.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.351 seconds
[2025-05-28T11:24:31.367+0000] {processor.py:161} INFO - Started process (PID=6572) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:24:31.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:24:31.370+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:24:31.370+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:24:32.255+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:24:32.247+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:24:32.257+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:24:32.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.928 seconds
[2025-05-28T11:25:02.450+0000] {processor.py:161} INFO - Started process (PID=6591) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:25:02.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:25:02.453+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:25:02.452+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:25:03.304+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:25:03.296+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:25:03.306+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:25:03.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.893 seconds
[2025-05-28T11:25:33.611+0000] {processor.py:161} INFO - Started process (PID=6610) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:25:33.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:25:33.616+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:25:33.615+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:25:34.988+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:25:34.981+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:25:34.990+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:25:35.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.430 seconds
[2025-05-28T11:26:05.556+0000] {processor.py:161} INFO - Started process (PID=6628) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:26:05.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:26:05.559+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:26:05.559+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:26:06.481+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:26:06.473+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:26:06.483+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:26:06.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.973 seconds
[2025-05-28T11:26:36.850+0000] {processor.py:161} INFO - Started process (PID=6646) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:26:36.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:26:36.854+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:26:36.853+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:26:37.884+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:26:37.875+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:26:37.886+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:26:37.944+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.102 seconds
[2025-05-28T11:27:08.108+0000] {processor.py:161} INFO - Started process (PID=6665) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:27:08.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:27:08.112+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:27:08.111+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:27:09.080+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:27:09.073+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:27:09.081+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:27:09.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.021 seconds
[2025-05-28T11:27:39.219+0000] {processor.py:161} INFO - Started process (PID=6683) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:27:39.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:27:39.222+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:27:39.222+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:27:40.438+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:27:40.430+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:27:40.439+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:27:40.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.260 seconds
[2025-05-28T11:28:10.589+0000] {processor.py:161} INFO - Started process (PID=6701) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:28:10.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:28:10.593+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:28:10.592+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:28:11.431+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:28:11.424+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:28:11.432+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:28:11.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.882 seconds
[2025-05-28T11:28:41.660+0000] {processor.py:161} INFO - Started process (PID=6726) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:28:41.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:28:41.665+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:28:41.664+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:28:42.755+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:28:42.747+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:28:42.757+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:28:42.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.148 seconds
[2025-05-28T11:29:13.099+0000] {processor.py:161} INFO - Started process (PID=6745) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:29:13.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:29:13.102+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:29:13.102+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:29:14.249+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:29:14.241+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:29:14.251+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:29:14.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.191 seconds
[2025-05-28T11:29:44.627+0000] {processor.py:161} INFO - Started process (PID=6763) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:29:44.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:29:44.631+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:29:44.630+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:29:45.698+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:29:45.690+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:29:45.700+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:29:45.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.129 seconds
[2025-05-28T11:30:15.956+0000] {processor.py:161} INFO - Started process (PID=6781) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:30:15.958+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:30:15.959+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:30:15.959+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:30:16.926+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:30:16.919+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:30:16.927+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:30:16.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.012 seconds
[2025-05-28T11:30:47.207+0000] {processor.py:161} INFO - Started process (PID=6799) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:30:47.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:30:47.211+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:30:47.210+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:30:48.473+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:30:48.467+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:30:48.475+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:30:48.504+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.310 seconds
[2025-05-28T11:31:18.928+0000] {processor.py:161} INFO - Started process (PID=6817) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:31:18.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:31:18.932+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:31:18.931+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:31:20.126+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:31:20.119+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:31:20.127+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:31:20.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.269 seconds
[2025-05-28T11:31:50.380+0000] {processor.py:161} INFO - Started process (PID=6835) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:31:50.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:31:50.383+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:31:50.383+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:31:51.520+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:31:51.515+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:31:51.521+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:31:51.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.177 seconds
[2025-05-28T11:32:21.867+0000] {processor.py:161} INFO - Started process (PID=6853) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:32:21.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:32:21.870+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:32:21.869+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:32:22.876+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:32:22.868+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:32:22.878+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:32:22.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.044 seconds
[2025-05-28T11:32:53.129+0000] {processor.py:161} INFO - Started process (PID=6871) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:32:53.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:32:53.133+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:32:53.132+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:32:54.026+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:32:54.019+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:32:54.027+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:32:54.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.946 seconds
[2025-05-28T11:33:24.318+0000] {processor.py:161} INFO - Started process (PID=6889) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:33:24.320+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:33:24.322+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:33:24.321+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:33:25.105+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:33:25.097+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:33:25.106+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:33:25.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.825 seconds
[2025-05-28T11:33:55.588+0000] {processor.py:161} INFO - Started process (PID=6908) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:33:55.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:33:55.592+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:33:55.591+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:33:56.622+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:33:56.614+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:33:56.624+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:33:56.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.072 seconds
[2025-05-28T11:34:27.118+0000] {processor.py:161} INFO - Started process (PID=6926) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:34:27.120+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:34:27.123+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:34:27.122+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:34:28.056+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:34:28.048+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:34:28.057+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:34:28.086+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.995 seconds
[2025-05-28T11:34:58.606+0000] {processor.py:161} INFO - Started process (PID=6944) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:34:58.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:34:58.609+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:34:58.609+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:34:59.411+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:34:59.403+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:34:59.412+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:34:59.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.836 seconds
[2025-05-28T11:35:29.849+0000] {processor.py:161} INFO - Started process (PID=6962) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:35:29.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:35:29.859+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:35:29.857+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:35:31.096+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:35:31.089+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:35:31.097+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:35:31.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.304 seconds
[2025-05-28T11:36:01.429+0000] {processor.py:161} INFO - Started process (PID=6981) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:36:01.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:36:01.433+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:36:01.432+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:36:02.494+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:36:02.488+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:36:02.495+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:36:02.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.106 seconds
[2025-05-28T11:36:32.719+0000] {processor.py:161} INFO - Started process (PID=6999) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:36:32.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:36:32.722+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:36:32.722+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:36:33.756+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:36:33.750+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:36:33.757+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:36:33.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.080 seconds
[2025-05-28T11:37:04.043+0000] {processor.py:161} INFO - Started process (PID=7017) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:37:04.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:37:04.046+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:37:04.046+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:37:04.902+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:37:04.895+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:37:04.903+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:37:04.934+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.900 seconds
[2025-05-28T11:37:35.783+0000] {processor.py:161} INFO - Started process (PID=7035) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:37:35.785+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:37:35.787+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:37:35.786+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:37:36.706+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:37:36.698+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:37:36.708+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:37:36.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.966 seconds
[2025-05-28T11:38:07.047+0000] {processor.py:161} INFO - Started process (PID=7052) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:38:07.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:38:07.050+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:38:07.050+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:38:07.893+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:38:07.885+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:38:07.894+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:38:07.933+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.895 seconds
[2025-05-28T11:38:38.184+0000] {processor.py:161} INFO - Started process (PID=7070) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:38:38.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:38:38.187+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:38:38.187+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:38:38.874+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:38:38.866+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:38:38.875+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:38:38.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.729 seconds
[2025-05-28T11:39:09.116+0000] {processor.py:161} INFO - Started process (PID=7088) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:39:09.118+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:39:09.120+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:39:09.119+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:39:09.880+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:39:09.873+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:39:09.881+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:39:09.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.806 seconds
[2025-05-28T11:39:40.427+0000] {processor.py:161} INFO - Started process (PID=7106) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:39:40.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:39:40.430+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:39:40.429+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:39:41.189+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:39:41.182+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:39:41.190+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:39:41.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.803 seconds
[2025-05-28T11:40:12.028+0000] {processor.py:161} INFO - Started process (PID=7124) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:40:12.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:40:12.034+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:40:12.033+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:40:12.811+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:40:12.805+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:40:12.813+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:40:12.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.837 seconds
[2025-05-28T11:40:43.645+0000] {processor.py:161} INFO - Started process (PID=7149) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:40:43.646+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:40:43.648+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:40:43.647+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:40:44.578+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:40:44.557+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:40:44.581+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:40:44.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.986 seconds
[2025-05-28T11:41:14.932+0000] {processor.py:161} INFO - Started process (PID=7168) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:41:14.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:41:14.936+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:41:14.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:41:15.755+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:41:15.741+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:41:15.758+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:41:15.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.909 seconds
[2025-05-28T11:41:46.502+0000] {processor.py:161} INFO - Started process (PID=7186) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:41:46.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:41:46.505+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:41:46.504+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:41:47.455+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:41:47.444+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:41:47.467+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:41:47.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.056 seconds
[2025-05-28T11:42:18.087+0000] {processor.py:161} INFO - Started process (PID=7204) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:42:18.088+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:42:18.090+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:42:18.090+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:42:18.985+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:42:18.977+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:42:18.986+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:42:19.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.940 seconds
[2025-05-28T11:42:49.638+0000] {processor.py:161} INFO - Started process (PID=7222) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:42:49.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:42:49.641+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:42:49.641+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:42:50.668+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:42:50.662+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:42:50.669+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:42:50.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.071 seconds
[2025-05-28T11:43:20.942+0000] {processor.py:161} INFO - Started process (PID=7241) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:43:20.944+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:43:20.946+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:43:20.946+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:43:21.849+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:43:21.841+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:43:21.850+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:43:21.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.953 seconds
[2025-05-28T11:43:52.375+0000] {processor.py:161} INFO - Started process (PID=7259) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:43:52.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:43:52.378+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:43:52.377+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:43:53.166+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:43:53.155+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:43:53.168+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:43:53.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.882 seconds
[2025-05-28T11:44:23.750+0000] {processor.py:161} INFO - Started process (PID=7277) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:44:23.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:44:23.753+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:44:23.753+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:44:24.725+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:44:24.715+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:44:24.727+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:44:24.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.030 seconds
[2025-05-28T11:44:55.243+0000] {processor.py:161} INFO - Started process (PID=7295) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:44:55.244+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:44:55.246+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:44:55.246+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:44:55.908+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:44:55.900+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:44:55.909+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:44:55.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.709 seconds
[2025-05-28T11:45:26.467+0000] {processor.py:161} INFO - Started process (PID=7313) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:45:26.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:45:26.470+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:45:26.469+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:45:27.126+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:45:27.119+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:45:27.127+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:45:27.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.694 seconds
[2025-05-28T11:45:57.711+0000] {processor.py:161} INFO - Started process (PID=7331) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:45:57.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:45:57.715+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:45:57.714+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:45:58.581+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:45:58.573+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:45:58.582+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:45:58.613+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.912 seconds
[2025-05-28T11:46:29.287+0000] {processor.py:161} INFO - Started process (PID=7350) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:46:29.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:46:29.290+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:46:29.290+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:46:29.962+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:46:29.955+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:46:29.964+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:46:29.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.717 seconds
[2025-05-28T11:47:00.434+0000] {processor.py:161} INFO - Started process (PID=7368) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:47:00.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:47:00.437+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:47:00.437+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:47:01.309+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:47:01.298+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:47:01.311+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:47:01.387+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.965 seconds
[2025-05-28T11:47:31.914+0000] {processor.py:161} INFO - Started process (PID=7386) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:47:31.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:47:31.922+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:47:31.920+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:47:32.976+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:47:32.969+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:47:32.978+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:47:33.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.131 seconds
[2025-05-28T11:48:03.206+0000] {processor.py:161} INFO - Started process (PID=7404) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:48:03.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:48:03.210+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:48:03.209+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:48:03.875+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:48:03.869+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:48:03.877+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:48:03.909+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.711 seconds
[2025-05-28T11:48:34.088+0000] {processor.py:161} INFO - Started process (PID=7422) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:48:34.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:48:34.091+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:48:34.091+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:48:34.745+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:48:34.738+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:48:34.747+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:48:34.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.727 seconds
[2025-05-28T11:49:05.009+0000] {processor.py:161} INFO - Started process (PID=7441) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:49:05.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:49:05.013+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:49:05.012+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:49:05.729+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:49:05.718+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:49:05.731+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:49:05.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.797 seconds
[2025-05-28T11:49:35.930+0000] {processor.py:161} INFO - Started process (PID=7459) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:49:35.932+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:49:35.934+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:49:35.933+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:49:36.820+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:49:36.812+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:49:36.822+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:49:36.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.934 seconds
[2025-05-28T11:50:07.654+0000] {processor.py:161} INFO - Started process (PID=7477) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:50:07.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:50:07.658+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:50:07.657+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:50:08.509+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:50:08.500+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:50:08.510+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:50:08.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.898 seconds
[2025-05-28T11:50:39.227+0000] {processor.py:161} INFO - Started process (PID=7495) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:50:39.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:50:39.230+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:50:39.230+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:50:40.090+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:50:40.083+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:50:40.092+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:50:40.123+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.904 seconds
[2025-05-28T11:51:10.602+0000] {processor.py:161} INFO - Started process (PID=7513) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:51:10.605+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:51:10.609+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:51:10.607+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:51:11.664+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:51:11.656+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:51:11.666+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:51:11.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.260 seconds
[2025-05-28T11:51:42.383+0000] {processor.py:161} INFO - Started process (PID=7531) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:51:42.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:51:42.386+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:51:42.386+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:51:43.210+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:51:43.201+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:51:43.211+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:51:43.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.866 seconds
[2025-05-28T11:52:13.721+0000] {processor.py:161} INFO - Started process (PID=7549) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:52:13.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:52:13.724+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:52:13.724+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:52:14.366+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:52:14.359+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:52:14.368+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:52:14.410+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.697 seconds
[2025-05-28T11:52:44.561+0000] {processor.py:161} INFO - Started process (PID=7567) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:52:44.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:52:44.565+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:52:44.564+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:52:45.861+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:52:45.853+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:52:45.863+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:52:45.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.351 seconds
[2025-05-28T11:53:16.483+0000] {processor.py:161} INFO - Started process (PID=7591) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:53:16.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:53:16.493+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:53:16.492+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:53:17.162+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:53:17.154+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:53:17.163+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:53:17.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.734 seconds
[2025-05-28T11:53:48.088+0000] {processor.py:161} INFO - Started process (PID=7609) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:53:48.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:53:48.092+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:53:48.092+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:53:49.063+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:53:49.055+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:53:49.064+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:53:49.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.016 seconds
[2025-05-28T11:54:19.573+0000] {processor.py:161} INFO - Started process (PID=7627) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:54:19.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:54:19.576+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:54:19.575+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:54:20.680+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:54:20.672+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:54:20.681+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:54:20.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.148 seconds
[2025-05-28T11:54:51.146+0000] {processor.py:161} INFO - Started process (PID=7645) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:54:51.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:54:51.151+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:54:51.150+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:54:51.861+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:54:51.852+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:54:51.862+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:54:51.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.768 seconds
[2025-05-28T11:55:22.374+0000] {processor.py:161} INFO - Started process (PID=7663) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:55:22.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:55:22.377+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:55:22.376+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:55:23.047+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:55:23.038+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:55:23.048+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:55:23.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.716 seconds
[2025-05-28T11:55:53.602+0000] {processor.py:161} INFO - Started process (PID=7681) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:55:53.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:55:53.606+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:55:53.605+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:55:54.471+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:55:54.462+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:55:54.473+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:55:54.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.908 seconds
[2025-05-28T11:56:24.607+0000] {processor.py:161} INFO - Started process (PID=7699) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:56:24.609+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:56:24.612+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:56:24.611+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:56:25.774+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:56:25.766+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:56:25.776+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:56:25.806+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.212 seconds
[2025-05-28T11:56:56.331+0000] {processor.py:161} INFO - Started process (PID=7717) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:56:56.332+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:56:56.334+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:56:56.333+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:56:57.155+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:56:57.147+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:56:57.156+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:56:57.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.869 seconds
[2025-05-28T11:57:28.010+0000] {processor.py:161} INFO - Started process (PID=7735) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:57:28.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:57:28.014+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:57:28.013+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:57:29.196+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:57:29.188+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:57:29.197+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:57:29.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.226 seconds
[2025-05-28T11:57:59.785+0000] {processor.py:161} INFO - Started process (PID=7753) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:57:59.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:57:59.794+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:57:59.793+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:58:00.940+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:58:00.930+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:58:00.942+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:58:00.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.203 seconds
[2025-05-28T11:58:31.098+0000] {processor.py:161} INFO - Started process (PID=7771) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:58:31.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:58:31.101+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:58:31.101+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:58:32.413+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:58:32.383+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:58:32.417+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:58:32.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.432 seconds
[2025-05-28T11:59:03.078+0000] {processor.py:161} INFO - Started process (PID=7790) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:59:03.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:59:03.082+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:59:03.082+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:59:04.179+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:59:04.172+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:59:04.182+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:59:04.214+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.155 seconds
[2025-05-28T11:59:34.617+0000] {processor.py:161} INFO - Started process (PID=7808) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:59:34.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T11:59:34.621+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:59:34.620+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:59:35.734+0000] {logging_mixin.py:188} INFO - [2025-05-28T11:59:35.727+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T11:59:35.735+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T11:59:35.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.162 seconds
[2025-05-28T12:00:06.075+0000] {processor.py:161} INFO - Started process (PID=7826) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:00:06.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:00:06.081+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:00:06.080+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:00:07.332+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:00:07.323+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:00:07.333+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:00:07.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.300 seconds
[2025-05-28T12:00:37.654+0000] {processor.py:161} INFO - Started process (PID=7844) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:00:37.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:00:37.669+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:00:37.668+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:00:39.061+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:00:39.053+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:00:39.062+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:00:39.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.461 seconds
[2025-05-28T12:01:09.218+0000] {processor.py:161} INFO - Started process (PID=7862) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:01:09.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:01:09.223+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:01:09.222+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:01:10.207+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:01:10.196+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:01:10.209+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:01:10.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.061 seconds
[2025-05-28T12:01:40.752+0000] {processor.py:161} INFO - Started process (PID=7886) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:01:40.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:01:40.755+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:01:40.755+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:01:41.914+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:01:41.908+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:01:41.915+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:01:41.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.199 seconds
[2025-05-28T12:02:12.144+0000] {processor.py:161} INFO - Started process (PID=7904) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:02:12.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:02:12.147+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:02:12.147+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:02:13.150+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:02:13.142+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:02:13.151+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:02:13.181+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.045 seconds
[2025-05-28T12:02:43.701+0000] {processor.py:161} INFO - Started process (PID=7922) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:02:43.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:02:43.706+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:02:43.705+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:02:44.890+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:02:44.885+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:02:44.891+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:02:44.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.230 seconds
[2025-05-28T12:03:15.400+0000] {processor.py:161} INFO - Started process (PID=7940) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:03:15.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:03:15.404+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:03:15.403+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:03:16.588+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:03:16.579+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:03:16.589+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:03:16.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.227 seconds
[2025-05-28T12:03:46.832+0000] {processor.py:161} INFO - Started process (PID=7958) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:03:46.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:03:46.836+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:03:46.835+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:03:48.092+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:03:48.085+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:03:48.093+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:03:48.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.303 seconds
[2025-05-28T12:04:18.325+0000] {processor.py:161} INFO - Started process (PID=7982) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:04:18.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:04:18.328+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:04:18.328+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:04:19.525+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:04:19.518+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:04:19.526+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:04:19.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.242 seconds
[2025-05-28T12:04:49.799+0000] {processor.py:161} INFO - Started process (PID=8000) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:04:49.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:04:49.804+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:04:49.803+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:04:50.832+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:04:50.825+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:04:50.834+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:04:50.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.079 seconds
[2025-05-28T12:05:21.315+0000] {processor.py:161} INFO - Started process (PID=8018) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:05:21.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:05:21.318+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:05:21.318+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:05:22.313+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:05:22.305+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:05:22.314+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:05:22.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.037 seconds
[2025-05-28T12:05:52.892+0000] {processor.py:161} INFO - Started process (PID=8035) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:05:52.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:05:52.896+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:05:52.895+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:05:53.915+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:05:53.907+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:05:53.916+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:05:53.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.064 seconds
[2025-05-28T12:06:24.570+0000] {processor.py:161} INFO - Started process (PID=8053) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:06:24.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:06:24.576+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:06:24.575+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:06:25.443+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:06:25.434+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:06:25.444+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:06:25.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.934 seconds
[2025-05-28T12:06:55.953+0000] {processor.py:161} INFO - Started process (PID=8071) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:06:55.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:06:55.957+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:06:55.957+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:06:56.896+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:06:56.888+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:06:56.897+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:06:56.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.988 seconds
[2025-05-28T12:07:27.010+0000] {processor.py:161} INFO - Started process (PID=8088) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:07:27.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:07:27.014+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:07:27.013+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:07:27.836+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:07:27.828+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:07:27.837+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:07:27.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.867 seconds
[2025-05-28T12:07:58.961+0000] {processor.py:161} INFO - Started process (PID=8107) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:07:58.964+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:07:58.974+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:07:58.973+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:08:00.047+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:08:00.038+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:08:00.048+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:08:00.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.139 seconds
[2025-05-28T12:08:30.362+0000] {processor.py:161} INFO - Started process (PID=8125) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:08:30.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:08:30.365+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:08:30.365+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:08:31.599+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:08:31.590+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:08:31.600+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:08:31.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.274 seconds
[2025-05-28T12:09:01.774+0000] {processor.py:161} INFO - Started process (PID=8143) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:09:01.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:09:01.779+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:09:01.778+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:09:03.158+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:09:03.152+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:09:03.160+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:09:03.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.431 seconds
[2025-05-28T12:09:33.622+0000] {processor.py:161} INFO - Started process (PID=8161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:09:33.623+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:09:33.625+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:09:33.625+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:09:34.812+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:09:34.806+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:09:34.813+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:09:34.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.224 seconds
[2025-05-28T12:10:05.052+0000] {processor.py:161} INFO - Started process (PID=8180) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:10:05.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:10:05.058+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:10:05.057+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:10:06.789+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:10:06.774+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:10:06.792+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:10:06.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.838 seconds
[2025-05-28T12:10:37.007+0000] {processor.py:161} INFO - Started process (PID=8199) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:10:37.009+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:10:37.011+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:10:37.010+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:10:37.807+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:10:37.798+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:10:37.808+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:10:37.843+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.844 seconds
[2025-05-28T12:11:08.064+0000] {processor.py:161} INFO - Started process (PID=8218) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:11:08.066+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:11:08.068+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:11:08.067+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:11:09.161+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:11:09.153+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:11:09.162+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:11:09.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.143 seconds
[2025-05-28T12:11:39.670+0000] {processor.py:161} INFO - Started process (PID=8236) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:11:39.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:11:39.675+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:11:39.674+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:11:40.686+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:11:40.681+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:11:40.687+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:11:40.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.062 seconds
[2025-05-28T12:12:10.886+0000] {processor.py:161} INFO - Started process (PID=8254) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:12:10.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:12:10.890+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:12:10.889+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:12:11.707+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:12:11.700+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:12:11.708+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:12:11.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.857 seconds
[2025-05-28T12:12:42.609+0000] {processor.py:161} INFO - Started process (PID=8272) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:12:42.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:12:42.613+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:12:42.613+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:12:43.586+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:12:43.580+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:12:43.588+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:12:43.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.025 seconds
[2025-05-28T12:13:13.928+0000] {processor.py:161} INFO - Started process (PID=8291) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:13:13.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:13:13.931+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:13:13.931+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:13:14.788+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:13:14.779+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:13:14.789+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:13:14.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.902 seconds
[2025-05-28T12:13:45.304+0000] {processor.py:161} INFO - Started process (PID=8309) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:13:45.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:13:45.309+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:13:45.308+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:13:46.362+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:13:46.327+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:13:46.365+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:13:46.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.169 seconds
[2025-05-28T12:14:17.017+0000] {processor.py:161} INFO - Started process (PID=8327) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:14:17.029+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:14:17.037+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:14:17.036+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:14:18.151+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:14:18.146+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:14:18.152+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:14:18.181+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.182 seconds
[2025-05-28T12:14:48.368+0000] {processor.py:161} INFO - Started process (PID=8345) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:14:48.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:14:48.371+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:14:48.371+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:14:50.105+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:14:50.099+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:14:50.106+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:14:50.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.781 seconds
[2025-05-28T12:15:20.662+0000] {processor.py:161} INFO - Started process (PID=8369) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:15:20.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:15:20.668+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:15:20.667+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:15:21.589+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:15:21.581+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:15:21.590+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:15:21.622+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.980 seconds
[2025-05-28T12:15:51.750+0000] {processor.py:161} INFO - Started process (PID=8387) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:15:51.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:15:51.753+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:15:51.753+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:15:52.690+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:15:52.683+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:15:52.692+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:15:52.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.979 seconds
[2025-05-28T12:16:23.249+0000] {processor.py:161} INFO - Started process (PID=8404) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:16:23.251+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:16:23.252+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:16:23.252+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:16:24.274+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:16:24.265+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:16:24.276+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:16:24.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.131 seconds
[2025-05-28T12:16:55.030+0000] {processor.py:161} INFO - Started process (PID=8422) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:16:55.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:16:55.049+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:16:55.048+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:16:56.041+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:16:56.033+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:16:56.042+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:16:56.071+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.119 seconds
[2025-05-28T12:17:26.335+0000] {processor.py:161} INFO - Started process (PID=8441) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:17:26.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:17:26.338+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:17:26.338+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:17:27.355+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:17:27.347+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:17:27.357+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:17:27.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.055 seconds
[2025-05-28T12:17:57.932+0000] {processor.py:161} INFO - Started process (PID=8459) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:17:57.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:17:57.935+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:17:57.934+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:17:58.722+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:17:58.715+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:17:58.725+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:17:58.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.863 seconds
[2025-05-28T12:18:29.172+0000] {processor.py:161} INFO - Started process (PID=8477) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:18:29.174+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:18:29.175+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:18:29.175+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:18:30.411+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:18:30.403+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:18:30.413+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:18:30.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.278 seconds
[2025-05-28T12:19:00.544+0000] {processor.py:161} INFO - Started process (PID=8494) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:19:00.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:19:00.547+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:19:00.547+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:19:01.308+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:19:01.301+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:19:01.309+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:19:01.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.804 seconds
[2025-05-28T12:19:31.737+0000] {processor.py:161} INFO - Started process (PID=8512) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:19:31.739+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:19:31.741+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:19:31.740+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:19:32.662+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:19:32.655+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:19:32.666+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:19:32.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.967 seconds
[2025-05-28T12:20:02.823+0000] {processor.py:161} INFO - Started process (PID=8530) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:20:02.825+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:20:02.828+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:20:02.827+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:20:03.996+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:20:03.976+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:20:03.998+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:20:04.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.263 seconds
[2025-05-28T12:20:34.661+0000] {processor.py:161} INFO - Started process (PID=8549) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:20:34.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:20:34.665+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:20:34.664+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:20:35.516+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:20:35.508+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:20:35.517+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:20:35.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.899 seconds
[2025-05-28T12:21:05.746+0000] {processor.py:161} INFO - Started process (PID=8567) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:21:05.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:21:05.749+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:21:05.749+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:21:06.524+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:21:06.517+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:21:06.526+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:21:06.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.810 seconds
[2025-05-28T12:21:36.763+0000] {processor.py:161} INFO - Started process (PID=8585) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:21:36.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:21:36.766+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:21:36.766+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:21:37.734+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:21:37.725+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:21:37.735+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:21:37.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.010 seconds
[2025-05-28T12:22:07.971+0000] {processor.py:161} INFO - Started process (PID=8602) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:22:07.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:22:07.974+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:22:07.974+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:22:09.112+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:22:09.098+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:22:09.116+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:22:09.153+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.192 seconds
[2025-05-28T12:22:39.352+0000] {processor.py:161} INFO - Started process (PID=8620) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:22:39.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:22:39.356+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:22:39.355+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:22:40.375+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:22:40.367+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:22:40.376+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:22:40.405+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.063 seconds
[2025-05-28T12:23:10.764+0000] {processor.py:161} INFO - Started process (PID=8638) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:23:10.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:23:10.768+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:23:10.768+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:23:11.534+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:23:11.527+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:23:11.536+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:23:11.558+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.803 seconds
[2025-05-28T12:23:42.048+0000] {processor.py:161} INFO - Started process (PID=8656) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:23:42.049+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:23:42.051+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:23:42.050+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:23:43.251+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:23:43.243+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:23:43.253+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:23:43.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.242 seconds
[2025-05-28T12:24:13.423+0000] {processor.py:161} INFO - Started process (PID=8674) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:24:13.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:24:13.427+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:24:13.427+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:24:14.235+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:24:14.227+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:24:14.237+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:24:14.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.863 seconds
[2025-05-28T12:24:44.591+0000] {processor.py:161} INFO - Started process (PID=8692) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:24:44.593+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:24:44.594+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:24:44.594+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:24:45.523+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:24:45.514+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:24:45.525+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:24:45.562+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.984 seconds
[2025-05-28T12:25:15.806+0000] {processor.py:161} INFO - Started process (PID=8710) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:25:15.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:25:15.817+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:25:15.814+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:25:17.356+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:25:17.350+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:25:17.357+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:25:17.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.610 seconds
[2025-05-28T12:25:47.600+0000] {processor.py:161} INFO - Started process (PID=8728) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:25:47.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:25:47.603+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:25:47.602+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:25:48.658+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:25:48.653+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:25:48.660+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:25:48.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.098 seconds
[2025-05-28T12:26:18.866+0000] {processor.py:161} INFO - Started process (PID=8746) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:26:18.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:26:18.869+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:26:18.869+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:26:19.676+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:26:19.668+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:26:19.678+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:26:19.708+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.851 seconds
[2025-05-28T12:26:50.231+0000] {processor.py:161} INFO - Started process (PID=8764) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:26:50.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:26:50.235+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:26:50.234+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:26:51.299+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:26:51.289+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:26:51.301+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:26:51.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.127 seconds
[2025-05-28T12:27:21.434+0000] {processor.py:161} INFO - Started process (PID=8789) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:27:21.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:27:21.438+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:27:21.437+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:27:22.452+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:27:22.445+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:27:22.454+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:27:22.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.060 seconds
[2025-05-28T12:27:53.071+0000] {processor.py:161} INFO - Started process (PID=8807) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:27:53.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:27:53.074+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:27:53.073+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:27:53.882+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:27:53.875+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:27:53.883+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:27:53.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.854 seconds
[2025-05-28T12:28:24.449+0000] {processor.py:161} INFO - Started process (PID=8825) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:28:24.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:28:24.452+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:28:24.452+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:28:25.285+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:28:25.278+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:28:25.287+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:28:25.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.869 seconds
[2025-05-28T12:28:55.737+0000] {processor.py:161} INFO - Started process (PID=8843) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:28:55.739+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:28:55.741+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:28:55.740+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:28:56.817+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:28:56.810+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:28:56.818+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:28:56.849+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.119 seconds
[2025-05-28T12:29:27.427+0000] {processor.py:161} INFO - Started process (PID=8861) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:29:27.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:29:27.431+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:29:27.430+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:29:28.323+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:29:28.315+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:29:28.326+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:29:28.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.937 seconds
[2025-05-28T12:29:58.827+0000] {processor.py:161} INFO - Started process (PID=8879) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:29:58.828+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:29:58.830+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:29:58.830+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:30:00.142+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:30:00.019+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:30:00.152+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:30:00.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.427 seconds
[2025-05-28T12:30:30.607+0000] {processor.py:161} INFO - Started process (PID=8897) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:30:30.609+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:30:30.612+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:30:30.611+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:30:31.850+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:30:31.844+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:30:31.851+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:30:31.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.289 seconds
[2025-05-28T12:31:02.364+0000] {processor.py:161} INFO - Started process (PID=8915) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:31:02.365+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:31:02.368+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:31:02.367+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:31:03.522+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:31:03.517+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:31:03.524+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:31:03.557+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.202 seconds
[2025-05-28T12:31:33.831+0000] {processor.py:161} INFO - Started process (PID=8933) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:31:33.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:31:33.835+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:31:33.834+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:31:34.820+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:31:34.815+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:31:34.821+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:31:34.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.028 seconds
[2025-05-28T12:32:05.274+0000] {processor.py:161} INFO - Started process (PID=8952) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:32:05.277+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:32:05.280+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:32:05.279+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:32:06.316+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:32:06.308+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:32:06.317+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:32:06.345+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.091 seconds
[2025-05-28T12:32:36.810+0000] {processor.py:161} INFO - Started process (PID=8970) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:32:36.812+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:32:36.813+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:32:36.813+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:32:37.806+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:32:37.799+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:32:37.808+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:32:37.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.039 seconds
[2025-05-28T12:33:08.182+0000] {processor.py:161} INFO - Started process (PID=8989) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:33:08.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:33:08.185+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:33:08.184+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:33:09.203+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:33:09.194+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:33:09.206+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:33:09.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.076 seconds
[2025-05-28T12:33:39.635+0000] {processor.py:161} INFO - Started process (PID=9007) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:33:39.636+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:33:39.638+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:33:39.637+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:33:40.676+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:33:40.670+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:33:40.677+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:33:40.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.083 seconds
[2025-05-28T12:34:11.157+0000] {processor.py:161} INFO - Started process (PID=9026) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:34:11.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:34:11.161+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:34:11.160+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:34:11.958+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:34:11.950+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:34:11.959+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:34:11.989+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.845 seconds
[2025-05-28T12:34:42.327+0000] {processor.py:161} INFO - Started process (PID=9044) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:34:42.329+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:34:42.331+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:34:42.330+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:34:43.130+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:34:43.123+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:34:43.132+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:34:43.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.841 seconds
[2025-05-28T12:35:13.445+0000] {processor.py:161} INFO - Started process (PID=9062) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:35:13.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:35:13.450+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:35:13.449+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:35:14.304+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:35:14.295+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:35:14.305+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:35:14.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.902 seconds
[2025-05-28T12:35:44.769+0000] {processor.py:161} INFO - Started process (PID=9080) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:35:44.771+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:35:44.773+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:35:44.772+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:35:46.048+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:35:46.041+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:35:46.050+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:35:46.083+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.323 seconds
[2025-05-28T12:36:16.370+0000] {processor.py:161} INFO - Started process (PID=9097) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:36:16.378+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:36:16.388+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:36:16.387+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:36:17.518+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:36:17.511+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:36:17.520+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:36:17.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.215 seconds
[2025-05-28T12:36:48.021+0000] {processor.py:161} INFO - Started process (PID=9115) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:36:48.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:36:48.026+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:36:48.025+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:36:49.161+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:36:49.154+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:36:49.163+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:36:49.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.213 seconds
[2025-05-28T12:37:19.501+0000] {processor.py:161} INFO - Started process (PID=9132) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:37:19.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:37:19.504+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:37:19.504+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:37:20.543+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:37:20.535+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:37:20.545+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:37:20.576+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.083 seconds
[2025-05-28T12:37:50.976+0000] {processor.py:161} INFO - Started process (PID=9150) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:37:50.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:37:50.980+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:37:50.979+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:37:52.163+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:37:52.157+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:37:52.164+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:37:52.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.238 seconds
[2025-05-28T12:38:22.671+0000] {processor.py:161} INFO - Started process (PID=9175) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:38:22.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:38:22.674+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:38:22.674+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:38:23.633+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:38:23.610+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:38:23.635+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:38:23.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.043 seconds
[2025-05-28T12:38:54.254+0000] {processor.py:161} INFO - Started process (PID=9193) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:38:54.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:38:54.260+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:38:54.259+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:38:55.191+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:38:55.184+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:38:55.192+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:38:55.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.985 seconds
[2025-05-28T12:39:25.465+0000] {processor.py:161} INFO - Started process (PID=9212) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:39:25.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:39:25.468+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:39:25.467+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:39:26.282+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:39:26.274+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:39:26.284+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:39:26.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.852 seconds
[2025-05-28T12:39:56.525+0000] {processor.py:161} INFO - Started process (PID=9230) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:39:56.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:39:56.528+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:39:56.528+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:39:57.351+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:39:57.343+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:39:57.352+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:39:57.383+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.866 seconds
[2025-05-28T12:40:27.682+0000] {processor.py:161} INFO - Started process (PID=9248) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:40:27.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:40:27.686+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:40:27.685+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:40:28.668+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:40:28.661+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:40:28.669+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:40:28.699+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.025 seconds
[2025-05-28T12:40:58.894+0000] {processor.py:161} INFO - Started process (PID=9265) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:40:58.896+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:40:58.897+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:40:58.897+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:41:00.441+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:41:00.433+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:41:00.443+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:41:00.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.588 seconds
[2025-05-28T12:41:30.669+0000] {processor.py:161} INFO - Started process (PID=9283) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:41:30.670+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:41:30.672+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:41:30.672+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:41:31.892+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:41:31.886+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:41:31.893+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:41:31.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.265 seconds
[2025-05-28T12:42:02.134+0000] {processor.py:161} INFO - Started process (PID=9301) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:42:02.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:42:02.138+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:42:02.137+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:42:03.006+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:42:02.998+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:42:03.007+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:42:03.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.904 seconds
[2025-05-28T12:42:33.444+0000] {processor.py:161} INFO - Started process (PID=9319) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:42:33.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:42:33.447+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:42:33.446+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:42:34.750+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:42:34.742+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:42:34.751+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:42:34.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.346 seconds
[2025-05-28T12:43:05.138+0000] {processor.py:161} INFO - Started process (PID=9337) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:43:05.141+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:43:05.144+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:43:05.143+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:43:06.113+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:43:06.105+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:43:06.114+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:43:06.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.023 seconds
[2025-05-28T12:43:36.640+0000] {processor.py:161} INFO - Started process (PID=9355) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:43:36.642+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:43:36.643+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:43:36.643+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:43:37.575+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:43:37.568+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:43:37.576+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:43:37.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.972 seconds
[2025-05-28T12:44:08.202+0000] {processor.py:161} INFO - Started process (PID=9373) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:44:08.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:44:08.207+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:44:08.206+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:44:09.437+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:44:09.429+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:44:09.438+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:44:09.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.281 seconds
[2025-05-28T12:44:39.943+0000] {processor.py:161} INFO - Started process (PID=9392) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:44:39.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:44:39.950+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:44:39.949+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:44:41.054+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:44:41.047+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:44:41.056+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:44:41.097+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.176 seconds
[2025-05-28T12:45:11.328+0000] {processor.py:161} INFO - Started process (PID=9410) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:45:11.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:45:11.332+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:45:11.331+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:45:12.141+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:45:12.135+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:45:12.143+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:45:12.171+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.853 seconds
[2025-05-28T12:45:42.383+0000] {processor.py:161} INFO - Started process (PID=9428) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:45:42.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:45:42.386+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:45:42.386+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:45:43.151+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:45:43.143+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:45:43.153+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:45:43.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.800 seconds
[2025-05-28T12:46:13.302+0000] {processor.py:161} INFO - Started process (PID=9447) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:46:13.304+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:46:13.306+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:46:13.305+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:46:14.721+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:46:14.714+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:46:14.723+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:46:14.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.473 seconds
[2025-05-28T12:46:45.223+0000] {processor.py:161} INFO - Started process (PID=9465) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:46:45.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:46:45.226+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:46:45.225+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:46:46.206+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:46:46.199+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:46:46.207+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:46:46.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.040 seconds
[2025-05-28T12:47:16.596+0000] {processor.py:161} INFO - Started process (PID=9483) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:47:16.599+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:47:16.601+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:47:16.600+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:47:17.544+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:47:17.535+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:47:17.545+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:47:17.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.987 seconds
[2025-05-28T12:47:47.942+0000] {processor.py:161} INFO - Started process (PID=9502) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:47:47.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:47:47.945+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:47:47.944+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:47:49.163+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:47:49.156+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:47:49.164+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:47:49.195+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.262 seconds
[2025-05-28T12:48:19.743+0000] {processor.py:161} INFO - Started process (PID=9520) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:48:19.745+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:48:19.746+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:48:19.746+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:48:20.583+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:48:20.576+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:48:20.585+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:48:20.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.879 seconds
[2025-05-28T12:48:51.309+0000] {processor.py:161} INFO - Started process (PID=9538) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:48:51.311+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:48:51.313+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:48:51.312+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:48:52.675+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:48:52.667+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:48:52.677+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:48:52.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.417 seconds
[2025-05-28T12:49:23.160+0000] {processor.py:161} INFO - Started process (PID=9556) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:49:23.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:49:23.165+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:49:23.164+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:49:24.106+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:49:24.098+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:49:24.108+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:49:24.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.992 seconds
[2025-05-28T12:49:54.802+0000] {processor.py:161} INFO - Started process (PID=9580) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:49:54.804+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:49:54.806+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:49:54.805+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:49:55.626+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:49:55.619+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:49:55.627+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:49:55.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.866 seconds
[2025-05-28T12:50:26.176+0000] {processor.py:161} INFO - Started process (PID=9599) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:50:26.177+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:50:26.179+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:50:26.178+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:50:26.975+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:50:26.967+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:50:26.977+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:50:27.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.871 seconds
[2025-05-28T12:50:57.740+0000] {processor.py:161} INFO - Started process (PID=9618) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:50:57.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:50:57.746+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:50:57.745+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:50:58.820+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:50:58.812+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:50:58.821+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:50:58.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.139 seconds
[2025-05-28T12:51:29.338+0000] {processor.py:161} INFO - Started process (PID=9636) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:51:29.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:51:29.342+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:51:29.341+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:51:30.114+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:51:30.105+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:51:30.116+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:51:30.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.831 seconds
[2025-05-28T12:52:00.633+0000] {processor.py:161} INFO - Started process (PID=9654) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:52:00.635+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:52:00.637+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:52:00.636+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:52:01.619+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:52:01.600+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:52:01.622+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:52:01.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.071 seconds
[2025-05-28T12:52:32.220+0000] {processor.py:161} INFO - Started process (PID=9672) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:52:32.222+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:52:32.225+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:52:32.224+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:52:32.953+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:52:32.945+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:52:32.955+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:52:32.986+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.782 seconds
[2025-05-28T12:53:03.533+0000] {processor.py:161} INFO - Started process (PID=9690) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:53:03.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:53:03.536+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:53:03.536+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:53:04.187+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:53:04.180+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:53:04.189+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:53:04.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.696 seconds
[2025-05-28T12:53:34.712+0000] {processor.py:161} INFO - Started process (PID=9708) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:53:34.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:53:34.716+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:53:34.715+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:53:35.399+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:53:35.391+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:53:35.401+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:53:35.431+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.732 seconds
[2025-05-28T12:54:05.869+0000] {processor.py:161} INFO - Started process (PID=9726) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:54:05.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:54:05.872+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:54:05.871+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:54:06.813+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:54:06.807+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:54:06.814+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:54:06.849+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.988 seconds
[2025-05-28T12:54:37.320+0000] {processor.py:161} INFO - Started process (PID=9745) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:54:37.322+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:54:37.324+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:54:37.323+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:54:38.032+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:54:38.023+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:54:38.033+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:54:38.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.756 seconds
[2025-05-28T12:55:08.545+0000] {processor.py:161} INFO - Started process (PID=9763) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:55:08.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:55:08.549+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:55:08.548+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:55:09.380+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:55:09.373+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:55:09.381+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:55:09.413+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.876 seconds
[2025-05-28T12:55:40.192+0000] {processor.py:161} INFO - Started process (PID=9782) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:55:40.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:55:40.195+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:55:40.194+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:55:40.841+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:55:40.832+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:55:40.843+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:55:40.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.683 seconds
[2025-05-28T12:56:11.355+0000] {processor.py:161} INFO - Started process (PID=9800) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:56:11.357+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:56:11.362+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:56:11.359+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:56:12.393+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:56:12.384+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:56:12.394+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:56:12.419+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.083 seconds
[2025-05-28T12:56:42.881+0000] {processor.py:161} INFO - Started process (PID=9818) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:56:42.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:56:42.885+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:56:42.885+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:56:43.594+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:56:43.588+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:56:43.596+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:56:43.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.764 seconds
[2025-05-28T12:57:13.780+0000] {processor.py:161} INFO - Started process (PID=9837) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:57:13.781+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:57:13.783+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:57:13.782+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:57:14.825+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:57:14.814+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:57:14.827+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:57:14.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.111 seconds
[2025-05-28T12:57:45.410+0000] {processor.py:161} INFO - Started process (PID=9855) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:57:45.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:57:45.414+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:57:45.413+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:57:46.104+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:57:46.097+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:57:46.105+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:57:46.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.748 seconds
[2025-05-28T12:58:16.699+0000] {processor.py:161} INFO - Started process (PID=9873) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:58:16.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:58:16.702+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:58:16.702+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:58:17.648+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:58:17.642+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:58:17.649+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:58:17.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.001 seconds
[2025-05-28T12:58:47.884+0000] {processor.py:161} INFO - Started process (PID=9891) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:58:47.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:58:47.892+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:58:47.891+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:58:49.322+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:58:49.312+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:58:49.324+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:58:49.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.492 seconds
[2025-05-28T12:59:19.722+0000] {processor.py:161} INFO - Started process (PID=9910) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:59:19.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:59:19.737+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:59:19.736+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:59:21.610+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:59:21.602+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:59:21.613+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:59:21.655+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.964 seconds
[2025-05-28T12:59:52.472+0000] {processor.py:161} INFO - Started process (PID=9927) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:59:52.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T12:59:52.478+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:59:52.477+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:59:54.327+0000] {logging_mixin.py:188} INFO - [2025-05-28T12:59:54.252+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T12:59:54.336+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T12:59:54.455+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.997 seconds
[2025-05-28T13:00:26.626+0000] {processor.py:161} INFO - Started process (PID=9946) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:00:26.632+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:00:26.637+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:00:26.636+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:00:33.174+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:00:32.869+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:00:33.243+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:00:33.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.852 seconds
[2025-05-28T13:01:06.916+0000] {processor.py:161} INFO - Started process (PID=9971) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:01:06.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:01:06.936+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:01:06.934+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:01:15.579+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:01:13.723+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:01:15.594+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:01:15.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 8.851 seconds
[2025-05-28T13:01:46.584+0000] {processor.py:161} INFO - Started process (PID=9988) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:01:46.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:01:46.589+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:01:46.588+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:01:53.057+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:01:52.999+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:01:53.069+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:01:53.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.689 seconds
[2025-05-28T13:08:35.837+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:08:35.847+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:08:35.859+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:08:35.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:08:41.578+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:08:41.561+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:08:41.580+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:08:41.622+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.799 seconds
[2025-05-28T13:09:12.088+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:09:12.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:09:12.093+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:09:12.093+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:09:13.808+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:09:13.799+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:09:13.809+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:09:13.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.770 seconds
[2025-05-28T13:09:44.106+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:09:44.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:09:44.110+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:09:44.110+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:09:45.555+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:09:45.550+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:09:45.556+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:09:45.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.496 seconds
[2025-05-28T13:10:16.205+0000] {processor.py:161} INFO - Started process (PID=233) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:10:16.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:10:16.210+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:10:16.209+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:10:17.116+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:10:17.109+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:10:17.118+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:10:17.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.953 seconds
[2025-05-28T13:10:47.342+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:10:47.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:10:47.348+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:10:47.347+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:10:48.595+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:10:48.587+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:10:48.597+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:10:48.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.298 seconds
[2025-05-28T13:11:19.155+0000] {processor.py:161} INFO - Started process (PID=276) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:11:19.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:11:19.163+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:11:19.161+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:11:20.105+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:11:20.097+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:11:20.106+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:11:20.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.002 seconds
[2025-05-28T13:11:50.304+0000] {processor.py:161} INFO - Started process (PID=294) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:11:50.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:11:50.310+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:11:50.310+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:11:51.358+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:11:51.352+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:11:51.359+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:11:51.390+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.100 seconds
[2025-05-28T13:12:21.728+0000] {processor.py:161} INFO - Started process (PID=312) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:12:21.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:12:21.736+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:12:21.735+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:12:23.150+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:12:23.135+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:12:23.153+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:12:23.213+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.508 seconds
[2025-05-28T13:12:54.120+0000] {processor.py:161} INFO - Started process (PID=330) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:12:54.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:12:54.133+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:12:54.130+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:12:55.838+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:12:55.820+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:12:55.841+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:12:55.909+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.831 seconds
[2025-05-28T13:13:26.246+0000] {processor.py:161} INFO - Started process (PID=348) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:13:26.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:13:26.254+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:13:26.253+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:13:28.489+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:13:28.480+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:13:28.491+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:13:28.534+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.302 seconds
[2025-05-28T13:13:59.553+0000] {processor.py:161} INFO - Started process (PID=366) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:13:59.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:13:59.564+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:13:59.563+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:14:01.571+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:14:01.547+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:14:01.590+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:14:01.666+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.157 seconds
[2025-05-28T13:14:32.403+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:14:32.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:14:32.421+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:14:32.418+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:14:34.679+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:14:34.672+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:14:34.681+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:14:34.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.367 seconds
[2025-05-28T13:15:05.191+0000] {processor.py:161} INFO - Started process (PID=402) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:15:05.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:15:05.197+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:15:05.196+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:15:06.797+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:15:06.789+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:15:06.799+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:15:06.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.672 seconds
[2025-05-28T13:15:37.558+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:15:37.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:15:37.567+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:15:37.566+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:15:39.458+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:15:39.452+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:15:39.460+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:15:39.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.956 seconds
[2025-05-28T13:16:09.682+0000] {processor.py:161} INFO - Started process (PID=437) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:16:09.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:16:09.698+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:16:09.697+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:16:11.262+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:16:11.248+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:16:11.265+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:16:11.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.716 seconds
[2025-05-28T13:16:41.853+0000] {processor.py:161} INFO - Started process (PID=455) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:16:41.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:16:41.860+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:16:41.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:16:43.228+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:16:43.218+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:16:43.229+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:16:43.270+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.437 seconds
[2025-05-28T13:17:13.889+0000] {processor.py:161} INFO - Started process (PID=473) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:17:13.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:17:13.895+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:17:13.894+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:17:16.999+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:17:16.979+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2025-05-28T13:17:17.016+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:17:17.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.249 seconds
[2025-05-28T13:24:07.957+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:24:07.968+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:24:07.983+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:24:07.981+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:24:14.645+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:24:15.129+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:24:15.128+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:24:15.167+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:24:15.167+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:24:15.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 7.294 seconds
[2025-05-28T13:24:45.392+0000] {processor.py:161} INFO - Started process (PID=200) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:24:45.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:24:45.397+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:24:45.396+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:24:47.315+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:24:47.370+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:24:47.369+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:24:47.419+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:24:47.418+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:24:47.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.110 seconds
[2025-05-28T13:25:18.145+0000] {processor.py:161} INFO - Started process (PID=218) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:25:18.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:25:18.161+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:25:18.160+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:25:20.401+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:25:20.486+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:25:20.485+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:25:20.537+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:25:20.536+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:25:20.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.458 seconds
[2025-05-28T13:25:50.733+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:25:50.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:25:50.739+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:25:50.738+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:25:52.110+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:25:52.140+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:25:52.139+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:25:52.166+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:25:52.165+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:25:52.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.478 seconds
[2025-05-28T13:26:22.619+0000] {processor.py:161} INFO - Started process (PID=254) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:26:22.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:26:22.623+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:26:22.622+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:26:23.497+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:26:23.529+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:26:23.529+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:26:23.554+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:26:23.554+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:26:23.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.974 seconds
[2025-05-28T13:26:53.927+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:26:53.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:26:53.938+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:26:53.937+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:26:54.871+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:26:54.905+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:26:54.904+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:26:54.931+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:26:54.931+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:26:54.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.056 seconds
[2025-05-28T13:27:25.084+0000] {processor.py:161} INFO - Started process (PID=290) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:27:25.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:27:25.088+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:27:25.088+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:27:25.886+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:27:25.914+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:27:25.913+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:27:25.938+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:27:25.938+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:27:25.970+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.893 seconds
[2025-05-28T13:27:56.544+0000] {processor.py:161} INFO - Started process (PID=308) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:27:56.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:27:56.548+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:27:56.548+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:27:57.595+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:27:57.642+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:27:57.642+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:27:57.681+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:27:57.681+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:27:57.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.177 seconds
[2025-05-28T13:28:28.018+0000] {processor.py:161} INFO - Started process (PID=326) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:28:28.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:28:28.023+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:28:28.022+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:28:28.942+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:28:28.986+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:28:28.985+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:28:29.034+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:28:29.034+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:28:29.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.060 seconds
[2025-05-28T13:28:59.355+0000] {processor.py:161} INFO - Started process (PID=345) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:28:59.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:28:59.358+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:28:59.358+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:29:00.194+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:29:00.222+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:29:00.222+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:29:00.246+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:29:00.246+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:29:00.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.938 seconds
[2025-05-28T13:29:30.408+0000] {processor.py:161} INFO - Started process (PID=364) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:29:30.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:29:30.412+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:29:30.411+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:29:31.640+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:29:31.781+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:29:31.780+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:29:31.939+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:29:31.939+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:29:32.048+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.648 seconds
[2025-05-28T13:30:02.539+0000] {processor.py:161} INFO - Started process (PID=382) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:30:02.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:30:02.553+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:30:02.552+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:30:03.849+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:30:03.892+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:30:03.891+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:30:03.932+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:30:03.932+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:30:03.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.460 seconds
[2025-05-28T13:30:34.351+0000] {processor.py:161} INFO - Started process (PID=400) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:30:34.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:30:34.362+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:30:34.361+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:30:35.976+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:30:36.011+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:30:36.010+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:30:36.038+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:30:36.038+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:30:36.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.732 seconds
[2025-05-28T13:31:06.390+0000] {processor.py:161} INFO - Started process (PID=418) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:31:06.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:31:06.395+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:31:06.394+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:31:07.922+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:31:07.961+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:31:07.960+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:31:07.996+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:31:07.996+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:31:08.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.673 seconds
[2025-05-28T13:31:39.304+0000] {processor.py:161} INFO - Started process (PID=443) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:31:39.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:31:39.352+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:31:39.351+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:31:41.822+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:31:41.923+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:31:41.922+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:31:42.013+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:31:42.010+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:31:42.105+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.852 seconds
[2025-05-28T13:32:12.981+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:32:12.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:32:12.989+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:32:12.988+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:32:15.288+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:32:15.357+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:32:15.357+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:32:15.406+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:32:15.406+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:32:15.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.555 seconds
[2025-05-28T13:32:46.122+0000] {processor.py:161} INFO - Started process (PID=479) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:32:46.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:32:46.129+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:32:46.128+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:32:47.516+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:32:47.562+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:32:47.560+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:32:47.605+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:32:47.605+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:32:47.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.560 seconds
[2025-05-28T13:33:18.035+0000] {processor.py:161} INFO - Started process (PID=497) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:33:18.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:33:18.048+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:33:18.042+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:33:22.437+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:33:22.496+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:33:22.495+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:33:22.552+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:33:22.551+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:33:22.636+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.614 seconds
[2025-05-28T13:33:53.753+0000] {processor.py:161} INFO - Started process (PID=515) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:33:53.756+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:33:53.772+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:33:53.771+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:33:55.203+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:33:55.248+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:33:55.247+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:33:55.286+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:33:55.286+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:33:55.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.590 seconds
[2025-05-28T13:34:25.675+0000] {processor.py:161} INFO - Started process (PID=533) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:34:25.676+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T13:34:25.679+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:34:25.678+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:34:26.541+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T13:34:26.576+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:34:26.575+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T13:34:26.632+0000] {logging_mixin.py:188} INFO - [2025-05-28T13:34:26.631+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T13:34:26.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.050 seconds
[2025-05-28T14:07:41.014+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:07:41.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:07:41.078+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:07:41.077+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:08:06.416+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:08:07.820+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:08:07.819+0000] {override.py:1858} INFO - Created Permission View: can read on DAG:postgres_to_bigquery
[2025-05-28T14:08:07.890+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:08:07.890+0000] {override.py:1858} INFO - Created Permission View: can delete on DAG:postgres_to_bigquery
[2025-05-28T14:08:07.945+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:08:07.944+0000] {override.py:1858} INFO - Created Permission View: can edit on DAG:postgres_to_bigquery
[2025-05-28T14:08:07.949+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:08:07.948+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:08:08.044+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:08:08.031+0000] {dag.py:3111} INFO - Creating ORM DAG for postgres_to_bigquery
[2025-05-28T14:08:08.096+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:08:08.095+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:08:08.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 27.272 seconds
[2025-05-28T14:08:39.322+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:08:39.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:08:39.338+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:08:39.334+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:08:44.936+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:08:45.118+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:08:45.114+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:08:45.229+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:08:45.228+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:08:45.378+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.076 seconds
[2025-05-28T14:09:17.588+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:09:17.628+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:09:17.646+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:09:17.645+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:09:23.260+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:09:23.410+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:09:23.398+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:09:23.556+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:09:23.555+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:09:23.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.161 seconds
[2025-05-28T14:09:55.104+0000] {processor.py:161} INFO - Started process (PID=238) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:09:55.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:09:55.157+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:09:55.156+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:10:00.591+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:10:00.785+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:10:00.773+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:10:00.933+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:10:00.932+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:10:01.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.075 seconds
[2025-05-28T14:10:31.357+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:10:31.360+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:10:31.364+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:10:31.363+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:10:32.831+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:10:32.874+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:10:32.873+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:10:32.901+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:10:32.901+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:10:32.933+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.584 seconds
[2025-05-28T14:11:03.090+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:11:03.093+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:11:03.096+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:11:03.096+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:11:05.017+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:11:05.058+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:11:05.058+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:11:05.106+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:11:05.105+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:11:05.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.079 seconds
[2025-05-28T14:11:35.395+0000] {processor.py:161} INFO - Started process (PID=298) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:11:35.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:11:35.399+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:11:35.398+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:11:36.195+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:11:36.226+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:11:36.226+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:11:36.250+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:11:36.250+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:11:36.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.898 seconds
[2025-05-28T14:12:06.744+0000] {processor.py:161} INFO - Started process (PID=316) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:12:06.745+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:12:06.748+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:12:06.748+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:12:07.918+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:12:07.951+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:12:07.951+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:12:07.984+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:12:07.984+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:12:08.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.279 seconds
[2025-05-28T14:12:38.154+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:12:38.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:12:38.158+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:12:38.157+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:12:39.122+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:12:39.165+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:12:39.164+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:12:39.204+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:12:39.203+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:12:39.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.111 seconds
[2025-05-28T14:13:09.626+0000] {processor.py:161} INFO - Started process (PID=352) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:13:09.628+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:13:09.630+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:13:09.630+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:13:10.897+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:13:10.931+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:13:10.931+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:13:10.964+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:13:10.964+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:13:10.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.375 seconds
[2025-05-28T14:13:41.164+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:13:41.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:13:41.168+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:13:41.167+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:13:42.033+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:13:42.106+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:13:42.105+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:13:42.165+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:13:42.165+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:13:42.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.068 seconds
[2025-05-28T14:14:12.522+0000] {processor.py:161} INFO - Started process (PID=388) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:14:12.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:14:12.527+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:14:12.526+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:14:13.446+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:14:13.482+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:14:13.481+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:14:13.514+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:14:13.514+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:14:13.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.033 seconds
[2025-05-28T14:14:43.802+0000] {processor.py:161} INFO - Started process (PID=406) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:14:43.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:14:43.805+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:14:43.805+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:14:44.575+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:14:44.604+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:14:44.603+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:14:44.631+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:14:44.631+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:14:44.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.867 seconds
[2025-05-28T14:15:14.925+0000] {processor.py:161} INFO - Started process (PID=424) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:15:14.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:15:14.930+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:15:14.928+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:15:16.011+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:15:16.046+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:15:16.045+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:15:16.080+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:15:16.079+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:15:16.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.202 seconds
[2025-05-28T14:15:46.414+0000] {processor.py:161} INFO - Started process (PID=443) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:15:46.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:15:46.417+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:15:46.417+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:15:47.317+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:15:47.347+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:15:47.347+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:15:47.371+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:15:47.371+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:15:47.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.997 seconds
[2025-05-28T14:16:17.725+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:16:17.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:16:17.730+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:16:17.730+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:16:19.762+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:16:19.795+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:16:19.794+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:16:19.825+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:16:19.824+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:16:19.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.156 seconds
[2025-05-28T14:16:50.200+0000] {processor.py:161} INFO - Started process (PID=479) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:16:50.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:16:50.216+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:16:50.215+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:16:51.382+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:16:51.421+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:16:51.420+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:16:51.450+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:16:51.450+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:16:51.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.289 seconds
[2025-05-28T14:17:21.778+0000] {processor.py:161} INFO - Started process (PID=498) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:17:21.780+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:17:21.783+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:17:21.782+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:17:23.228+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:17:23.271+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:17:23.270+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:17:23.306+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:17:23.305+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:17:23.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.573 seconds
[2025-05-28T14:17:53.697+0000] {processor.py:161} INFO - Started process (PID=516) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:17:53.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:17:53.701+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:17:53.700+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:17:54.602+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:17:54.636+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:17:54.636+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:17:54.661+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:17:54.661+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:17:54.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.003 seconds
[2025-05-28T14:18:25.017+0000] {processor.py:161} INFO - Started process (PID=534) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:18:25.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:18:25.021+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:18:25.020+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:18:25.785+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:18:25.815+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:18:25.814+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:18:25.838+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:18:25.838+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:18:25.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.855 seconds
[2025-05-28T14:18:56.147+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:18:56.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:18:56.151+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:18:56.150+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:18:57.033+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:18:57.074+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:18:57.073+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:18:57.098+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:18:57.098+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:18:57.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.990 seconds
[2025-05-28T14:19:27.394+0000] {processor.py:161} INFO - Started process (PID=570) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:19:27.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:19:27.398+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:19:27.397+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:19:28.162+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:19:28.196+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:19:28.196+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:19:28.221+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:19:28.221+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:19:28.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.861 seconds
[2025-05-28T14:19:58.517+0000] {processor.py:161} INFO - Started process (PID=588) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:19:58.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:19:58.521+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:19:58.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:19:59.413+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:19:59.456+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:19:59.456+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:19:59.487+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:19:59.487+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:19:59.562+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.053 seconds
[2025-05-28T14:20:29.875+0000] {processor.py:161} INFO - Started process (PID=606) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:20:29.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:20:29.879+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:20:29.878+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:20:30.764+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:20:30.839+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:20:30.838+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:20:30.883+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:20:30.883+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:20:30.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.076 seconds
[2025-05-28T14:21:01.225+0000] {processor.py:161} INFO - Started process (PID=624) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:21:01.226+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:21:01.229+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:21:01.229+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:21:02.085+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:21:02.115+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:21:02.115+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:21:02.142+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:21:02.141+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:21:02.179+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.963 seconds
[2025-05-28T14:21:32.472+0000] {processor.py:161} INFO - Started process (PID=643) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:21:32.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:21:32.476+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:21:32.476+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:21:33.363+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:21:33.428+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:21:33.427+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:21:33.464+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:21:33.463+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:21:33.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.026 seconds
[2025-05-28T14:22:03.788+0000] {processor.py:161} INFO - Started process (PID=661) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:22:03.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:22:03.792+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:22:03.791+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:22:04.689+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:22:04.722+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:22:04.721+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:22:04.752+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:22:04.751+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:22:04.783+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.003 seconds
[2025-05-28T14:22:34.944+0000] {processor.py:161} INFO - Started process (PID=679) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:22:34.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:22:34.950+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:22:34.949+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:22:35.886+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:22:35.918+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:22:35.917+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:22:35.943+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:22:35.943+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:22:35.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.041 seconds
[2025-05-28T14:23:06.246+0000] {processor.py:161} INFO - Started process (PID=703) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:23:06.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:23:06.251+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:23:06.250+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:23:07.526+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:23:07.571+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:23:07.570+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:23:07.604+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:23:07.604+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:23:07.647+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.414 seconds
[2025-05-28T14:23:37.725+0000] {processor.py:161} INFO - Started process (PID=721) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:23:37.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:23:37.729+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:23:37.729+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:23:38.497+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:23:38.526+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:23:38.525+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:23:38.567+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:23:38.566+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:23:38.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.886 seconds
[2025-05-28T14:24:08.760+0000] {processor.py:161} INFO - Started process (PID=739) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:24:08.761+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:24:08.764+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:24:08.764+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:24:09.657+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:24:09.702+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:24:09.700+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:24:09.749+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:24:09.748+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:24:09.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.060 seconds
[2025-05-28T14:24:40.061+0000] {processor.py:161} INFO - Started process (PID=757) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:24:40.062+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:24:40.064+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:24:40.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:24:40.915+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:24:40.943+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:24:40.942+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:24:40.967+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:24:40.966+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:24:41.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.949 seconds
[2025-05-28T14:25:11.430+0000] {processor.py:161} INFO - Started process (PID=776) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:25:11.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:25:11.437+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:25:11.436+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:25:12.341+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:25:12.374+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:25:12.374+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:25:12.427+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:25:12.426+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:25:12.455+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.035 seconds
[2025-05-28T14:25:42.756+0000] {processor.py:161} INFO - Started process (PID=794) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:25:42.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:25:42.760+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:25:42.759+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:25:43.786+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:25:43.816+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:25:43.815+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:25:43.840+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:25:43.840+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:25:43.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.120 seconds
[2025-05-28T14:26:14.130+0000] {processor.py:161} INFO - Started process (PID=813) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:26:14.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:26:14.134+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:26:14.133+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:26:15.292+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:26:15.331+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:26:15.331+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:26:15.358+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:26:15.357+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:26:15.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.287 seconds
[2025-05-28T14:26:45.706+0000] {processor.py:161} INFO - Started process (PID=831) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:26:45.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:26:45.709+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:26:45.709+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:26:46.488+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:26:46.515+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:26:46.515+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:26:46.539+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:26:46.538+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:26:46.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.872 seconds
[2025-05-28T14:27:16.866+0000] {processor.py:161} INFO - Started process (PID=849) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:27:16.867+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:27:16.870+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:27:16.869+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:27:17.782+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:27:17.818+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:27:17.818+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:27:17.849+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:27:17.848+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:27:17.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.019 seconds
[2025-05-28T14:27:48.231+0000] {processor.py:161} INFO - Started process (PID=867) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:27:48.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:27:48.235+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:27:48.235+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:27:49.029+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:27:49.056+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:27:49.056+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:27:49.087+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:27:49.086+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:27:49.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.891 seconds
[2025-05-28T14:28:19.472+0000] {processor.py:161} INFO - Started process (PID=885) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:28:19.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:28:19.475+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:28:19.475+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:28:20.384+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:28:20.415+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:28:20.414+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:28:20.438+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:28:20.438+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:28:20.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.005 seconds
[2025-05-28T14:28:50.762+0000] {processor.py:161} INFO - Started process (PID=903) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:28:50.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:28:50.779+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:28:50.778+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:28:52.033+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:28:52.066+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:28:52.065+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:28:52.095+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:28:52.094+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:28:52.167+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.423 seconds
[2025-05-28T14:29:22.475+0000] {processor.py:161} INFO - Started process (PID=920) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:29:22.477+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:29:22.479+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:29:22.479+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:29:23.498+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:29:23.529+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:29:23.528+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:29:23.554+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:29:23.554+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:29:23.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.129 seconds
[2025-05-28T14:29:53.883+0000] {processor.py:161} INFO - Started process (PID=938) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:29:53.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:29:53.887+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:29:53.886+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:29:55.167+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:29:55.262+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:29:55.261+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:29:55.334+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:29:55.333+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:29:55.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.511 seconds
[2025-05-28T14:30:25.716+0000] {processor.py:161} INFO - Started process (PID=956) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:30:25.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:30:25.721+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:30:25.721+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:30:26.637+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:30:26.669+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:30:26.668+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:30:26.702+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:30:26.702+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:30:26.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.033 seconds
[2025-05-28T14:30:57.024+0000] {processor.py:161} INFO - Started process (PID=975) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:30:57.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:30:57.043+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:30:57.042+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:30:58.058+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:30:58.087+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:30:58.086+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:30:58.111+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:30:58.110+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:30:58.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.144 seconds
[2025-05-28T14:31:28.320+0000] {processor.py:161} INFO - Started process (PID=994) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:31:28.322+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:31:28.324+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:31:28.324+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:31:29.363+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:31:29.392+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:31:29.391+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:31:29.418+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:31:29.418+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:31:29.450+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.139 seconds
[2025-05-28T14:31:59.746+0000] {processor.py:161} INFO - Started process (PID=1012) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:31:59.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:31:59.751+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:31:59.750+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:32:01.536+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:32:01.573+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:32:01.573+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:32:01.601+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:32:01.600+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:32:01.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.899 seconds
[2025-05-28T14:32:31.938+0000] {processor.py:161} INFO - Started process (PID=1035) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:32:31.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:32:31.943+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:32:31.942+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:32:32.800+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:32:32.831+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:32:32.830+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:32:32.856+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:32:32.856+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:32:32.893+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.963 seconds
[2025-05-28T14:33:03.351+0000] {processor.py:161} INFO - Started process (PID=1053) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:33:03.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:33:03.358+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:33:03.357+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:33:05.256+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:33:05.364+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:33:05.363+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:33:05.455+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:33:05.455+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:33:05.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.220 seconds
[2025-05-28T14:33:35.701+0000] {processor.py:161} INFO - Started process (PID=1073) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:33:35.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:33:35.706+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:33:35.705+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:33:37.188+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:33:37.280+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:33:37.279+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:33:37.405+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:33:37.405+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:33:37.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.808 seconds
[2025-05-28T14:34:08.080+0000] {processor.py:161} INFO - Started process (PID=1095) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:34:08.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:34:08.095+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:34:08.094+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:34:12.214+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:34:12.311+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:34:12.310+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:34:12.390+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:34:12.389+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:34:12.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.427 seconds
[2025-05-28T14:34:43.146+0000] {processor.py:161} INFO - Started process (PID=1115) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:34:43.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:34:43.162+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:34:43.161+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:34:46.687+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:34:46.871+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:34:46.869+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:34:47.036+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:34:47.035+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:34:47.173+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.046 seconds
[2025-05-28T14:35:17.977+0000] {processor.py:161} INFO - Started process (PID=1133) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:35:17.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:35:17.992+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:35:17.991+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:35:21.544+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:35:21.741+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:35:21.739+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:35:21.921+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:35:21.909+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:35:22.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.116 seconds
[2025-05-28T14:35:52.344+0000] {processor.py:161} INFO - Started process (PID=1151) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:35:52.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:35:52.353+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:35:52.352+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:35:54.202+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:35:54.279+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:35:54.268+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:35:54.373+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:35:54.372+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:35:54.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.129 seconds
[2025-05-28T14:36:25.052+0000] {processor.py:161} INFO - Started process (PID=1169) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:36:25.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:36:25.056+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:36:25.055+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:36:26.313+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:36:26.344+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:36:26.344+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:36:26.373+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:36:26.373+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:36:26.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.373 seconds
[2025-05-28T14:36:56.841+0000] {processor.py:161} INFO - Started process (PID=1187) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:36:56.843+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:36:56.846+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:36:56.845+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:36:57.992+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:36:58.032+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:36:58.032+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:36:58.068+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:36:58.068+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:36:58.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.272 seconds
[2025-05-28T14:37:28.289+0000] {processor.py:161} INFO - Started process (PID=1204) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:37:28.292+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:37:28.295+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:37:28.294+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:37:29.175+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:37:29.206+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:37:29.205+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:37:29.236+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:37:29.235+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:37:29.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.997 seconds
[2025-05-28T14:37:59.957+0000] {processor.py:161} INFO - Started process (PID=1222) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:37:59.959+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:37:59.973+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:37:59.966+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:38:02.596+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:38:02.643+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:38:02.642+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:38:02.690+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:38:02.690+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:38:02.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.815 seconds
[2025-05-28T14:38:33.238+0000] {processor.py:161} INFO - Started process (PID=1240) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:38:33.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:38:33.249+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:38:33.248+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:38:34.391+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:38:34.437+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:38:34.436+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:38:34.471+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:38:34.471+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:38:34.520+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.302 seconds
[2025-05-28T14:39:04.731+0000] {processor.py:161} INFO - Started process (PID=1258) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:39:04.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:39:04.735+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:39:04.735+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:39:06.445+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:39:06.490+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:39:06.489+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:39:06.535+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:39:06.534+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:39:06.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.897 seconds
[2025-05-28T14:39:37.294+0000] {processor.py:161} INFO - Started process (PID=1276) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:39:37.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:39:37.298+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:39:37.297+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:39:38.565+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:39:38.600+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:39:38.599+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:39:38.628+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:39:38.628+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:39:38.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.380 seconds
[2025-05-28T14:40:08.759+0000] {processor.py:161} INFO - Started process (PID=1294) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:40:08.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:40:08.779+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:40:08.778+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:40:11.474+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:40:11.618+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:40:11.609+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:40:11.763+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:40:11.762+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:40:11.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.139 seconds
[2025-05-28T14:40:42.061+0000] {processor.py:161} INFO - Started process (PID=1312) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:40:42.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:40:42.066+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:40:42.065+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:40:42.959+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:40:42.990+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:40:42.989+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:40:43.016+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:40:43.016+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:40:43.047+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.994 seconds
[2025-05-28T14:41:13.515+0000] {processor.py:161} INFO - Started process (PID=1336) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:41:13.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:41:13.572+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:41:13.570+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:41:15.772+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:41:15.808+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:41:15.807+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:41:15.844+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:41:15.844+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:41:15.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.412 seconds
[2025-05-28T14:41:46.200+0000] {processor.py:161} INFO - Started process (PID=1354) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:41:46.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:41:46.208+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:41:46.207+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:41:47.763+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:41:47.830+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:41:47.829+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:41:47.897+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:41:47.897+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:41:47.934+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.743 seconds
[2025-05-28T14:42:18.414+0000] {processor.py:161} INFO - Started process (PID=1372) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:42:18.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:42:18.431+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:42:18.430+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:42:20.146+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:42:20.181+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:42:20.181+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:42:20.211+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:42:20.211+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:42:20.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.866 seconds
[2025-05-28T14:42:50.855+0000] {processor.py:161} INFO - Started process (PID=1389) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:42:50.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:42:50.871+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:42:50.871+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:42:51.850+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:42:51.885+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:42:51.884+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:42:51.923+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:42:51.922+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:42:51.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.146 seconds
[2025-05-28T14:43:22.253+0000] {processor.py:161} INFO - Started process (PID=1407) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:43:22.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:43:22.284+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:43:22.276+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:43:24.370+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:43:24.432+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:43:24.431+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:43:24.477+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:43:24.477+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:43:24.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.305 seconds
[2025-05-28T14:43:54.670+0000] {processor.py:161} INFO - Started process (PID=1425) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:43:54.671+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:43:54.675+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:43:54.674+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:43:55.998+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:43:56.113+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:43:56.111+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:43:56.197+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:43:56.197+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:43:56.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.652 seconds
[2025-05-28T14:44:27.365+0000] {processor.py:161} INFO - Started process (PID=1444) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:44:27.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:44:27.405+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:44:27.404+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:44:30.362+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:44:30.489+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:44:30.488+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:44:30.564+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:44:30.564+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:44:30.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.400 seconds
[2025-05-28T14:45:01.332+0000] {processor.py:161} INFO - Started process (PID=1462) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:45:01.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:45:01.353+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:45:01.352+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:45:04.180+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:45:04.216+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:45:04.215+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:45:04.248+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:45:04.245+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:45:04.278+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.983 seconds
[2025-05-28T14:45:34.871+0000] {processor.py:161} INFO - Started process (PID=1480) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:45:34.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:45:34.878+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:45:34.877+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:45:36.402+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:45:36.453+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:45:36.452+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:45:36.482+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:45:36.482+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:45:36.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.664 seconds
[2025-05-28T14:49:53.446+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:49:53.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:49:53.452+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:49:53.451+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:49:57.424+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:49:58.204+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:49:58.203+0000] {override.py:1858} INFO - Created Permission View: can edit on DAG:postgres_to_bigquery
[2025-05-28T14:49:58.221+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:49:58.221+0000] {override.py:1858} INFO - Created Permission View: can read on DAG:postgres_to_bigquery
[2025-05-28T14:49:58.236+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:49:58.235+0000] {override.py:1858} INFO - Created Permission View: can delete on DAG:postgres_to_bigquery
[2025-05-28T14:49:58.237+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:49:58.236+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:49:58.258+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:49:58.257+0000] {dag.py:3111} INFO - Creating ORM DAG for postgres_to_bigquery
[2025-05-28T14:49:58.282+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:49:58.282+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:49:58.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.877 seconds
[2025-05-28T14:50:28.530+0000] {processor.py:161} INFO - Started process (PID=190) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:50:28.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:50:28.535+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:50:28.534+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:50:30.363+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:50:30.398+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:50:30.397+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:50:30.445+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:50:30.444+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:50:30.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.958 seconds
[2025-05-28T14:51:01.045+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:51:01.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:51:01.052+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:51:01.051+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:51:02.790+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:51:02.829+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:51:02.829+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:51:02.869+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:51:02.869+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:51:02.919+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.883 seconds
[2025-05-28T14:51:32.989+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:51:32.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:51:32.993+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:51:32.993+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:51:33.780+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:51:33.813+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:51:33.812+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:51:33.837+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:51:33.836+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:51:33.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.889 seconds
[2025-05-28T14:52:04.182+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:52:04.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:52:04.186+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:52:04.185+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:52:05.193+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:52:05.235+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:52:05.234+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:52:05.264+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:52:05.263+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:52:05.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.117 seconds
[2025-05-28T14:52:35.592+0000] {processor.py:161} INFO - Started process (PID=262) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:52:35.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:52:35.597+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:52:35.596+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:52:36.401+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:52:36.432+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:52:36.432+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:52:36.457+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:52:36.457+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:52:36.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.910 seconds
[2025-05-28T14:53:06.801+0000] {processor.py:161} INFO - Started process (PID=280) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:53:06.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:53:06.805+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:53:06.805+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:53:07.955+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:53:07.993+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:53:07.992+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:53:08.023+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:53:08.023+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:53:08.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.265 seconds
[2025-05-28T14:53:38.245+0000] {processor.py:161} INFO - Started process (PID=298) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:53:38.246+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:53:38.249+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:53:38.249+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:53:39.743+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:53:39.834+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:53:39.833+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:53:39.882+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:53:39.881+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:53:39.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.723 seconds
[2025-05-28T14:54:10.304+0000] {processor.py:161} INFO - Started process (PID=317) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:54:10.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:54:10.313+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:54:10.312+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:54:11.947+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:54:11.984+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:54:11.984+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:54:12.019+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:54:12.019+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:54:12.070+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.786 seconds
[2025-05-28T14:54:42.661+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:54:42.676+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:54:42.686+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:54:42.680+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:54:47.109+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:54:47.270+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:54:47.268+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:54:47.430+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:54:47.429+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:54:47.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.972 seconds
[2025-05-28T14:55:18.143+0000] {processor.py:161} INFO - Started process (PID=359) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:55:18.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:55:18.148+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:55:18.147+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:55:18.988+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:55:19.017+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:55:19.017+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:55:19.042+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:55:19.042+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:55:19.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.938 seconds
[2025-05-28T14:55:49.628+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:55:49.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:55:49.637+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:55:49.636+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:55:50.817+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:55:50.872+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:55:50.872+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:55:50.903+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:55:50.903+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:55:50.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.320 seconds
[2025-05-28T14:56:22.157+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:56:22.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:56:22.272+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:56:22.272+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:56:25.403+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:56:25.508+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:56:25.496+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:56:25.612+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:56:25.612+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:56:25.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.581 seconds
[2025-05-28T14:56:56.483+0000] {processor.py:161} INFO - Started process (PID=413) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:56:56.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:56:56.489+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:56:56.488+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:56:57.545+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:56:57.583+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:56:57.582+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:56:57.618+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:56:57.618+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:56:57.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.188 seconds
[2025-05-28T14:57:28.108+0000] {processor.py:161} INFO - Started process (PID=431) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:57:28.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:57:28.115+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:57:28.114+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:57:30.508+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:57:30.584+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:57:30.583+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:57:30.645+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:57:30.644+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:57:30.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.604 seconds
[2025-05-28T14:58:01.556+0000] {processor.py:161} INFO - Started process (PID=448) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:58:01.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:58:01.561+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:58:01.560+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:58:02.740+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:58:02.902+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:58:02.901+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:58:02.930+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:58:02.929+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:58:02.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.421 seconds
[2025-05-28T14:58:33.421+0000] {processor.py:161} INFO - Started process (PID=466) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:58:33.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:58:33.425+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:58:33.424+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:58:34.320+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:58:34.375+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:58:34.374+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:58:34.495+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:58:34.495+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:58:34.725+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.312 seconds
[2025-05-28T14:59:05.133+0000] {processor.py:161} INFO - Started process (PID=484) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:59:05.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:59:05.137+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:59:05.136+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:59:06.427+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:59:06.466+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:59:06.465+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:59:06.501+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:59:06.500+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:59:06.534+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.410 seconds
[2025-05-28T14:59:37.410+0000] {processor.py:161} INFO - Started process (PID=502) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:59:37.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T14:59:37.414+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:59:37.413+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:59:38.462+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T14:59:38.493+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:59:38.492+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T14:59:38.520+0000] {logging_mixin.py:188} INFO - [2025-05-28T14:59:38.520+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T14:59:38.554+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.153 seconds
[2025-05-28T15:00:08.958+0000] {processor.py:161} INFO - Started process (PID=520) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:00:08.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:00:08.963+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:00:08.963+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:00:10.759+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:00:10.804+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:00:10.803+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:00:10.851+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:00:10.851+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T15:00:10.886+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.943 seconds
[2025-05-28T15:00:41.166+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:00:41.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:00:41.171+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:00:41.171+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:00:42.531+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:00:42.608+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:00:42.607+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:00:42.665+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:00:42.665+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T15:00:42.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.542 seconds
[2025-05-28T15:01:13.013+0000] {processor.py:161} INFO - Started process (PID=556) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:01:13.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:01:13.017+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:01:13.017+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:01:14.796+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:01:14.906+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:01:14.905+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:01:15.009+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:01:15.009+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T15:01:15.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.145 seconds
[2025-05-28T15:01:45.688+0000] {processor.py:161} INFO - Started process (PID=574) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:01:45.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:01:45.695+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:01:45.694+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:01:47.013+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:01:47.044+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:01:47.044+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:01:47.073+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:01:47.073+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T15:01:47.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.451 seconds
[2025-05-28T15:02:17.450+0000] {processor.py:161} INFO - Started process (PID=598) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:02:17.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:02:17.457+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:02:17.456+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:02:19.187+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:02:19.232+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:02:19.232+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:02:19.269+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:02:19.269+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T15:02:19.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.880 seconds
[2025-05-28T15:02:49.756+0000] {processor.py:161} INFO - Started process (PID=617) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:02:49.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:02:49.761+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:02:49.760+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:02:50.922+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:02:50.974+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:02:50.973+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:02:51.008+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:02:51.007+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T15:02:51.041+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.298 seconds
[2025-05-28T15:03:21.770+0000] {processor.py:161} INFO - Started process (PID=635) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:03:21.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:03:21.780+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:03:21.779+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:03:23.912+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:03:23.962+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:03:23.961+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:03:24.000+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:03:24.000+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T15:03:24.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.275 seconds
[2025-05-28T15:03:54.446+0000] {processor.py:161} INFO - Started process (PID=653) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:03:54.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:03:54.451+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:03:54.450+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:03:55.416+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:03:55.466+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:03:55.465+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:03:55.537+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:03:55.536+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T15:03:55.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.169 seconds
[2025-05-28T15:04:25.748+0000] {processor.py:161} INFO - Started process (PID=670) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:04:25.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:04:25.755+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:04:25.755+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:04:27.241+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:04:27.378+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:04:27.377+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:04:27.511+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:04:27.511+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T15:04:27.608+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.868 seconds
[2025-05-28T15:04:58.065+0000] {processor.py:161} INFO - Started process (PID=688) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:04:58.066+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:04:58.069+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:04:58.068+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:04:58.997+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:04:59.033+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:04:59.032+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:04:59.067+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:04:59.067+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T15:04:59.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.047 seconds
[2025-05-28T15:05:29.512+0000] {processor.py:161} INFO - Started process (PID=706) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:05:29.516+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:05:29.520+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:05:29.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:05:31.001+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:05:31.039+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:05:31.038+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:05:31.083+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:05:31.082+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T15:05:31.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.651 seconds
[2025-05-28T15:06:01.761+0000] {processor.py:161} INFO - Started process (PID=724) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:06:01.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:06:01.765+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:06:01.764+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:06:04.908+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:06:04.974+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:06:04.973+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:06:05.068+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:06:05.063+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2025-05-28T15:06:05.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.434 seconds
[2025-05-28T15:06:37.003+0000] {processor.py:161} INFO - Started process (PID=756) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:06:37.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:06:37.100+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:06:37.099+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:07:10.400+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:07:10.399+0000] {timeout.py:68} ERROR - Process timed out, PID: 756
[2025-05-28T15:07:44.105+0000] {processor.py:161} INFO - Started process (PID=816) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:07:44.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:07:44.122+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:07:44.121+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:07:47.470+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:07:47.592+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:07:47.591+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:07:47.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.690 seconds
[2025-05-28T15:08:18.087+0000] {processor.py:161} INFO - Started process (PID=835) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:08:18.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:08:18.091+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:08:18.091+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:08:19.659+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:08:19.697+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:08:19.696+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:08:19.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.683 seconds
[2025-05-28T15:08:50.185+0000] {processor.py:161} INFO - Started process (PID=859) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:08:50.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:08:50.190+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:08:50.190+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:08:52.046+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:08:52.104+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:08:52.103+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:08:52.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.045 seconds
[2025-05-28T15:09:22.617+0000] {processor.py:161} INFO - Started process (PID=876) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:09:22.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:09:22.621+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:09:22.621+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:09:24.101+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:09:24.138+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:09:24.137+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:09:24.203+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.599 seconds
[2025-05-28T15:09:55.159+0000] {processor.py:161} INFO - Started process (PID=894) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:09:55.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:09:55.165+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:09:55.164+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:09:57.158+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:09:57.221+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:09:57.220+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:09:57.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.175 seconds
[2025-05-28T15:10:27.435+0000] {processor.py:161} INFO - Started process (PID=912) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:10:27.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:10:27.439+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:10:27.439+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:10:28.284+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:10:28.318+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:10:28.317+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:10:28.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.949 seconds
[2025-05-28T15:10:58.893+0000] {processor.py:161} INFO - Started process (PID=930) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:10:58.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:10:58.900+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:10:58.899+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:11:00.148+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:11:00.185+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:11:00.184+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:11:00.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.372 seconds
[2025-05-28T15:11:30.600+0000] {processor.py:161} INFO - Started process (PID=948) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:11:30.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:11:30.606+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:11:30.605+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:11:32.533+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:11:32.583+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:11:32.582+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:11:32.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.096 seconds
[2025-05-28T15:12:04.272+0000] {processor.py:161} INFO - Started process (PID=967) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:12:04.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:12:04.324+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:12:04.323+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:12:09.690+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:12:09.867+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:12:09.866+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:12:10.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.910 seconds
[2025-05-28T15:12:40.732+0000] {processor.py:161} INFO - Started process (PID=985) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:12:40.734+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:12:40.736+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:12:40.736+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:12:43.162+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:12:43.196+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:12:43.196+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:12:43.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.545 seconds
[2025-05-28T15:13:13.694+0000] {processor.py:161} INFO - Started process (PID=1003) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:13:13.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:13:13.702+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:13:13.701+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:13:16.527+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:13:16.602+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:13:16.601+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:13:16.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.007 seconds
[2025-05-28T15:13:46.817+0000] {processor.py:161} INFO - Started process (PID=1021) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:13:46.818+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:13:46.821+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:13:46.821+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:13:47.655+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:13:47.684+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:13:47.682+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:13:47.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.930 seconds
[2025-05-28T15:14:18.419+0000] {processor.py:161} INFO - Started process (PID=1039) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:14:18.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:14:18.428+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:14:18.427+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:14:19.830+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:14:19.877+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:14:19.876+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:14:19.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.582 seconds
[2025-05-28T15:14:50.650+0000] {processor.py:161} INFO - Started process (PID=1063) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:14:50.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:14:50.654+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:14:50.654+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:14:51.787+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:14:51.820+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:14:51.819+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:14:51.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.236 seconds
[2025-05-28T15:15:22.257+0000] {processor.py:161} INFO - Started process (PID=1081) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:15:22.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:15:22.261+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:15:22.260+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:15:23.251+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:15:23.280+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:15:23.279+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:15:23.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.080 seconds
[2025-05-28T15:15:53.593+0000] {processor.py:161} INFO - Started process (PID=1099) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:15:53.595+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:15:53.597+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:15:53.597+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:15:54.551+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:15:54.620+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:15:54.619+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:15:54.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.143 seconds
[2025-05-28T15:16:25.111+0000] {processor.py:161} INFO - Started process (PID=1117) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:16:25.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:16:25.114+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:16:25.114+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:16:26.093+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:16:26.122+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:16:26.121+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:16:26.179+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.076 seconds
[2025-05-28T15:16:56.454+0000] {processor.py:161} INFO - Started process (PID=1135) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:16:56.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:16:56.457+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:16:56.457+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:16:57.249+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:16:57.281+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:16:57.281+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:16:57.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.893 seconds
[2025-05-28T15:17:27.778+0000] {processor.py:161} INFO - Started process (PID=1153) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:17:27.780+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:17:27.784+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:17:27.783+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:17:28.763+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:17:28.794+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:17:28.793+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:17:28.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.086 seconds
[2025-05-28T15:17:58.987+0000] {processor.py:161} INFO - Started process (PID=1172) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:17:58.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:17:58.991+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:17:58.990+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:18:00.227+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:18:00.298+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:18:00.297+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:18:00.359+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.378 seconds
[2025-05-28T15:18:30.632+0000] {processor.py:161} INFO - Started process (PID=1191) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:18:30.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:18:30.635+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:18:30.635+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:18:31.867+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:18:31.896+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:18:31.895+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:18:31.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.329 seconds
[2025-05-28T15:19:02.293+0000] {processor.py:161} INFO - Started process (PID=1209) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:19:02.294+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:19:02.297+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:19:02.296+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:19:03.265+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:19:03.306+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:19:03.305+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:19:03.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.102 seconds
[2025-05-28T15:19:33.892+0000] {processor.py:161} INFO - Started process (PID=1227) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:19:33.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:19:33.896+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:19:33.896+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:19:35.180+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:19:35.218+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:19:35.217+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:19:35.288+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.403 seconds
[2025-05-28T15:20:05.639+0000] {processor.py:161} INFO - Started process (PID=1245) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:20:05.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:20:05.649+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:20:05.649+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:20:07.568+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:20:07.635+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:20:07.635+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:20:07.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.092 seconds
[2025-05-28T15:20:37.940+0000] {processor.py:161} INFO - Started process (PID=1263) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:20:37.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:20:37.946+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:20:37.945+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:20:39.041+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:20:39.071+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:20:39.070+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:20:39.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.200 seconds
[2025-05-28T15:21:09.343+0000] {processor.py:161} INFO - Started process (PID=1281) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:21:09.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:21:09.348+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:21:09.348+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:21:10.516+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:21:10.556+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:21:10.555+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:21:10.629+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.300 seconds
[2025-05-28T15:21:40.825+0000] {processor.py:161} INFO - Started process (PID=1299) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:21:40.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:21:40.829+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:21:40.829+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:21:42.344+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:21:42.373+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:21:42.373+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:21:42.424+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.609 seconds
[2025-05-28T15:22:12.966+0000] {processor.py:161} INFO - Started process (PID=1322) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:22:12.968+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:22:12.971+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:22:12.971+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:22:14.036+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:22:14.076+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:22:14.075+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:22:14.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.201 seconds
[2025-05-28T15:22:44.492+0000] {processor.py:161} INFO - Started process (PID=1342) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:22:44.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:22:44.499+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:22:44.497+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:22:45.537+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:22:45.567+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:22:45.566+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:22:45.622+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.149 seconds
[2025-05-28T15:23:15.740+0000] {processor.py:161} INFO - Started process (PID=1360) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:23:15.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:23:15.744+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:23:15.743+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:23:16.722+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:23:16.808+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:23:16.807+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:23:17.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.301 seconds
[2025-05-28T15:23:47.342+0000] {processor.py:161} INFO - Started process (PID=1378) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:23:47.343+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:23:47.346+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:23:47.345+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:23:48.260+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:23:48.293+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:23:48.293+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:23:48.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.018 seconds
[2025-05-28T15:24:18.447+0000] {processor.py:161} INFO - Started process (PID=1396) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:24:18.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:24:18.451+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:24:18.450+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:24:19.425+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:24:19.461+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:24:19.460+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:24:19.520+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.081 seconds
[2025-05-28T15:24:49.798+0000] {processor.py:161} INFO - Started process (PID=1414) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:24:49.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:24:49.802+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:24:49.802+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:24:50.814+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:24:50.843+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:24:50.843+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:24:50.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.131 seconds
[2025-05-28T15:25:21.135+0000] {processor.py:161} INFO - Started process (PID=1439) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:25:21.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:25:21.139+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:25:21.139+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:25:22.882+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:25:22.916+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:25:22.915+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:25:22.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.862 seconds
[2025-05-28T15:25:53.289+0000] {processor.py:161} INFO - Started process (PID=1457) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:25:53.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:25:53.294+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:25:53.293+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:25:54.963+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:25:55.048+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:25:55.047+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:25:55.153+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.870 seconds
[2025-05-28T15:26:25.563+0000] {processor.py:161} INFO - Started process (PID=1475) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:26:25.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:26:25.566+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:26:25.566+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:26:26.357+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:26:26.386+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:26:26.385+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:26:26.443+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.888 seconds
[2025-05-28T15:26:56.711+0000] {processor.py:161} INFO - Started process (PID=1493) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:26:56.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:26:56.716+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:26:56.715+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:26:57.488+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:26:57.517+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:26:57.516+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:26:57.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.873 seconds
[2025-05-28T15:27:27.917+0000] {processor.py:161} INFO - Started process (PID=1511) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:27:27.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:27:27.921+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:27:27.921+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:27:28.833+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:27:28.862+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:27:28.861+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:27:28.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.006 seconds
[2025-05-28T15:27:58.993+0000] {processor.py:161} INFO - Started process (PID=1528) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:27:58.994+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:27:58.996+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:27:58.996+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:27:59.843+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:27:59.873+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:27:59.872+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:27:59.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.937 seconds
[2025-05-28T15:28:30.460+0000] {processor.py:161} INFO - Started process (PID=1546) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:28:30.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:28:30.464+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:28:30.463+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:28:31.248+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:28:31.278+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:28:31.277+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:28:31.329+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.876 seconds
[2025-05-28T15:29:01.650+0000] {processor.py:161} INFO - Started process (PID=1564) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:29:01.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:29:01.654+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:29:01.654+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:29:03.087+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:29:03.120+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:29:03.119+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:29:03.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.544 seconds
[2025-05-28T15:29:33.446+0000] {processor.py:161} INFO - Started process (PID=1582) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:29:33.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:29:33.450+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:29:33.449+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:29:34.289+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:29:34.347+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:29:34.346+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:29:34.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.019 seconds
[2025-05-28T15:30:04.789+0000] {processor.py:161} INFO - Started process (PID=1600) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:30:04.790+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:30:04.794+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:30:04.793+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:30:05.995+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:30:06.105+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:30:06.095+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:30:06.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.441 seconds
[2025-05-28T15:30:36.279+0000] {processor.py:161} INFO - Started process (PID=1619) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:30:36.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:30:36.283+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:30:36.283+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:30:37.070+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:30:37.098+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:30:37.097+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:30:37.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.881 seconds
[2025-05-28T15:31:07.483+0000] {processor.py:161} INFO - Started process (PID=1637) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:31:07.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:31:07.521+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:31:07.512+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:31:08.607+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:31:08.643+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:31:08.642+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:31:08.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.246 seconds
[2025-05-28T15:31:38.915+0000] {processor.py:161} INFO - Started process (PID=1655) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:31:38.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:31:38.918+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:31:38.918+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:31:40.013+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:31:40.054+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:31:40.053+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:31:40.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.213 seconds
[2025-05-28T15:32:10.444+0000] {processor.py:161} INFO - Started process (PID=1673) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:32:10.446+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:32:10.449+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:32:10.448+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:32:11.287+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:32:11.319+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:32:11.319+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:32:11.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.945 seconds
[2025-05-28T15:32:41.750+0000] {processor.py:161} INFO - Started process (PID=1691) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:32:41.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:32:41.754+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:32:41.754+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:32:42.758+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:32:42.788+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:32:42.787+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:32:42.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.102 seconds
[2025-05-28T15:33:12.961+0000] {processor.py:161} INFO - Started process (PID=1709) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:33:12.963+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:33:12.966+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:33:12.965+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:33:14.312+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:33:14.352+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:33:14.352+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:33:14.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.490 seconds
[2025-05-28T15:33:44.716+0000] {processor.py:161} INFO - Started process (PID=1727) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:33:44.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:33:44.720+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:33:44.720+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:33:45.816+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:33:45.850+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:33:45.849+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:33:45.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.186 seconds
[2025-05-28T15:34:16.180+0000] {processor.py:161} INFO - Started process (PID=1744) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:34:16.182+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:34:16.184+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:34:16.183+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:34:17.107+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:34:17.145+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:34:17.144+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:34:17.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.115 seconds
[2025-05-28T15:34:47.570+0000] {processor.py:161} INFO - Started process (PID=1761) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:34:47.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:34:47.573+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:34:47.573+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:34:48.406+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:34:48.473+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:34:48.472+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:34:48.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.997 seconds
[2025-05-28T15:35:18.654+0000] {processor.py:161} INFO - Started process (PID=1779) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:35:18.657+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:35:18.660+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:35:18.660+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:35:19.685+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:35:19.717+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:35:19.716+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:35:19.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.133 seconds
[2025-05-28T15:35:49.886+0000] {processor.py:161} INFO - Started process (PID=1797) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:35:49.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:35:49.893+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:35:49.892+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:35:50.954+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:35:50.982+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:35:50.982+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:35:51.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.172 seconds
[2025-05-28T15:36:21.459+0000] {processor.py:161} INFO - Started process (PID=1815) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:36:21.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:36:21.475+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:36:21.474+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:36:22.822+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:36:22.848+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:36:22.848+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:36:22.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.479 seconds
[2025-05-28T15:36:53.181+0000] {processor.py:161} INFO - Started process (PID=1839) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:36:53.182+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:36:53.184+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:36:53.184+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:36:54.027+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:36:54.067+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:36:54.066+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:36:54.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.958 seconds
[2025-05-28T15:37:25.039+0000] {processor.py:161} INFO - Started process (PID=1857) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:37:25.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:37:25.043+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:37:25.042+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:37:26.502+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:37:26.533+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:37:26.531+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:37:26.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.579 seconds
[2025-05-28T15:37:56.878+0000] {processor.py:161} INFO - Started process (PID=1875) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:37:56.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:37:56.883+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:37:56.882+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:37:57.855+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:37:57.894+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:37:57.893+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:37:57.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.079 seconds
[2025-05-28T15:38:28.106+0000] {processor.py:161} INFO - Started process (PID=1893) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:38:28.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:38:28.110+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:38:28.110+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:38:29.005+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:38:29.061+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:38:29.060+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:38:29.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.035 seconds
[2025-05-28T15:38:59.397+0000] {processor.py:161} INFO - Started process (PID=1911) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:38:59.398+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:38:59.400+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:38:59.400+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:39:00.513+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:39:00.552+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:39:00.551+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:39:00.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.237 seconds
[2025-05-28T15:39:30.989+0000] {processor.py:161} INFO - Started process (PID=1929) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:39:30.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:39:30.992+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:39:30.992+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:39:31.797+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:39:31.825+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:39:31.825+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:39:31.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.907 seconds
[2025-05-28T15:40:02.371+0000] {processor.py:161} INFO - Started process (PID=1947) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:40:02.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:40:02.386+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:40:02.385+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:40:04.196+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:40:04.227+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:40:04.227+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:40:04.292+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.950 seconds
[2025-05-28T15:40:34.498+0000] {processor.py:161} INFO - Started process (PID=1965) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:40:34.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:40:34.504+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:40:34.503+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:40:35.547+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:40:35.578+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:40:35.577+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:40:35.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.161 seconds
[2025-05-28T15:41:05.776+0000] {processor.py:161} INFO - Started process (PID=1982) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:41:05.778+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:41:05.783+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:41:05.782+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:41:07.062+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:41:07.093+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:41:07.092+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:41:07.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.394 seconds
[2025-05-28T15:41:37.454+0000] {processor.py:161} INFO - Started process (PID=2000) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:41:37.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:41:37.458+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:41:37.457+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:41:38.361+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:41:38.393+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:41:38.392+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:41:38.450+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.003 seconds
[2025-05-28T15:42:08.788+0000] {processor.py:161} INFO - Started process (PID=2018) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:42:08.790+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:42:08.795+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:42:08.794+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:42:09.794+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:42:09.862+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:42:09.861+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:42:10.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.269 seconds
[2025-05-28T15:42:40.352+0000] {processor.py:161} INFO - Started process (PID=2037) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:42:40.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:42:40.357+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:42:40.357+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:42:41.383+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:42:41.470+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:42:41.469+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:42:41.615+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.275 seconds
[2025-05-28T15:43:11.765+0000] {processor.py:161} INFO - Started process (PID=2055) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:43:11.767+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:43:11.769+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:43:11.768+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:43:13.283+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:43:13.348+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:43:13.347+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:43:13.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.676 seconds
[2025-05-28T15:43:43.765+0000] {processor.py:161} INFO - Started process (PID=2073) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:43:43.767+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:43:43.770+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:43:43.769+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:43:44.620+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:43:44.667+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:43:44.666+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:43:44.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.980 seconds
[2025-05-28T15:44:15.092+0000] {processor.py:161} INFO - Started process (PID=2090) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:44:15.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:44:15.097+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:44:15.097+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:44:16.496+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:44:16.543+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:44:16.542+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:44:16.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.552 seconds
[2025-05-28T15:44:46.951+0000] {processor.py:161} INFO - Started process (PID=2108) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:44:46.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:44:46.955+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:44:46.954+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:44:47.857+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:44:47.957+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:44:47.956+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:44:48.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.145 seconds
[2025-05-28T15:45:18.260+0000] {processor.py:161} INFO - Started process (PID=2126) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:45:18.262+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:45:18.267+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:45:18.266+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:45:19.461+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:45:19.525+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:45:19.524+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:45:19.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.353 seconds
[2025-05-28T15:45:49.825+0000] {processor.py:161} INFO - Started process (PID=2144) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:45:49.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:45:49.833+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:45:49.833+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:45:51.656+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:45:51.688+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:45:51.687+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:45:51.764+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.962 seconds
[2025-05-28T15:46:22.088+0000] {processor.py:161} INFO - Started process (PID=2162) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:46:22.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:46:22.104+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:46:22.101+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:46:24.804+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:46:24.856+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:46:24.856+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:46:24.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.872 seconds
[2025-05-28T15:46:55.241+0000] {processor.py:161} INFO - Started process (PID=2186) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:46:55.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:46:55.245+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:46:55.245+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:46:57.017+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:46:57.253+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:46:57.252+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:46:57.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.204 seconds
[2025-05-28T15:47:28.128+0000] {processor.py:161} INFO - Started process (PID=2204) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:47:28.130+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:47:28.133+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:47:28.132+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:47:29.317+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:47:29.352+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:47:29.352+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:47:29.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.319 seconds
[2025-05-28T15:48:00.332+0000] {processor.py:161} INFO - Started process (PID=2223) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:48:00.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:48:00.343+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:48:00.342+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:48:02.574+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:48:02.737+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:48:02.736+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:48:03.041+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.726 seconds
[2025-05-28T15:48:33.626+0000] {processor.py:161} INFO - Started process (PID=2241) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:48:33.628+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:48:33.630+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:48:33.629+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:48:34.836+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:48:34.893+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:48:34.891+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:48:34.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.358 seconds
[2025-05-28T15:49:05.262+0000] {processor.py:161} INFO - Started process (PID=2259) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:49:05.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:49:05.290+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:49:05.289+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:49:06.958+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:49:06.994+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:49:06.993+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:49:07.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.843 seconds
[2025-05-28T15:49:37.823+0000] {processor.py:161} INFO - Started process (PID=2277) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:49:37.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:49:37.830+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:49:37.829+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:49:39.254+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:49:39.304+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:49:39.303+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:49:39.367+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.555 seconds
[2025-05-28T15:50:10.013+0000] {processor.py:161} INFO - Started process (PID=2295) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:50:10.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:50:10.029+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:50:10.028+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:50:13.476+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:50:13.586+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:50:13.585+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:50:13.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.766 seconds
[2025-05-28T15:50:44.577+0000] {processor.py:161} INFO - Started process (PID=2323) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:50:44.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:50:44.583+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:50:44.582+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:50:45.975+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:50:46.009+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:50:46.009+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:50:46.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.525 seconds
[2025-05-28T15:51:16.385+0000] {processor.py:161} INFO - Started process (PID=2343) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:51:16.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:51:16.393+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:51:16.392+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:51:18.952+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:51:19.073+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:51:19.071+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:51:19.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.994 seconds
[2025-05-28T15:51:49.559+0000] {processor.py:161} INFO - Started process (PID=2361) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:51:49.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:51:49.583+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:51:49.582+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:51:55.486+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:51:55.646+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:51:55.635+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:51:56.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.516 seconds
[2025-05-28T15:52:26.952+0000] {processor.py:161} INFO - Started process (PID=2385) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:52:26.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:52:26.969+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:52:26.968+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:52:31.796+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:52:32.033+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:52:32.032+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:52:32.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.419 seconds
[2025-05-28T15:53:02.968+0000] {processor.py:161} INFO - Started process (PID=2402) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:53:02.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:53:02.986+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:53:02.985+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:53:07.826+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:53:07.965+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:53:07.964+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:53:08.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.304 seconds
[2025-05-28T15:53:41.826+0000] {processor.py:161} INFO - Started process (PID=2466) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:53:41.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:53:41.925+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:53:41.923+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:54:12.401+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:54:12.400+0000] {timeout.py:68} ERROR - Process timed out, PID: 2466
[2025-05-28T15:54:43.724+0000] {processor.py:161} INFO - Started process (PID=2506) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:54:43.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:54:43.839+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:54:43.838+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:54:50.035+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:54:51.145+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:54:51.144+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:54:51.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 7.809 seconds
[2025-05-28T15:55:22.011+0000] {processor.py:161} INFO - Started process (PID=2545) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:55:22.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:55:22.027+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:55:22.026+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:55:26.559+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:55:27.178+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:55:27.177+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:55:27.345+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:55:27.345+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-17 00:00:00+00:00, run_after=2024-09-18 00:00:00+00:00
[2025-05-28T15:55:27.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.499 seconds
[2025-05-28T15:55:58.198+0000] {processor.py:161} INFO - Started process (PID=2620) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:55:58.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:55:58.202+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:55:58.201+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:55:59.790+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:55:59.834+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:55:59.833+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:55:59.908+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.720 seconds
[2025-05-28T15:56:30.142+0000] {processor.py:161} INFO - Started process (PID=2638) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:56:30.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:56:30.148+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:56:30.147+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:56:34.289+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:56:34.408+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:56:34.407+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:56:34.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.425 seconds
[2025-05-28T15:57:05.184+0000] {processor.py:161} INFO - Started process (PID=2657) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:57:05.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:57:05.190+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:57:05.188+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:57:07.309+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:57:07.354+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:57:07.353+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:57:07.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.272 seconds
[2025-05-28T15:57:37.833+0000] {processor.py:161} INFO - Started process (PID=2675) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:57:37.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:57:37.839+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:57:37.838+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:57:39.116+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:57:39.151+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:57:39.150+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:57:39.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.405 seconds
[2025-05-28T15:58:09.441+0000] {processor.py:161} INFO - Started process (PID=2693) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:58:09.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:58:09.448+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:58:09.447+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:58:11.475+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:58:11.519+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:58:11.518+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:58:11.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.156 seconds
[2025-05-28T15:58:41.783+0000] {processor.py:161} INFO - Started process (PID=2711) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:58:41.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:58:41.786+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:58:41.785+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:58:42.939+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:58:43.137+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:58:43.135+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:58:43.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.707 seconds
[2025-05-28T15:59:15.228+0000] {processor.py:161} INFO - Started process (PID=2728) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:59:15.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:59:15.243+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:59:15.232+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:59:19.352+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:59:19.423+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:59:19.422+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:59:19.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.321 seconds
[2025-05-28T15:59:50.256+0000] {processor.py:161} INFO - Started process (PID=2752) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:59:50.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T15:59:50.260+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:59:50.259+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:59:52.958+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T15:59:53.005+0000] {logging_mixin.py:188} INFO - [2025-05-28T15:59:53.004+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T15:59:53.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.857 seconds
[2025-05-28T16:00:24.652+0000] {processor.py:161} INFO - Started process (PID=2779) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:00:24.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:00:24.666+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:00:24.665+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:00:27.067+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:00:27.232+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:00:27.220+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:00:27.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.955 seconds
[2025-05-28T16:00:57.763+0000] {processor.py:161} INFO - Started process (PID=2809) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:00:57.767+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:00:57.769+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:00:57.768+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:00:59.509+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:00:59.662+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:00:59.662+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:00:59.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.157 seconds
[2025-05-28T16:01:30.872+0000] {processor.py:161} INFO - Started process (PID=2836) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:01:30.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:01:30.898+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:01:30.897+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:01:34.364+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:01:34.475+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:01:34.465+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:01:34.683+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.835 seconds
[2025-05-28T16:02:05.344+0000] {processor.py:161} INFO - Started process (PID=2856) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:02:05.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:02:05.373+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:02:05.372+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:02:09.207+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:02:09.305+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:02:09.304+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:02:09.459+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.151 seconds
[2025-05-28T16:02:40.256+0000] {processor.py:161} INFO - Started process (PID=2883) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:02:40.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:02:40.267+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:02:40.266+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:02:41.469+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:02:41.540+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:02:41.540+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:02:41.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.522 seconds
[2025-05-28T16:03:12.345+0000] {processor.py:161} INFO - Started process (PID=2923) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:03:12.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:03:12.351+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:03:12.350+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:03:17.063+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:03:17.242+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:03:17.241+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:03:17.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.146 seconds
[2025-05-28T16:03:48.333+0000] {processor.py:161} INFO - Started process (PID=2956) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:03:48.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:03:48.342+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:03:48.341+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:03:51.473+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:03:51.517+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:03:51.516+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:03:51.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.342 seconds
[2025-05-28T16:04:22.473+0000] {processor.py:161} INFO - Started process (PID=2980) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:04:22.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:04:22.477+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:04:22.476+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:04:24.866+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:04:24.917+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:04:24.916+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:04:25.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.596 seconds
[2025-05-28T16:04:55.575+0000] {processor.py:161} INFO - Started process (PID=2999) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:04:55.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:04:55.593+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:04:55.592+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:04:56.762+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:04:56.855+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:04:56.854+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:04:56.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.405 seconds
[2025-05-28T16:05:27.641+0000] {processor.py:161} INFO - Started process (PID=3023) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:05:27.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:05:27.651+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:05:27.650+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:05:31.580+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:05:31.700+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:05:31.699+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:05:32.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.519 seconds
[2025-05-28T16:06:03.024+0000] {processor.py:161} INFO - Started process (PID=3060) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:06:03.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:06:03.030+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:06:03.029+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:06:04.682+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:06:04.746+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:06:04.745+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:06:04.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.900 seconds
[2025-05-28T16:06:35.584+0000] {processor.py:161} INFO - Started process (PID=3078) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:06:35.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:06:35.589+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:06:35.588+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:06:37.287+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:06:37.329+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:06:37.328+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:06:37.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.817 seconds
[2025-05-28T16:07:07.505+0000] {processor.py:161} INFO - Started process (PID=3096) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:07:07.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:07:07.508+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:07:07.508+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:07:08.849+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:07:08.904+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:07:08.904+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:07:09.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.529 seconds
[2025-05-28T16:07:39.530+0000] {processor.py:161} INFO - Started process (PID=3121) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:07:39.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:07:39.536+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:07:39.535+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:07:42.044+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:07:42.094+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:07:42.093+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:07:42.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.741 seconds
[2025-05-28T16:08:12.874+0000] {processor.py:161} INFO - Started process (PID=3142) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:08:12.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:08:12.878+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:08:12.877+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:08:14.926+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:08:14.995+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:08:14.985+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:08:15.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.283 seconds
[2025-05-28T16:08:45.587+0000] {processor.py:161} INFO - Started process (PID=3173) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:08:45.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:08:45.593+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:08:45.590+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:08:49.698+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:08:49.846+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:08:49.845+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:08:50.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.595 seconds
[2025-05-28T16:09:22.793+0000] {processor.py:161} INFO - Started process (PID=3201) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:09:22.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:09:22.914+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:09:22.913+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:09:33.464+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:09:33.737+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:09:33.725+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:09:33.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 11.233 seconds
[2025-05-28T16:10:04.992+0000] {processor.py:161} INFO - Started process (PID=3226) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:10:04.994+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:10:04.995+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:10:04.995+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:10:06.990+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:10:07.099+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:10:07.098+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:10:07.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.258 seconds
[2025-05-28T16:10:37.443+0000] {processor.py:161} INFO - Started process (PID=3244) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:10:37.444+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:10:37.445+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:10:37.445+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:10:38.930+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:10:38.988+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:10:38.987+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:10:39.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.642 seconds
[2025-05-28T16:11:09.304+0000] {processor.py:161} INFO - Started process (PID=3268) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:11:09.318+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:11:09.320+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:11:09.320+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:11:10.829+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:11:10.907+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:11:10.906+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:11:11.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.825 seconds
[2025-05-28T16:11:41.646+0000] {processor.py:161} INFO - Started process (PID=3298) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:11:41.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:11:41.649+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:11:41.648+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:11:43.996+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:11:44.075+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:11:44.073+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:11:44.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.629 seconds
[2025-05-28T16:12:14.391+0000] {processor.py:161} INFO - Started process (PID=3331) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:12:14.393+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:12:14.395+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:12:14.394+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:12:16.665+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:12:16.720+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:12:16.718+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:12:16.827+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.447 seconds
[2025-05-28T16:12:47.067+0000] {processor.py:161} INFO - Started process (PID=3369) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:12:47.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:12:47.075+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:12:47.074+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:12:49.004+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:12:49.058+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:12:49.057+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:12:49.123+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.082 seconds
[2025-05-28T16:13:20.052+0000] {processor.py:161} INFO - Started process (PID=3400) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:13:20.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:13:20.056+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:13:20.055+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:13:22.498+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:13:22.555+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:13:22.554+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:13:22.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.613 seconds
[2025-05-28T16:13:52.852+0000] {processor.py:161} INFO - Started process (PID=3431) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:13:52.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:13:52.854+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:13:52.854+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:13:53.711+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:13:53.770+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:13:53.769+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:13:53.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.009 seconds
[2025-05-28T16:14:24.178+0000] {processor.py:161} INFO - Started process (PID=3450) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:14:24.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:14:24.181+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:14:24.180+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:14:25.110+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:14:25.149+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:14:25.148+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:14:25.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.084 seconds
[2025-05-28T16:14:55.564+0000] {processor.py:161} INFO - Started process (PID=3468) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:14:55.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:14:55.567+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:14:55.567+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:14:56.676+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:14:56.720+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:14:56.718+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:14:56.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.233 seconds
[2025-05-28T16:15:26.902+0000] {processor.py:161} INFO - Started process (PID=3486) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:15:26.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:15:26.904+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:15:26.904+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:15:27.579+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:15:27.615+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:15:27.614+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:15:27.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.782 seconds
[2025-05-28T16:15:57.971+0000] {processor.py:161} INFO - Started process (PID=3508) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:15:57.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:15:57.974+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:15:57.974+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:15:59.024+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:15:59.065+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:15:59.064+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:15:59.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.167 seconds
[2025-05-28T16:16:29.560+0000] {processor.py:161} INFO - Started process (PID=3532) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:16:29.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:16:29.564+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:16:29.564+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:16:30.386+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:16:30.427+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:16:30.426+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:16:30.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.947 seconds
[2025-05-28T16:17:00.888+0000] {processor.py:161} INFO - Started process (PID=3553) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:17:00.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:17:00.893+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:17:00.892+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:17:01.992+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:17:02.038+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:17:02.037+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:17:02.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.258 seconds
[2025-05-28T16:17:32.495+0000] {processor.py:161} INFO - Started process (PID=3576) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:17:32.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:17:32.506+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:17:32.504+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:17:34.786+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:17:34.862+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:17:34.861+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:17:35.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.655 seconds
[2025-05-28T16:18:05.439+0000] {processor.py:161} INFO - Started process (PID=3603) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:18:05.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:18:05.442+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:18:05.442+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:18:06.434+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:18:06.574+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:18:06.573+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:18:06.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.281 seconds
[2025-05-28T16:18:37.108+0000] {processor.py:161} INFO - Started process (PID=3636) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:18:37.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:18:37.111+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:18:37.111+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:18:37.951+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:18:37.997+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:18:37.996+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:18:38.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.983 seconds
[2025-05-28T16:19:08.424+0000] {processor.py:161} INFO - Started process (PID=3669) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:19:08.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:19:08.427+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:19:08.427+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:19:09.253+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:19:09.306+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:19:09.305+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:19:09.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.980 seconds
[2025-05-28T16:19:39.619+0000] {processor.py:161} INFO - Started process (PID=3696) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:19:39.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:19:39.622+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:19:39.621+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:19:40.482+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:19:40.519+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:19:40.518+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:19:40.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.979 seconds
[2025-05-28T16:20:11.025+0000] {processor.py:161} INFO - Started process (PID=3717) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:20:11.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:20:11.029+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:20:11.028+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:20:12.218+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:20:12.258+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:20:12.257+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:20:12.326+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.312 seconds
[2025-05-28T16:20:42.673+0000] {processor.py:161} INFO - Started process (PID=3738) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:20:42.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:20:42.676+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:20:42.676+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:20:43.370+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:20:43.409+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:20:43.409+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:20:43.511+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.850 seconds
[2025-05-28T16:21:14.015+0000] {processor.py:161} INFO - Started process (PID=3771) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:21:14.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:21:14.028+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:21:14.024+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:21:15.719+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:21:15.757+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:21:15.756+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:21:15.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.839 seconds
[2025-05-28T16:21:47.054+0000] {processor.py:161} INFO - Started process (PID=3798) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:21:47.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:21:47.061+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:21:47.060+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:21:48.165+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:21:48.225+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:21:48.224+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:21:48.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.297 seconds
[2025-05-28T16:22:18.948+0000] {processor.py:161} INFO - Started process (PID=3822) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:22:18.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T16:22:18.953+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:22:18.952+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:22:21.779+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T16:22:21.866+0000] {logging_mixin.py:188} INFO - [2025-05-28T16:22:21.865+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T16:22:21.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.063 seconds
[2025-05-28T19:14:53.149+0000] {processor.py:161} INFO - Started process (PID=3868) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:14:53.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:14:53.214+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:14:53.213+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:15:24.306+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:15:24.305+0000] {timeout.py:68} ERROR - Process timed out, PID: 3868
[2025-05-28T19:15:56.022+0000] {processor.py:161} INFO - Started process (PID=3908) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:15:56.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:15:56.079+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:15:56.074+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:16:06.070+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:16:07.163+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:16:07.162+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:16:08.443+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 12.477 seconds
[2025-05-28T19:16:42.840+0000] {processor.py:161} INFO - Started process (PID=3937) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:16:42.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:16:42.870+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:16:42.869+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:16:48.160+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:16:48.405+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:16:48.404+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:16:48.824+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.050 seconds
[2025-05-28T19:17:20.311+0000] {processor.py:161} INFO - Started process (PID=3999) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:17:20.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:17:20.341+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:17:20.340+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:17:28.490+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:17:28.597+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:17:28.596+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:17:28.752+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 8.792 seconds
[2025-05-28T19:17:59.466+0000] {processor.py:161} INFO - Started process (PID=4017) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:17:59.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:17:59.592+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:17:59.591+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:18:02.632+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:18:02.745+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:18:02.744+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:18:03.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.661 seconds
[2025-05-28T19:18:34.629+0000] {processor.py:161} INFO - Started process (PID=4035) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:18:34.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:18:34.663+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:18:34.661+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:18:40.450+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:18:40.615+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:18:40.614+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:18:40.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.247 seconds
[2025-05-28T19:19:12.473+0000] {processor.py:161} INFO - Started process (PID=4061) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:19:12.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:19:12.489+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:19:12.488+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:19:14.526+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:19:14.586+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:19:14.585+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:19:14.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.284 seconds
[2025-05-28T19:19:46.221+0000] {processor.py:161} INFO - Started process (PID=4077) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:19:46.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:19:46.265+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:19:46.263+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:19:53.268+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:19:53.632+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:19:53.630+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:19:55.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 8.993 seconds
[2025-05-28T19:20:26.605+0000] {processor.py:161} INFO - Started process (PID=4098) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:20:26.628+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:20:26.646+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:20:26.645+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:20:33.257+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:20:33.665+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:20:33.651+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:20:35.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 8.673 seconds
[2025-05-28T19:21:07.148+0000] {processor.py:161} INFO - Started process (PID=4117) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:21:07.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:21:07.195+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:21:07.194+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:21:14.068+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:21:15.278+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:21:15.277+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:21:15.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 8.621 seconds
[2025-05-28T19:21:46.250+0000] {processor.py:161} INFO - Started process (PID=4140) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:21:46.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:21:46.267+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:21:46.266+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:21:53.301+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:21:53.619+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:21:53.604+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:21:54.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 7.923 seconds
[2025-05-28T19:22:25.152+0000] {processor.py:161} INFO - Started process (PID=4159) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:22:25.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:22:25.165+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:22:25.164+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:22:31.480+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:22:31.694+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:22:31.693+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:22:33.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 8.099 seconds
[2025-05-28T19:23:03.873+0000] {processor.py:161} INFO - Started process (PID=4178) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:23:03.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:23:03.884+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:23:03.878+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:23:10.839+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:23:12.022+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:23:12.021+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:23:12.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 8.525 seconds
[2025-05-28T19:23:43.109+0000] {processor.py:161} INFO - Started process (PID=4210) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:23:43.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:23:43.128+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:23:43.120+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:23:49.650+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:23:49.886+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:23:49.885+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:23:50.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 7.202 seconds
[2025-05-28T19:24:20.710+0000] {processor.py:161} INFO - Started process (PID=4240) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:24:20.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:24:20.723+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:24:20.721+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:24:23.608+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:24:23.797+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:24:23.796+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:24:24.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.548 seconds
[2025-05-28T19:24:56.153+0000] {processor.py:161} INFO - Started process (PID=4272) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:24:56.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:24:56.218+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:24:56.217+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:25:04.483+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:25:04.881+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:25:04.870+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:25:06.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 10.964 seconds
[2025-05-28T19:25:38.085+0000] {processor.py:161} INFO - Started process (PID=4303) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:25:38.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:25:38.113+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:25:38.112+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:25:46.893+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:25:48.997+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:25:48.996+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:25:49.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 11.738 seconds
[2025-05-28T19:26:21.550+0000] {processor.py:161} INFO - Started process (PID=4340) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:26:21.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:26:21.568+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:26:21.565+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:26:31.775+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:26:32.432+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:26:32.430+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:26:33.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 12.149 seconds
[2025-05-28T19:27:05.625+0000] {processor.py:161} INFO - Started process (PID=4379) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:27:05.671+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:27:05.688+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:27:05.687+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:27:14.637+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:27:15.249+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:27:15.232+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:27:18.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 13.222 seconds
[2025-05-28T19:27:49.644+0000] {processor.py:161} INFO - Started process (PID=4422) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:27:49.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:27:49.679+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:27:49.678+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:27:56.421+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:27:57.653+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:27:57.640+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:27:58.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 8.556 seconds
[2025-05-28T19:28:38.497+0000] {processor.py:161} INFO - Started process (PID=4444) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:28:38.556+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:28:38.595+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:28:38.593+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:28:50.271+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:28:50.663+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:28:50.661+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:28:51.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 13.189 seconds
[2025-05-28T19:29:23.474+0000] {processor.py:161} INFO - Started process (PID=4468) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:29:23.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:29:23.507+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:29:23.506+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:29:31.313+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:29:31.618+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:29:31.612+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:29:33.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 10.476 seconds
[2025-05-28T19:30:05.357+0000] {processor.py:161} INFO - Started process (PID=4489) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:30:05.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-05-28T19:30:05.389+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:30:05.388+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:30:13.835+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-05-28T19:30:15.235+0000] {logging_mixin.py:188} INFO - [2025-05-28T19:30:15.228+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-05-28T19:30:15.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 10.462 seconds
