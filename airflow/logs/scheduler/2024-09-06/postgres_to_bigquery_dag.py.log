[2024-09-06T04:16:04.739+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:16:04.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:16:04.746+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:16:04.745+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:16:11.224+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:16:11.214+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:16:11.225+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:16:11.256+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.554 seconds
[2024-09-06T04:16:42.364+0000] {processor.py:161} INFO - Started process (PID=218) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:16:42.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:16:42.390+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:16:42.390+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:16:47.814+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:16:47.793+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:16:47.822+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:16:47.875+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.595 seconds
[2024-09-06T04:17:18.008+0000] {processor.py:161} INFO - Started process (PID=238) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:17:18.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:17:18.013+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:17:18.012+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:17:20.442+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:17:20.422+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:17:20.443+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:17:20.709+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.710 seconds
[2024-09-06T04:17:51.283+0000] {processor.py:161} INFO - Started process (PID=257) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:17:51.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:17:51.292+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:17:51.291+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:17:54.353+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:17:54.233+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:17:54.385+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:17:54.461+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.208 seconds
[2024-09-06T04:30:52.504+0000] {processor.py:161} INFO - Started process (PID=169) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:30:52.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:30:52.517+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:30:52.516+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:30:56.784+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:30:56.766+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:30:56.786+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:30:56.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.404 seconds
[2024-09-06T04:31:27.162+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:31:27.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:31:27.166+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:31:27.166+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:31:28.658+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:31:28.651+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:31:28.661+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:31:28.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.561 seconds
[2024-09-06T04:31:59.030+0000] {processor.py:161} INFO - Started process (PID=213) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:31:59.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:31:59.038+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:31:59.037+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:32:00.155+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:32:00.149+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:32:00.156+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:32:00.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.165 seconds
[2024-09-06T04:32:30.317+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:32:30.318+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:32:30.321+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:32:30.320+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:32:31.102+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:32:31.094+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:32:31.104+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:32:31.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.822 seconds
[2024-09-06T04:33:01.570+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:33:01.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:33:01.575+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:33:01.574+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:33:02.750+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:33:02.743+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:33:02.752+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:33:02.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.234 seconds
[2024-09-06T04:33:33.217+0000] {processor.py:161} INFO - Started process (PID=277) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:33:33.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:33:33.220+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:33:33.220+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:33:34.544+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:33:34.537+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:33:34.546+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:33:34.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.372 seconds
[2024-09-06T04:34:04.888+0000] {processor.py:161} INFO - Started process (PID=295) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:34:04.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:34:04.895+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:34:04.894+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:34:05.997+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:34:05.990+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:34:05.999+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:34:06.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.143 seconds
[2024-09-06T04:34:36.430+0000] {processor.py:161} INFO - Started process (PID=313) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:34:36.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:34:36.434+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:34:36.434+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:34:37.257+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:34:37.249+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:34:37.258+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:34:37.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.865 seconds
[2024-09-06T04:35:07.787+0000] {processor.py:161} INFO - Started process (PID=331) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:35:07.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:35:07.792+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:35:07.792+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:35:08.716+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:35:08.708+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:35:08.717+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:35:08.747+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.972 seconds
[2024-09-06T04:35:39.125+0000] {processor.py:161} INFO - Started process (PID=347) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:35:39.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:35:39.129+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:35:39.129+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:35:40.114+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:35:40.107+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:35:40.115+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:35:40.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.030 seconds
[2024-09-06T04:36:10.536+0000] {processor.py:161} INFO - Started process (PID=367) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:36:10.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:36:10.540+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:36:10.539+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:36:11.451+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:36:11.444+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:36:11.452+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:36:11.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.949 seconds
[2024-09-06T04:36:42.570+0000] {processor.py:161} INFO - Started process (PID=382) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:36:42.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:36:42.588+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:36:42.587+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:36:46.452+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:36:46.442+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:36:46.464+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:36:46.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.987 seconds
[2024-09-06T04:37:20.117+0000] {processor.py:161} INFO - Started process (PID=400) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:37:20.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:37:20.155+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:37:20.154+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:37:28.129+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:37:27.702+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:37:28.171+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:37:28.261+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 8.179 seconds
[2024-09-06T04:38:03.321+0000] {processor.py:161} INFO - Started process (PID=424) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:38:03.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:38:03.341+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:38:03.336+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:38:19.430+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:38:18.678+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:38:19.495+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:38:19.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 16.246 seconds
[2024-09-06T04:38:49.956+0000] {processor.py:161} INFO - Started process (PID=445) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:38:49.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:38:49.966+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:38:49.966+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:38:54.031+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:38:54.022+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:38:54.033+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:38:54.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.188 seconds
[2024-09-06T04:39:24.448+0000] {processor.py:161} INFO - Started process (PID=484) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:39:24.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:39:24.504+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:39:24.504+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:39:37.620+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:39:37.582+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:39:37.637+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:39:37.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 13.424 seconds
[2024-09-06T04:40:09.239+0000] {processor.py:161} INFO - Started process (PID=516) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:40:09.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:40:09.286+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:40:09.285+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:40:12.246+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:40:12.077+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:40:12.248+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:40:12.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.147 seconds
[2024-09-06T04:40:42.490+0000] {processor.py:161} INFO - Started process (PID=534) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:40:42.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:40:42.495+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:40:42.495+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:40:44.087+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:40:44.075+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:40:44.089+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:40:44.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.653 seconds
[2024-09-06T04:41:14.708+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:41:14.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:41:14.726+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:41:14.726+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:41:18.435+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:41:18.344+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:41:18.445+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:41:18.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.986 seconds
[2024-09-06T04:41:49.322+0000] {processor.py:161} INFO - Started process (PID=570) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:41:49.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:41:49.330+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:41:49.329+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:41:52.354+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:41:52.342+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:41:52.363+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:41:52.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.119 seconds
[2024-09-06T04:42:23.010+0000] {processor.py:161} INFO - Started process (PID=588) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:42:23.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:42:23.015+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:42:23.014+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:42:24.172+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:42:24.167+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:42:24.173+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:42:24.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.195 seconds
[2024-09-06T04:42:54.498+0000] {processor.py:161} INFO - Started process (PID=606) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:42:54.501+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:42:54.504+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:42:54.504+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:42:55.711+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:42:55.706+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:42:55.712+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:42:55.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.259 seconds
[2024-09-06T04:43:26.753+0000] {processor.py:161} INFO - Started process (PID=624) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:43:26.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:43:26.758+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:43:26.757+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:43:28.850+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:43:28.818+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:43:28.854+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:43:28.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.186 seconds
[2024-09-06T04:43:59.255+0000] {processor.py:161} INFO - Started process (PID=642) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:43:59.259+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:43:59.263+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:43:59.262+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:44:00.641+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:44:00.633+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:44:00.642+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:44:00.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.422 seconds
[2024-09-06T04:44:31.194+0000] {processor.py:161} INFO - Started process (PID=660) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:44:31.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:44:31.199+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:44:31.199+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:44:32.521+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:44:32.512+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:44:32.522+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:44:32.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.395 seconds
[2024-09-06T04:45:02.720+0000] {processor.py:161} INFO - Started process (PID=684) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:45:02.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:45:02.724+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:45:02.723+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:45:04.166+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:45:04.158+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:45:04.167+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:45:04.203+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.495 seconds
[2024-09-06T04:45:34.515+0000] {processor.py:161} INFO - Started process (PID=702) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:45:34.517+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:45:34.521+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:45:34.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:45:35.690+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:45:35.684+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:45:35.691+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:45:35.717+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.211 seconds
[2024-09-06T04:46:06.162+0000] {processor.py:161} INFO - Started process (PID=720) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:46:06.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:46:06.167+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:46:06.166+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:46:07.538+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:46:07.532+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:46:07.540+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:46:07.579+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.426 seconds
[2024-09-06T04:46:38.231+0000] {processor.py:161} INFO - Started process (PID=738) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:46:38.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:46:38.236+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:46:38.235+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:46:39.489+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:46:39.476+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:46:39.490+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:46:39.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.300 seconds
[2024-09-06T04:47:09.909+0000] {processor.py:161} INFO - Started process (PID=759) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:47:09.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:47:09.914+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:47:09.913+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:47:12.004+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:47:11.996+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:47:12.006+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:47:12.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.132 seconds
[2024-09-06T04:47:42.499+0000] {processor.py:161} INFO - Started process (PID=778) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:47:42.501+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:47:42.504+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:47:42.503+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:47:43.724+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:47:43.716+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:47:43.727+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:47:43.764+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.278 seconds
[2024-09-06T04:48:13.907+0000] {processor.py:161} INFO - Started process (PID=796) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:48:13.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:48:13.913+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:48:13.912+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:48:14.937+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:48:14.930+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:48:14.938+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:48:14.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.065 seconds
[2024-09-06T04:48:45.065+0000] {processor.py:161} INFO - Started process (PID=814) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:48:45.066+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:48:45.068+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:48:45.068+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:48:46.008+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:48:46.002+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:48:46.009+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:48:46.050+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.993 seconds
[2024-09-06T04:49:16.964+0000] {processor.py:161} INFO - Started process (PID=832) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:49:16.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:49:16.978+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:49:16.977+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:49:18.569+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:49:18.533+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:49:18.574+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:49:18.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.728 seconds
[2024-09-06T04:49:49.427+0000] {processor.py:161} INFO - Started process (PID=850) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:49:49.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:49:49.431+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:49:49.431+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:49:50.827+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:49:50.820+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:49:50.828+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:49:50.859+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.439 seconds
[2024-09-06T04:50:21.415+0000] {processor.py:161} INFO - Started process (PID=868) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:50:21.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:50:21.421+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:50:21.420+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:50:22.550+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:50:22.544+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:50:22.551+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:50:22.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.199 seconds
[2024-09-06T04:50:53.254+0000] {processor.py:161} INFO - Started process (PID=886) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:50:53.255+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:50:53.258+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:50:53.257+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:50:54.607+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:50:54.598+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:50:54.608+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:50:54.639+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.394 seconds
[2024-09-06T04:51:24.758+0000] {processor.py:161} INFO - Started process (PID=904) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:51:24.761+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:51:24.765+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:51:24.765+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:51:25.789+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:51:25.783+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:51:25.790+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:51:25.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.076 seconds
[2024-09-06T04:51:56.308+0000] {processor.py:161} INFO - Started process (PID=923) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:51:56.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:51:56.312+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:51:56.312+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:51:57.460+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:51:57.452+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:51:57.462+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:51:57.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.191 seconds
[2024-09-06T04:52:41.250+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:52:41.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:52:41.257+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:52:41.256+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:52:44.287+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:52:44.280+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:52:44.291+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:52:44.317+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.083 seconds
[2024-09-06T04:53:14.586+0000] {processor.py:161} INFO - Started process (PID=185) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:53:14.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:53:14.592+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:53:14.591+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:53:15.793+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:53:15.788+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:53:15.795+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:53:15.833+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.262 seconds
[2024-09-06T04:53:46.372+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:53:46.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:53:46.377+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:53:46.376+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:53:47.964+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:53:47.958+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:53:47.965+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:53:47.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.640 seconds
[2024-09-06T04:54:18.783+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:54:18.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:54:18.802+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:54:18.801+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:54:20.195+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:54:20.190+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:54:20.196+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:54:20.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.475 seconds
[2024-09-06T04:54:50.805+0000] {processor.py:161} INFO - Started process (PID=243) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:54:50.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:54:50.838+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:54:50.837+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:54:54.239+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:54:54.227+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:54:54.241+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:54:54.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.506 seconds
[2024-09-06T04:55:24.540+0000] {processor.py:161} INFO - Started process (PID=261) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:55:24.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:55:24.546+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:55:24.545+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:55:25.740+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:55:25.732+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:55:25.741+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:55:25.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.243 seconds
[2024-09-06T04:55:56.178+0000] {processor.py:161} INFO - Started process (PID=281) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:55:56.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:55:56.184+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:55:56.184+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:55:57.367+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:55:57.358+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:55:57.368+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:55:57.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.234 seconds
[2024-09-06T04:56:28.046+0000] {processor.py:161} INFO - Started process (PID=297) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:56:28.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:56:28.056+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:56:28.055+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:56:30.476+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:56:30.470+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:56:30.479+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:56:30.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.487 seconds
[2024-09-06T04:57:01.048+0000] {processor.py:161} INFO - Started process (PID=317) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:57:01.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:57:01.064+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:57:01.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:57:02.472+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:57:02.463+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file('/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:57:02.475+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:57:02.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.489 seconds
[2024-09-06T04:57:27.489+0000] {processor.py:161} INFO - Started process (PID=329) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:57:27.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:57:27.495+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:57:27.494+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:57:27.531+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:57:27.528+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33
    credentials = service_account.Credentials.from_service_account_file(/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                                                                                                                  ^
SyntaxError: invalid decimal literal
[2024-09-06T04:57:27.545+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:57:27.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.114 seconds
[2024-09-06T04:57:28.601+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:57:28.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:57:28.609+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:57:28.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:57:28.639+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:57:28.637+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json')
                                                                        ^
SyntaxError: unterminated string literal (detected at line 33)
[2024-09-06T04:57:28.641+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:57:28.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.115 seconds
[2024-09-06T04:57:31.935+0000] {processor.py:161} INFO - Started process (PID=343) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:57:31.949+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:57:31.962+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:57:31.961+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:57:33.749+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:57:33.732+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:57:33.751+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:57:33.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.889 seconds
[2024-09-06T04:58:04.372+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:58:04.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:58:04.379+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:58:04.378+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:58:05.735+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:58:05.728+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:58:05.736+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:58:05.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.417 seconds
[2024-09-06T04:58:37.589+0000] {processor.py:161} INFO - Started process (PID=380) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:58:37.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:58:37.667+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:58:37.666+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:58:43.236+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:58:43.226+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:58:43.237+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:58:43.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.737 seconds
[2024-09-06T04:59:13.916+0000] {processor.py:161} INFO - Started process (PID=404) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:59:13.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:59:13.933+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:59:13.931+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:59:15.951+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:59:15.946+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:59:15.952+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:59:15.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.084 seconds
[2024-09-06T04:59:46.494+0000] {processor.py:161} INFO - Started process (PID=422) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:59:46.501+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T04:59:46.507+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:59:46.506+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:59:47.645+0000] {logging_mixin.py:188} INFO - [2024-09-06T04:59:47.638+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T04:59:47.646+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T04:59:47.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.191 seconds
[2024-09-06T05:00:17.976+0000] {processor.py:161} INFO - Started process (PID=440) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:00:17.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:00:17.987+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:00:17.986+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:00:19.809+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:00:19.799+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:00:19.810+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:00:19.870+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.918 seconds
[2024-09-06T05:03:03.587+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:03:03.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:03:03.597+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:03:03.595+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:03:03.705+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:03:03.702+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33
    os.path.
            ^
SyntaxError: invalid syntax
[2024-09-06T05:03:03.709+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:03:03.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.236 seconds
[2024-09-06T05:03:34.157+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:03:34.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:03:34.162+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:03:34.161+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:03:34.194+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:03:34.192+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33
    os.path.
            ^
SyntaxError: invalid syntax
[2024-09-06T05:03:34.196+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:03:34.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.088 seconds
[2024-09-06T05:04:04.585+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:04:04.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:04:04.591+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:04:04.590+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:04:04.629+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:04:04.626+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33
    os.path.
            ^
SyntaxError: invalid syntax
[2024-09-06T05:04:04.630+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:04:04.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.106 seconds
[2024-09-06T05:04:35.139+0000] {processor.py:161} INFO - Started process (PID=219) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:04:35.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:04:35.143+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:04:35.143+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:04:35.174+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:04:35.172+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33
    os.path.
            ^
SyntaxError: invalid syntax
[2024-09-06T05:04:35.175+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:04:35.214+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.087 seconds
[2024-09-06T05:05:05.645+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:05:05.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:05:05.649+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:05:05.649+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:05:05.681+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:05:05.680+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33
    os.path.
            ^
SyntaxError: invalid syntax
[2024-09-06T05:05:05.682+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:05:05.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.080 seconds
[2024-09-06T05:05:36.011+0000] {processor.py:161} INFO - Started process (PID=252) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:05:36.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:05:36.014+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:05:36.014+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:05:36.047+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:05:36.045+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33
    os.path.
            ^
SyntaxError: invalid syntax
[2024-09-06T05:05:36.048+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:05:36.083+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.080 seconds
[2024-09-06T05:06:06.291+0000] {processor.py:161} INFO - Started process (PID=269) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:06:06.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:06:06.295+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:06:06.295+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:06:06.327+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:06:06.325+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33
    os.path.
            ^
SyntaxError: invalid syntax
[2024-09-06T05:06:06.328+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:06:06.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.084 seconds
[2024-09-06T05:06:36.446+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:06:36.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:06:36.453+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:06:36.452+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:06:36.479+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:06:36.476+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33
    os.path.
            ^
SyntaxError: invalid syntax
[2024-09-06T05:06:36.481+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:06:36.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.089 seconds
[2024-09-06T05:07:07.066+0000] {processor.py:161} INFO - Started process (PID=302) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:07:07.068+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:07:07.072+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:07:07.071+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:07:07.105+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:07:07.104+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33
    os.path.
            ^
SyntaxError: invalid syntax
[2024-09-06T05:07:07.106+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:07:07.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.101 seconds
[2024-09-06T05:07:37.656+0000] {processor.py:161} INFO - Started process (PID=319) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:07:37.657+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:07:37.662+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:07:37.662+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:07:37.684+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:07:37.682+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33
    os.path.
            ^
SyntaxError: invalid syntax
[2024-09-06T05:07:37.685+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:07:37.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.072 seconds
[2024-09-06T05:08:08.616+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:08.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:08:08.622+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:08:08.622+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:08.653+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:08:08.651+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33
    os.path.
            ^
SyntaxError: invalid syntax
[2024-09-06T05:08:08.656+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:08.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.088 seconds
[2024-09-06T05:08:27.409+0000] {processor.py:161} INFO - Started process (PID=352) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:27.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:08:27.414+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:08:27.414+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:29.889+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:08:29.866+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    os.path.abspath()
    ^^^^^^^^^
AttributeError: module 'posixpath' has no attribute 'a'
[2024-09-06T05:08:29.892+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:29.933+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.541 seconds
[2024-09-06T05:08:38.145+0000] {processor.py:161} INFO - Started process (PID=358) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:38.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:08:38.153+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:08:38.152+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:40.175+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:08:40.163+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 36, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:08:40.176+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:40.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.077 seconds
[2024-09-06T05:08:41.699+0000] {processor.py:161} INFO - Started process (PID=364) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:41.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:08:41.749+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:08:41.748+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:43.966+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:08:43.928+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 33, in <module>
    print(os.path.abspath("my-etl-project-434409-3e70c40f6d3a.json")
    ^^^^^^^
NameError: name 'printos' is not defined. Did you mean: 'print'?
[2024-09-06T05:08:43.975+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:44.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.326 seconds
[2024-09-06T05:08:45.359+0000] {processor.py:161} INFO - Started process (PID=376) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:45.360+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:08:45.364+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:08:45.363+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:47.063+0000] {logging_mixin.py:188} INFO - /opt/airflow/my-etl-project-434409-3e70c40f6d3a.json
[2024-09-06T05:08:47.078+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:08:47.065+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 36, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:08:47.080+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:08:47.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.767 seconds
[2024-09-06T05:09:17.716+0000] {processor.py:161} INFO - Started process (PID=394) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:09:17.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:09:17.720+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:09:17.720+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:09:19.164+0000] {logging_mixin.py:188} INFO - /opt/airflow/my-etl-project-434409-3e70c40f6d3a.json
[2024-09-06T05:09:19.171+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:09:19.165+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 36, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:09:19.172+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:09:19.203+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.499 seconds
[2024-09-06T05:10:09.541+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:10:09.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:10:09.546+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:10:09.546+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:10:11.575+0000] {logging_mixin.py:188} INFO - /opt/airflow/my-etl-project-434409-3e70c40f6d3a.json
[2024-09-06T05:10:11.628+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:10:11.600+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 36, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:10:11.630+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:10:11.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.163 seconds
[2024-09-06T05:10:42.060+0000] {processor.py:161} INFO - Started process (PID=183) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:10:42.062+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:10:42.065+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:10:42.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:10:44.992+0000] {logging_mixin.py:188} INFO - /opt/airflow/my-etl-project-434409-3e70c40f6d3a.json
[2024-09-06T05:10:45.001+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:10:44.992+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 36, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:10:45.003+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:10:45.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.005 seconds
[2024-09-06T05:11:15.457+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:11:15.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:11:15.462+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:11:15.461+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:11:18.541+0000] {logging_mixin.py:188} INFO - /opt/airflow/my-etl-project-434409-3e70c40f6d3a.json
[2024-09-06T05:11:18.681+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:11:18.614+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 36, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:11:18.685+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:11:18.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.339 seconds
[2024-09-06T05:11:49.806+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:11:49.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:11:49.812+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:11:49.811+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:11:50.877+0000] {logging_mixin.py:188} INFO - /opt/airflow/my-etl-project-434409-3e70c40f6d3a.json
[2024-09-06T05:11:50.885+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:11:50.878+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 36, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:11:50.886+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:11:50.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.151 seconds
[2024-09-06T05:12:21.333+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:12:21.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:12:21.339+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:12:21.338+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:12:22.385+0000] {logging_mixin.py:188} INFO - /opt/airflow/my-etl-project-434409-3e70c40f6d3a.json
[2024-09-06T05:12:22.394+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:12:22.386+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 36, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:12:22.395+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:12:22.426+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.105 seconds
[2024-09-06T05:12:53.037+0000] {processor.py:161} INFO - Started process (PID=263) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:12:53.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:12:53.041+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:12:53.041+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:12:54.120+0000] {logging_mixin.py:188} INFO - /opt/airflow/my-etl-project-434409-3e70c40f6d3a.json
[2024-09-06T05:12:54.128+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:12:54.121+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 36, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:12:54.129+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:12:54.178+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.151 seconds
[2024-09-06T05:13:24.685+0000] {processor.py:161} INFO - Started process (PID=281) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:13:24.689+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:13:24.692+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:13:24.692+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:13:25.943+0000] {logging_mixin.py:188} INFO - /opt/airflow/my-etl-project-434409-3e70c40f6d3a.json
[2024-09-06T05:13:25.950+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:13:25.944+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 36, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:13:25.952+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:13:25.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.314 seconds
[2024-09-06T05:13:57.077+0000] {processor.py:161} INFO - Started process (PID=299) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:13:57.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:13:57.117+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:13:57.116+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:14:00.946+0000] {logging_mixin.py:188} INFO - /opt/airflow/my-etl-project-434409-3e70c40f6d3a.json
[2024-09-06T05:14:00.954+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:14:00.947+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 36, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:14:00.962+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:14:01.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.987 seconds
[2024-09-06T05:14:14.484+0000] {processor.py:161} INFO - Started process (PID=305) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:14:14.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:14:14.495+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:14:14.494+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:14:17.955+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:14:17.870+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 36, in <module>
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:14:17.957+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:14:18.099+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.636 seconds
[2024-09-06T05:14:48.544+0000] {processor.py:161} INFO - Started process (PID=323) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:14:48.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:14:48.548+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:14:48.548+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:14:49.732+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:14:49.727+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:14:49.734+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:14:49.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.229 seconds
[2024-09-06T05:15:20.238+0000] {processor.py:161} INFO - Started process (PID=347) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:15:20.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:15:20.252+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:15:20.251+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:15:21.314+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:15:21.306+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:15:21.316+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:15:21.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.116 seconds
[2024-09-06T05:15:51.602+0000] {processor.py:161} INFO - Started process (PID=366) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:15:51.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:15:51.613+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:15:51.611+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:15:53.481+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:15:53.462+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:15:53.482+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:15:53.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.997 seconds
[2024-09-06T05:16:23.984+0000] {processor.py:161} INFO - Started process (PID=385) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:16:23.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:16:23.988+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:16:23.988+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:16:25.015+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:16:25.007+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:16:25.017+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:16:25.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.078 seconds
[2024-09-06T05:16:55.652+0000] {processor.py:161} INFO - Started process (PID=403) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:16:55.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:16:55.657+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:16:55.657+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:16:56.711+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:16:56.703+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:16:56.714+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:16:56.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.121 seconds
[2024-09-06T05:17:27.105+0000] {processor.py:161} INFO - Started process (PID=421) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:17:27.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:17:27.110+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:17:27.109+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:17:28.956+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:17:28.939+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:17:28.959+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:17:28.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.906 seconds
[2024-09-06T05:17:59.364+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:17:59.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:17:59.370+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:17:59.369+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:18:00.596+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:18:00.587+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:18:00.598+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:18:00.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.277 seconds
[2024-09-06T05:18:30.865+0000] {processor.py:161} INFO - Started process (PID=457) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:18:30.866+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:18:30.869+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:18:30.869+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:18:32.016+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:18:32.006+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:18:32.018+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:18:32.048+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.194 seconds
[2024-09-06T05:19:02.442+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:19:02.444+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:19:02.447+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:19:02.446+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:19:03.558+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:19:03.542+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:19:03.560+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:19:03.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.158 seconds
[2024-09-06T05:19:34.377+0000] {processor.py:161} INFO - Started process (PID=493) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:19:34.380+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:19:34.392+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:19:34.391+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:19:35.694+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:19:35.687+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:19:35.696+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:19:35.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.392 seconds
[2024-09-06T05:20:06.028+0000] {processor.py:161} INFO - Started process (PID=511) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:20:06.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:20:06.033+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:20:06.032+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:20:07.330+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:20:07.324+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:20:07.331+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:20:07.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.338 seconds
[2024-09-06T05:20:37.557+0000] {processor.py:161} INFO - Started process (PID=529) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:20:37.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:20:37.578+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:20:37.576+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:20:38.809+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:20:38.802+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:20:38.811+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:20:38.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.296 seconds
[2024-09-06T05:21:09.161+0000] {processor.py:161} INFO - Started process (PID=547) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:21:09.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:21:09.166+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:21:09.165+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:21:10.949+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:21:10.942+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:21:10.950+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:21:10.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.833 seconds
[2024-09-06T05:21:41.556+0000] {processor.py:161} INFO - Started process (PID=565) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:21:41.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:21:41.562+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:21:41.561+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:21:42.952+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:21:42.946+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:21:42.953+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:21:42.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.451 seconds
[2024-09-06T05:22:13.407+0000] {processor.py:161} INFO - Started process (PID=584) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:22:13.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:22:13.423+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:22:13.421+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:22:15.606+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:22:15.601+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:22:15.607+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:22:15.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.258 seconds
[2024-09-06T05:22:46.532+0000] {processor.py:161} INFO - Started process (PID=603) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:22:46.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:22:46.536+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:22:46.536+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:22:47.767+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:22:47.754+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:22:47.769+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:22:47.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.277 seconds
[2024-09-06T05:23:18.140+0000] {processor.py:161} INFO - Started process (PID=621) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:18.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:23:18.146+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:23:18.146+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:19.472+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:23:19.466+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:23:19.475+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:19.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.378 seconds
[2024-09-06T05:23:39.681+0000] {processor.py:161} INFO - Started process (PID=640) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:39.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:23:39.686+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:23:39.686+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:39.712+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:23:39.710+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34
    credentials = service_account.Credentials.from_service_account_file("C:\Users\Lawalson\my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
[2024-09-06T05:23:39.714+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:39.754+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.085 seconds
[2024-09-06T05:23:43.953+0000] {processor.py:161} INFO - Started process (PID=645) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:43.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:23:43.975+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:23:43.974+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:44.145+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:23:44.142+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34
    credentials = service_account.Credentials.from_service_account_file("C:\Users\Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
[2024-09-06T05:23:44.150+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:44.288+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.363 seconds
[2024-09-06T05:23:47.087+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:47.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:23:47.091+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:23:47.091+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:47.114+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:23:47.111+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34
    credentials = service_account.Credentials.from_service_account_file("C:\Users/Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
[2024-09-06T05:23:47.115+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:47.165+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.088 seconds
[2024-09-06T05:23:50.371+0000] {processor.py:161} INFO - Started process (PID=655) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:50.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:23:50.377+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:23:50.376+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:52.220+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:23:52.210+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("C:/Users/Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:23:52.223+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:23:52.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.908 seconds
[2024-09-06T05:24:22.858+0000] {processor.py:161} INFO - Started process (PID=679) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:24:22.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:24:22.864+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:24:22.863+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:24:24.017+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:24:23.995+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("C:/Users/Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:24:24.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:24:24.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.209 seconds
[2024-09-06T05:24:54.621+0000] {processor.py:161} INFO - Started process (PID=697) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:24:54.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:24:54.627+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:24:54.624+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:24:55.720+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:24:55.713+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("C:/Users/Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:24:55.722+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:24:55.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.137 seconds
[2024-09-06T05:25:42.782+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:25:42.783+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:25:42.787+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:25:42.786+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:25:44.438+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:25:44.425+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("C:/Users/Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:25:44.439+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:25:44.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.716 seconds
[2024-09-06T05:26:15.386+0000] {processor.py:161} INFO - Started process (PID=183) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:26:15.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:26:15.408+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:26:15.407+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:26:18.925+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:26:18.879+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file(/Users/Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:26:18.927+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:26:19.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.671 seconds
[2024-09-06T05:26:20.154+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:26:20.156+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:26:20.160+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:26:20.159+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:26:22.455+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:26:22.445+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./Users/Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './Users/Lawalson/my_etl_project/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:26:22.458+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:26:22.503+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.366 seconds
[2024-09-06T05:26:33.827+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:26:33.828+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:26:33.832+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:26:33.831+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:26:36.154+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:26:36.147+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:26:36.156+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:26:36.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.373 seconds
[2024-09-06T05:27:06.870+0000] {processor.py:161} INFO - Started process (PID=222) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:27:06.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:27:06.874+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:27:06.874+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:27:07.923+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:27:07.916+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:27:07.924+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:27:07.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.096 seconds
[2024-09-06T05:27:38.157+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:27:38.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:27:38.161+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:27:38.161+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:27:39.142+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:27:39.136+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:27:39.143+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:27:39.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.026 seconds
[2024-09-06T05:28:25.669+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:28:25.671+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:28:25.675+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:28:25.674+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:28:28.211+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:28:28.203+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:28:28.213+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:28:28.267+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.614 seconds
[2024-09-06T05:28:58.694+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:28:58.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:28:58.712+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:28:58.711+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:29:01.157+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:29:01.149+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:29:01.159+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:29:01.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.531 seconds
[2024-09-06T05:29:32.325+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:29:32.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:29:32.366+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:29:32.365+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:29:37.031+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:29:37.024+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:29:37.033+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:29:37.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.819 seconds
[2024-09-06T05:30:07.462+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:30:07.464+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:30:07.467+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:30:07.467+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:30:08.806+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:30:08.798+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:30:08.807+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:30:08.845+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.402 seconds
[2024-09-06T05:30:27.670+0000] {processor.py:161} INFO - Started process (PID=239) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:30:27.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:30:27.682+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:30:27.681+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:30:29.162+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:30:29.156+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:30:29.163+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:30:29.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.541 seconds
[2024-09-06T05:31:22.034+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:31:22.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:31:22.041+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:31:22.041+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:31:25.539+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:31:25.524+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:31:25.540+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:31:25.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.595 seconds
[2024-09-06T05:31:56.177+0000] {processor.py:161} INFO - Started process (PID=192) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:31:56.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:31:56.182+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:31:56.181+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:31:57.432+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:31:57.425+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:31:57.434+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:31:57.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.312 seconds
[2024-09-06T05:32:03.522+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:32:03.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:32:03.530+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:32:03.529+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:32:05.526+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:32:05.516+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:32:05.527+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:32:05.586+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.078 seconds
[2024-09-06T05:32:10.734+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:32:10.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:32:10.742+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:32:10.742+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:32:11.961+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:32:11.952+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:32:11.963+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:32:12.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.290 seconds
[2024-09-06T05:32:13.805+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:32:13.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:32:13.809+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:32:13.809+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:32:16.613+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:32:16.606+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:32:16.614+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:32:16.647+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.855 seconds
[2024-09-06T05:32:46.940+0000] {processor.py:161} INFO - Started process (PID=228) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:32:46.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:32:46.945+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:32:46.944+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:32:48.542+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:32:48.531+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:32:48.543+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:32:48.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.654 seconds
[2024-09-06T05:33:19.346+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:33:19.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:33:19.350+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:33:19.350+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:33:20.895+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:33:20.888+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:33:20.896+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:33:20.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.602 seconds
[2024-09-06T05:33:51.353+0000] {processor.py:161} INFO - Started process (PID=264) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:33:51.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:33:51.358+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:33:51.358+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:33:52.489+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:33:52.483+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:33:52.491+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:33:52.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.176 seconds
[2024-09-06T05:34:22.679+0000] {processor.py:161} INFO - Started process (PID=282) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:34:22.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:34:22.683+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:34:22.682+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:34:23.649+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:34:23.640+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:34:23.650+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:34:23.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.016 seconds
[2024-09-06T05:34:53.924+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:34:53.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:34:53.930+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:34:53.929+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:34:55.440+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:34:55.434+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:34:55.441+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:34:55.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.563 seconds
[2024-09-06T05:35:25.986+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:35:25.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:35:25.990+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:35:25.990+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:35:27.225+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:35:27.220+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:35:27.226+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:35:27.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.291 seconds
[2024-09-06T05:35:57.784+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:35:57.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:35:57.801+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:35:57.801+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:35:59.079+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:35:59.072+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:35:59.080+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:35:59.122+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.357 seconds
[2024-09-06T05:36:29.505+0000] {processor.py:161} INFO - Started process (PID=360) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:36:29.507+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:36:29.513+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:36:29.512+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:36:31.816+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:36:31.806+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:36:31.817+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:36:31.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.384 seconds
[2024-09-06T05:37:02.175+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:37:02.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:37:02.182+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:37:02.181+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:37:03.751+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:37:03.741+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:37:03.753+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:37:03.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.634 seconds
[2024-09-06T05:37:34.326+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:37:34.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:37:34.354+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:37:34.348+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:37:36.358+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:37:36.351+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:37:36.360+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:37:36.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.122 seconds
[2024-09-06T05:38:07.270+0000] {processor.py:161} INFO - Started process (PID=413) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:38:07.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:38:07.277+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:38:07.277+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:38:08.893+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:38:08.883+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:38:08.896+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:38:08.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.684 seconds
[2024-09-06T05:38:39.495+0000] {processor.py:161} INFO - Started process (PID=431) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:38:39.501+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:38:39.517+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:38:39.516+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:38:41.491+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:38:41.484+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:38:41.492+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:38:41.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.060 seconds
[2024-09-06T05:39:12.401+0000] {processor.py:161} INFO - Started process (PID=449) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:39:12.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:39:12.410+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:39:12.409+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:39:13.679+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:39:13.672+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:39:13.680+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:39:13.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.331 seconds
[2024-09-06T05:39:43.906+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:39:43.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:39:43.912+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:39:43.911+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:39:46.160+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:39:46.147+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:39:46.162+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:39:46.212+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.320 seconds
[2024-09-06T05:40:05.186+0000] {processor.py:161} INFO - Started process (PID=486) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:05.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:40:05.204+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:40:05.203+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:07.423+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:40:07.377+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt//my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:40:07.425+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:07.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.331 seconds
[2024-09-06T05:40:08.646+0000] {processor.py:161} INFO - Started process (PID=492) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:08.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:40:08.651+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:40:08.650+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:10.683+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:40:10.651+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airt/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/a/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:40:10.685+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:10.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.109 seconds
[2024-09-06T05:40:11.075+0000] {processor.py:161} INFO - Started process (PID=498) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:11.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:40:11.082+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:40:11.081+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:13.088+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:40:13.064+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow//my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airf/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:40:13.089+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:13.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.062 seconds
[2024-09-06T05:40:14.207+0000] {processor.py:161} INFO - Started process (PID=504) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:14.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:40:14.213+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:40:14.213+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:17.793+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:40:17.753+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:40:17.804+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:17.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.728 seconds
[2024-09-06T05:40:48.503+0000] {processor.py:161} INFO - Started process (PID=522) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:48.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:40:48.519+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:40:48.510+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:49.983+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:40:49.977+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:40:49.984+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:40:50.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.542 seconds
[2024-09-06T05:41:20.658+0000] {processor.py:161} INFO - Started process (PID=540) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:41:20.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:41:20.664+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:41:20.663+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:41:22.101+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:41:22.092+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:41:22.103+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:41:22.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.487 seconds
[2024-09-06T05:41:53.073+0000] {processor.py:161} INFO - Started process (PID=558) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:41:53.076+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:41:53.080+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:41:53.079+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:41:55.535+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:41:55.527+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:41:55.536+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:41:55.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.508 seconds
[2024-09-06T05:42:25.900+0000] {processor.py:161} INFO - Started process (PID=576) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:42:25.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:42:25.905+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:42:25.904+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:42:27.177+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:42:27.171+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:42:27.180+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:42:27.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.342 seconds
[2024-09-06T05:42:58.100+0000] {processor.py:161} INFO - Started process (PID=600) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:42:58.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:42:58.113+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:42:58.112+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:42:59.780+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:42:59.773+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:42:59.781+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:42:59.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.741 seconds
[2024-09-06T05:43:30.213+0000] {processor.py:161} INFO - Started process (PID=618) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:43:30.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:43:30.230+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:43:30.228+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:43:31.831+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:43:31.822+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:43:31.832+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:43:31.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.691 seconds
[2024-09-06T05:44:02.069+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:44:02.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:44:02.081+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:44:02.079+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:44:03.903+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:44:03.894+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("./opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:44:03.904+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:44:03.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.901 seconds
[2024-09-06T05:44:34.198+0000] {processor.py:161} INFO - Started process (PID=653) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:44:34.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:44:34.204+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:44:34.203+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:44:37.052+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:44:37.038+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:44:37.054+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:44:37.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.929 seconds
[2024-09-06T05:45:07.232+0000] {processor.py:161} INFO - Started process (PID=671) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:45:07.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:45:07.237+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:45:07.237+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:45:10.434+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:45:10.423+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:45:10.435+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:45:10.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.303 seconds
[2024-09-06T05:45:40.793+0000] {processor.py:161} INFO - Started process (PID=689) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:45:40.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:45:40.812+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:45:40.810+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:45:42.111+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:45:42.106+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:45:42.113+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:45:42.154+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.395 seconds
[2024-09-06T05:46:32.313+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:46:32.336+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:46:32.340+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:46:32.340+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:46:35.096+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:46:35.086+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:46:35.098+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:46:35.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.858 seconds
[2024-09-06T05:47:05.346+0000] {processor.py:161} INFO - Started process (PID=190) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:47:05.359+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:47:05.364+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:47:05.363+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:47:06.881+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:47:06.873+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:47:06.883+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:47:06.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.593 seconds
[2024-09-06T05:47:37.855+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:47:37.857+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:47:37.859+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:47:37.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:47:39.692+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:47:39.679+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:47:39.693+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:47:39.740+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.897 seconds
[2024-09-06T05:48:09.954+0000] {processor.py:161} INFO - Started process (PID=162) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:48:09.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:48:09.959+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:48:09.958+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:48:11.142+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:48:11.136+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:48:11.143+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:48:11.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.240 seconds
[2024-09-06T05:48:41.556+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:48:41.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:48:41.565+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:48:41.564+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:48:43.709+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:48:43.703+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:48:43.713+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:48:43.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.212 seconds
[2024-09-06T05:49:14.677+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:49:14.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:49:14.684+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:49:14.684+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:49:16.329+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:49:16.316+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:49:16.331+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:49:16.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.735 seconds
[2024-09-06T05:49:47.332+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:49:47.336+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:49:47.342+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:49:47.341+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:49:48.733+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:49:48.725+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:49:48.734+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:49:48.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.477 seconds
[2024-09-06T05:50:19.062+0000] {processor.py:161} INFO - Started process (PID=247) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:50:19.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:50:19.068+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:50:19.067+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:50:20.313+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:50:20.307+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:50:20.314+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:50:20.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.296 seconds
[2024-09-06T05:50:51.258+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:50:51.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:50:51.272+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:50:51.270+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:50:52.868+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:50:52.860+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:50:52.870+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:50:52.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.674 seconds
[2024-09-06T05:51:23.055+0000] {processor.py:161} INFO - Started process (PID=283) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:51:23.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:51:23.062+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:51:23.061+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:51:24.518+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:51:24.511+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:51:24.520+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:51:24.553+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.509 seconds
[2024-09-06T05:51:55.224+0000] {processor.py:161} INFO - Started process (PID=301) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:51:55.226+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:51:55.232+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:51:55.229+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:51:56.636+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:51:56.628+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:51:56.638+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:51:56.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.470 seconds
[2024-09-06T05:52:27.477+0000] {processor.py:161} INFO - Started process (PID=319) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:52:27.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:52:27.494+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:52:27.492+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:52:28.770+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:52:28.756+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:52:28.772+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:52:28.806+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.374 seconds
[2024-09-06T05:52:59.626+0000] {processor.py:161} INFO - Started process (PID=337) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:52:59.632+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:52:59.639+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:52:59.637+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:53:01.205+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:53:01.199+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:53:01.207+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:53:01.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.629 seconds
[2024-09-06T05:53:31.602+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:53:31.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:53:31.616+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:53:31.615+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:53:33.586+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:53:33.579+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:53:33.587+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:53:33.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.057 seconds
[2024-09-06T05:54:04.527+0000] {processor.py:161} INFO - Started process (PID=375) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:54:04.531+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:54:04.541+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:54:04.540+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:54:06.095+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:54:06.083+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:54:06.097+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:54:06.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.657 seconds
[2024-09-06T05:54:36.781+0000] {processor.py:161} INFO - Started process (PID=393) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:54:36.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:54:36.789+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:54:36.788+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:54:38.166+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:54:38.156+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:54:38.168+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:54:38.210+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.483 seconds
[2024-09-06T05:55:08.940+0000] {processor.py:161} INFO - Started process (PID=412) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:55:08.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:55:08.947+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:55:08.946+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:55:10.568+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:55:10.559+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:55:10.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:55:10.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.680 seconds
[2024-09-06T05:55:41.607+0000] {processor.py:161} INFO - Started process (PID=430) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:55:41.609+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:55:41.612+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:55:41.612+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:55:42.924+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:55:42.918+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:55:42.925+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:55:42.961+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.365 seconds
[2024-09-06T05:56:13.434+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:56:13.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:56:13.439+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:56:13.438+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:56:14.544+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:56:14.537+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:56:14.546+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:56:14.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.154 seconds
[2024-09-06T05:56:45.336+0000] {processor.py:161} INFO - Started process (PID=466) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:56:45.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:56:45.348+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:56:45.346+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:56:47.179+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:56:47.155+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:56:47.183+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:56:47.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.938 seconds
[2024-09-06T05:57:17.971+0000] {processor.py:161} INFO - Started process (PID=485) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:57:17.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:57:17.977+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:57:17.976+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:57:19.224+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:57:19.218+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:57:19.226+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:57:19.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.310 seconds
[2024-09-06T05:57:50.045+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:57:50.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:57:50.059+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:57:50.057+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:57:51.755+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:57:51.746+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:57:51.757+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:57:51.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.780 seconds
[2024-09-06T05:58:22.865+0000] {processor.py:161} INFO - Started process (PID=528) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:58:22.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:58:22.880+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:58:22.879+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:58:24.283+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:58:24.274+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:58:24.284+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:58:24.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.495 seconds
[2024-09-06T05:58:54.425+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:58:54.426+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:58:54.428+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:58:54.428+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:58:55.475+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:58:55.470+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:58:55.477+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:58:55.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.091 seconds
[2024-09-06T05:59:25.765+0000] {processor.py:161} INFO - Started process (PID=563) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:59:25.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:59:25.768+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:59:25.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:59:26.805+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:59:26.799+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:59:26.806+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:59:26.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.075 seconds
[2024-09-06T05:59:57.088+0000] {processor.py:161} INFO - Started process (PID=581) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:59:57.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T05:59:57.092+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:59:57.092+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:59:57.869+0000] {logging_mixin.py:188} INFO - [2024-09-06T05:59:57.864+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T05:59:57.870+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T05:59:57.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.812 seconds
[2024-09-06T06:00:28.056+0000] {processor.py:161} INFO - Started process (PID=600) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:00:28.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:00:28.059+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:00:28.059+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:00:29.036+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:00:29.031+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:00:29.037+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:00:29.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.016 seconds
[2024-09-06T06:00:59.306+0000] {processor.py:161} INFO - Started process (PID=618) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:00:59.307+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:00:59.309+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:00:59.309+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:01:00.090+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:01:00.084+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:01:00.091+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:01:00.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.818 seconds
[2024-09-06T06:01:30.375+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:01:30.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:01:30.378+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:01:30.378+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:01:31.102+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:01:31.098+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:01:31.103+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:01:31.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.757 seconds
[2024-09-06T06:02:01.396+0000] {processor.py:161} INFO - Started process (PID=654) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:02:01.398+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:02:01.401+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:02:01.400+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:02:02.226+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:02:02.220+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:02:02.227+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:02:02.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.862 seconds
[2024-09-06T06:02:32.510+0000] {processor.py:161} INFO - Started process (PID=672) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:02:32.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:02:32.513+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:02:32.513+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:02:33.227+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:02:33.222+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:02:33.227+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:02:33.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.744 seconds
[2024-09-06T06:03:03.516+0000] {processor.py:161} INFO - Started process (PID=691) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:03:03.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:03:03.520+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:03:03.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:03:04.514+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:03:04.508+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:03:04.515+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:03:04.541+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.032 seconds
[2024-09-06T06:03:34.839+0000] {processor.py:161} INFO - Started process (PID=708) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:03:34.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:03:34.843+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:03:34.843+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:03:35.591+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:03:35.585+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:03:35.592+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:03:35.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.790 seconds
[2024-09-06T06:04:05.786+0000] {processor.py:161} INFO - Started process (PID=726) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:04:05.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:04:05.790+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:04:05.789+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:04:07.108+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:04:07.102+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:04:07.109+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:04:07.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.359 seconds
[2024-09-06T06:04:37.661+0000] {processor.py:161} INFO - Started process (PID=744) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:04:37.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:04:37.664+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:04:37.664+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:04:38.492+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:04:38.486+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:04:38.494+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:04:38.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.870 seconds
[2024-09-06T06:05:08.808+0000] {processor.py:161} INFO - Started process (PID=762) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:05:08.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:05:08.811+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:05:08.811+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:05:09.760+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:05:09.756+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:05:09.761+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:05:09.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.982 seconds
[2024-09-06T06:05:40.066+0000] {processor.py:161} INFO - Started process (PID=780) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:05:40.067+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:05:40.069+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:05:40.068+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:05:40.829+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:05:40.824+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:05:40.831+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:05:40.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.798 seconds
[2024-09-06T06:06:11.108+0000] {processor.py:161} INFO - Started process (PID=798) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:06:11.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:06:11.112+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:06:11.112+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:06:12.323+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:06:12.317+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:06:12.324+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:06:12.359+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.259 seconds
[2024-09-06T06:06:42.627+0000] {processor.py:161} INFO - Started process (PID=816) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:06:42.628+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:06:42.631+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:06:42.630+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:06:43.400+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:06:43.393+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:06:43.401+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:06:43.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.807 seconds
[2024-09-06T06:07:14.232+0000] {processor.py:161} INFO - Started process (PID=834) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:07:14.237+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:07:14.246+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:07:14.240+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:07:15.266+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:07:15.261+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:07:15.268+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:07:15.294+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.081 seconds
[2024-09-06T06:07:45.551+0000] {processor.py:161} INFO - Started process (PID=852) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:07:45.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:07:45.554+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:07:45.554+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:07:46.301+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:07:46.294+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:07:46.302+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:07:46.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.792 seconds
[2024-09-06T06:08:16.621+0000] {processor.py:161} INFO - Started process (PID=870) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:08:16.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:08:16.625+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:08:16.625+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:08:17.549+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:08:17.541+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:08:17.551+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:08:17.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.962 seconds
[2024-09-06T06:08:47.850+0000] {processor.py:161} INFO - Started process (PID=888) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:08:47.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:08:47.854+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:08:47.854+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:08:48.589+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:08:48.584+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:08:48.591+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:08:48.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.774 seconds
[2024-09-06T06:09:18.995+0000] {processor.py:161} INFO - Started process (PID=906) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:09:18.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:09:19.002+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:09:19.001+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:09:19.942+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:09:19.937+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:09:19.943+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:09:19.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.986 seconds
[2024-09-06T06:09:50.207+0000] {processor.py:161} INFO - Started process (PID=924) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:09:50.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:09:50.210+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:09:50.210+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:09:50.922+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:09:50.918+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:09:50.924+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:09:50.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.749 seconds
[2024-09-06T06:10:21.204+0000] {processor.py:161} INFO - Started process (PID=942) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:10:21.206+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:10:21.209+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:10:21.209+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:10:22.288+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:10:22.282+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:10:22.289+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:10:22.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.120 seconds
[2024-09-06T06:10:53.064+0000] {processor.py:161} INFO - Started process (PID=965) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:10:53.065+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:10:53.067+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:10:53.067+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:10:53.801+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:10:53.796+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:10:53.802+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:10:53.827+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.770 seconds
[2024-09-06T06:11:24.034+0000] {processor.py:161} INFO - Started process (PID=983) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:11:24.035+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:11:24.038+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:11:24.038+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:11:24.831+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:11:24.826+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:11:24.832+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:11:24.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.829 seconds
[2024-09-06T06:11:55.655+0000] {processor.py:161} INFO - Started process (PID=1001) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:11:55.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:11:55.658+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:11:55.658+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:11:56.538+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:11:56.528+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:11:56.540+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:11:56.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.935 seconds
[2024-09-06T06:12:26.734+0000] {processor.py:161} INFO - Started process (PID=1020) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:12:26.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:12:26.737+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:12:26.736+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:12:27.499+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:12:27.492+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:12:27.500+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:12:27.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.802 seconds
[2024-09-06T06:12:58.211+0000] {processor.py:161} INFO - Started process (PID=1039) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:12:58.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:12:58.215+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:12:58.215+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:12:59.002+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:12:58.998+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:12:59.003+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:12:59.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.824 seconds
[2024-09-06T06:13:29.339+0000] {processor.py:161} INFO - Started process (PID=1057) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:13:29.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:13:29.342+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:13:29.342+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:13:30.118+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:13:30.112+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:13:30.120+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:13:30.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.820 seconds
[2024-09-06T06:14:00.293+0000] {processor.py:161} INFO - Started process (PID=1076) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:14:00.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:14:00.298+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:14:00.297+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:14:01.348+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:14:01.343+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:14:01.349+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:14:01.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.084 seconds
[2024-09-06T06:14:31.630+0000] {processor.py:161} INFO - Started process (PID=1094) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:14:31.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:14:31.634+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:14:31.633+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:14:32.430+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:14:32.424+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:14:32.431+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:14:32.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.846 seconds
[2024-09-06T06:15:02.734+0000] {processor.py:161} INFO - Started process (PID=1112) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:15:02.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:15:02.739+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:15:02.738+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:15:03.721+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:15:03.717+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:15:03.723+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:15:03.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.026 seconds
[2024-09-06T06:15:34.017+0000] {processor.py:161} INFO - Started process (PID=1130) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:15:34.065+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:15:34.069+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:15:34.069+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:15:35.234+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:15:35.229+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:15:35.235+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:15:35.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.260 seconds
[2024-09-06T06:16:05.541+0000] {processor.py:161} INFO - Started process (PID=1148) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:16:05.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:16:05.545+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:16:05.545+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:16:06.479+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:16:06.474+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:16:06.480+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:16:06.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.974 seconds
[2024-09-06T06:16:36.662+0000] {processor.py:161} INFO - Started process (PID=1166) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:16:36.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:16:36.667+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:16:36.666+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:16:37.519+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:16:37.512+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:16:37.520+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:16:37.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.891 seconds
[2024-09-06T06:17:08.011+0000] {processor.py:161} INFO - Started process (PID=1184) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:17:08.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:17:08.015+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:17:08.015+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:17:08.964+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:17:08.958+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:17:08.966+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:17:08.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.989 seconds
[2024-09-06T06:17:39.250+0000] {processor.py:161} INFO - Started process (PID=1202) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:17:39.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:17:39.255+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:17:39.254+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:17:40.046+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:17:40.041+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:17:40.047+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:17:40.073+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.830 seconds
[2024-09-06T06:18:10.371+0000] {processor.py:161} INFO - Started process (PID=1221) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:18:10.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:18:10.378+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:18:10.377+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:18:11.519+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:18:11.512+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:18:11.520+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:18:11.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.186 seconds
[2024-09-06T06:18:41.782+0000] {processor.py:161} INFO - Started process (PID=1239) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:18:41.783+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:18:41.786+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:18:41.785+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:18:42.595+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:18:42.590+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:18:42.596+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:18:42.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.846 seconds
[2024-09-06T06:19:12.867+0000] {processor.py:161} INFO - Started process (PID=1258) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:19:12.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:19:12.871+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:19:12.870+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:19:13.737+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:19:13.732+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:19:13.739+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:19:13.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.910 seconds
[2024-09-06T06:19:44.036+0000] {processor.py:161} INFO - Started process (PID=1275) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:19:44.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:19:44.040+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:19:44.040+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:19:44.812+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:19:44.806+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:19:44.820+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:19:44.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.824 seconds
[2024-09-06T06:20:15.131+0000] {processor.py:161} INFO - Started process (PID=1293) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:20:15.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:20:15.136+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:20:15.136+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:20:16.090+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:20:16.083+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:20:16.091+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:20:16.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.003 seconds
[2024-09-06T06:20:46.379+0000] {processor.py:161} INFO - Started process (PID=1311) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:20:46.380+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:20:46.383+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:20:46.383+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:20:47.180+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:20:47.175+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:20:47.181+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:20:47.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.835 seconds
[2024-09-06T06:21:17.458+0000] {processor.py:161} INFO - Started process (PID=1329) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:21:17.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:21:17.464+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:21:17.463+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:21:18.323+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:21:18.316+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:21:18.325+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:21:18.367+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.916 seconds
[2024-09-06T06:21:48.654+0000] {processor.py:161} INFO - Started process (PID=1347) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:21:48.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:21:48.659+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:21:48.658+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:21:49.382+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:21:49.376+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:21:49.383+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:21:49.410+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.762 seconds
[2024-09-06T06:22:19.688+0000] {processor.py:161} INFO - Started process (PID=1365) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:22:19.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:22:19.693+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:22:19.693+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:22:20.569+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:22:20.564+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:22:20.571+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:22:20.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.921 seconds
[2024-09-06T06:22:50.857+0000] {processor.py:161} INFO - Started process (PID=1383) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:22:50.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:22:50.861+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:22:50.860+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:22:51.584+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:22:51.577+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:22:51.585+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:22:51.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.760 seconds
[2024-09-06T06:23:21.920+0000] {processor.py:161} INFO - Started process (PID=1401) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:23:21.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:23:21.923+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:23:21.923+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:23:22.744+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:23:22.739+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:23:22.745+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:23:22.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.857 seconds
[2024-09-06T06:23:53.038+0000] {processor.py:161} INFO - Started process (PID=1419) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:23:53.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:23:53.042+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:23:53.042+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:23:53.901+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:23:53.895+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:23:53.902+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:23:53.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.893 seconds
[2024-09-06T06:24:24.223+0000] {processor.py:161} INFO - Started process (PID=1443) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:24:24.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:24:24.226+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:24:24.225+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:24:25.003+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:24:24.991+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:24:25.005+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:24:25.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.831 seconds
[2024-09-06T06:24:55.526+0000] {processor.py:161} INFO - Started process (PID=1462) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:24:55.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:24:55.530+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:24:55.530+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:24:56.309+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:24:56.304+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:24:56.310+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:24:56.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.818 seconds
[2024-09-06T06:25:26.929+0000] {processor.py:161} INFO - Started process (PID=1480) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:25:26.950+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T06:25:26.967+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:25:26.953+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:25:29.176+0000] {logging_mixin.py:188} INFO - [2024-09-06T06:25:29.142+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T06:25:29.177+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T06:25:29.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.355 seconds
[2024-09-06T07:07:43.001+0000] {processor.py:161} INFO - Started process (PID=1496) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:07:43.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:07:43.060+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:07:43.059+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:07:50.170+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:07:50.118+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:07:50.173+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:07:50.262+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 7.285 seconds
[2024-09-06T07:08:21.202+0000] {processor.py:161} INFO - Started process (PID=1517) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:08:21.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:08:21.208+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:08:21.207+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:08:25.361+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:08:25.350+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:08:25.363+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:08:25.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.233 seconds
[2024-09-06T07:08:55.719+0000] {processor.py:161} INFO - Started process (PID=1535) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:08:55.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:08:55.727+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:08:55.726+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:08:58.492+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:08:58.445+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:08:58.494+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:08:58.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.847 seconds
[2024-09-06T07:09:29.134+0000] {processor.py:161} INFO - Started process (PID=1553) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:09:29.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:09:29.139+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:09:29.139+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:09:31.963+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:09:31.956+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:09:31.965+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:09:32.005+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.881 seconds
[2024-09-06T07:10:02.615+0000] {processor.py:161} INFO - Started process (PID=1577) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:10:02.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:10:02.620+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:10:02.619+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:10:03.530+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:10:03.524+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:10:03.531+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:10:03.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.959 seconds
[2024-09-06T07:10:34.251+0000] {processor.py:161} INFO - Started process (PID=1595) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:10:34.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:10:34.256+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:10:34.256+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:10:35.509+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:10:35.481+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/datamy-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:10:35.511+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:10:35.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.312 seconds
[2024-09-06T07:10:39.748+0000] {processor.py:161} INFO - Started process (PID=1601) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:10:39.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:10:39.754+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:10:39.753+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:10:40.781+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:10:40.774+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:10:40.783+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:10:40.814+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.080 seconds
[2024-09-06T07:10:46.883+0000] {processor.py:161} INFO - Started process (PID=1607) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:10:46.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:10:46.888+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:10:46.888+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:10:48.288+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:10:48.274+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow//my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:10:48.289+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:10:48.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.461 seconds
[2024-09-06T07:11:18.545+0000] {processor.py:161} INFO - Started process (PID=1625) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:11:18.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:11:18.550+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:11:18.549+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:11:19.533+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:11:19.524+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:11:19.534+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:11:19.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.033 seconds
[2024-09-06T07:11:49.826+0000] {processor.py:161} INFO - Started process (PID=1643) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:11:49.828+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:11:49.832+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:11:49.831+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:11:50.694+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:11:50.687+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:11:50.695+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:11:50.717+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.903 seconds
[2024-09-06T07:12:21.049+0000] {processor.py:161} INFO - Started process (PID=1661) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:12:21.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:12:21.056+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:12:21.055+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:12:22.223+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:12:22.216+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:12:22.225+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:12:22.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.225 seconds
[2024-09-06T07:12:52.697+0000] {processor.py:161} INFO - Started process (PID=1679) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:12:52.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:12:52.702+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:12:52.702+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:12:53.577+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:12:53.569+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:12:53.578+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:12:53.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.914 seconds
[2024-09-06T07:13:23.983+0000] {processor.py:161} INFO - Started process (PID=1698) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:13:23.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:13:23.991+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:13:23.990+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:13:25.157+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:13:25.152+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:13:25.159+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:13:25.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.224 seconds
[2024-09-06T07:13:55.718+0000] {processor.py:161} INFO - Started process (PID=1716) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:13:55.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:13:55.724+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:13:55.724+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:13:57.183+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:13:57.174+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:13:57.184+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:13:57.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.515 seconds
[2024-09-06T07:14:27.612+0000] {processor.py:161} INFO - Started process (PID=1733) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:14:27.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:14:27.618+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:14:27.617+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:14:28.630+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:14:28.625+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:14:28.631+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:14:28.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.063 seconds
[2024-09-06T07:14:59.169+0000] {processor.py:161} INFO - Started process (PID=1752) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:14:59.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:14:59.173+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:14:59.173+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:15:00.217+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:15:00.210+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:15:00.218+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:15:00.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.094 seconds
[2024-09-06T07:15:30.747+0000] {processor.py:161} INFO - Started process (PID=1770) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:15:30.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:15:30.752+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:15:30.752+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:15:31.937+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:15:31.927+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:15:31.939+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:15:31.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.242 seconds
[2024-09-06T07:16:02.086+0000] {processor.py:161} INFO - Started process (PID=1788) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:16:02.087+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:16:02.091+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:16:02.090+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:16:03.000+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:16:02.994+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:16:03.001+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:16:03.031+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.953 seconds
[2024-09-06T07:16:33.532+0000] {processor.py:161} INFO - Started process (PID=1812) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:16:33.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:16:33.537+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:16:33.536+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:16:34.501+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:16:34.494+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:16:34.505+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:16:34.530+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.007 seconds
[2024-09-06T07:17:04.807+0000] {processor.py:161} INFO - Started process (PID=1830) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:17:04.808+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:17:04.810+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:17:04.810+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:17:05.658+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:17:05.652+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:17:05.659+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:17:05.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.890 seconds
[2024-09-06T07:17:36.284+0000] {processor.py:161} INFO - Started process (PID=1848) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:17:36.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:17:36.289+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:17:36.288+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:17:37.316+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:17:37.309+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:17:37.318+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:17:37.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.070 seconds
[2024-09-06T07:18:07.703+0000] {processor.py:161} INFO - Started process (PID=1866) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:18:07.704+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:18:07.708+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:18:07.708+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:18:08.801+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:18:08.794+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:18:08.802+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:18:08.833+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.136 seconds
[2024-09-06T07:18:39.062+0000] {processor.py:161} INFO - Started process (PID=1883) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:18:39.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:18:39.066+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:18:39.065+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:18:39.926+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:18:39.919+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:18:39.927+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:18:39.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.904 seconds
[2024-09-06T07:18:55.492+0000] {processor.py:161} INFO - Started process (PID=1895) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:18:55.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:18:55.508+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:18:55.507+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:18:56.971+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:18:56.947+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/k/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:18:56.972+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:18:57.014+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.536 seconds
[2024-09-06T07:19:27.352+0000] {processor.py:161} INFO - Started process (PID=1913) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:19:27.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:19:27.357+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:19:27.356+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:19:28.373+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:19:28.366+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:19:28.374+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:19:28.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.064 seconds
[2024-09-06T07:19:58.950+0000] {processor.py:161} INFO - Started process (PID=1931) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:19:58.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:19:58.954+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:19:58.954+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:20:00.079+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:20:00.071+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:20:00.080+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:20:00.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.178 seconds
[2024-09-06T07:20:30.278+0000] {processor.py:161} INFO - Started process (PID=1949) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:20:30.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:20:30.285+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:20:30.285+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:20:31.576+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:20:31.568+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:20:31.577+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:20:31.622+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.361 seconds
[2024-09-06T07:20:45.762+0000] {processor.py:161} INFO - Started process (PID=1961) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:20:45.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:20:45.768+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:20:45.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:20:47.147+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:20:47.140+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow//my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:20:47.148+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:20:47.182+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.434 seconds
[2024-09-06T07:21:17.328+0000] {processor.py:161} INFO - Started process (PID=1979) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:21:17.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:21:17.335+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:21:17.334+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:21:18.253+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:21:18.247+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:21:18.255+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:21:18.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.968 seconds
[2024-09-06T07:21:48.835+0000] {processor.py:161} INFO - Started process (PID=1997) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:21:48.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:21:48.839+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:21:48.838+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:21:49.811+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:21:49.803+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:21:49.813+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:21:49.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.015 seconds
[2024-09-06T07:22:20.221+0000] {processor.py:161} INFO - Started process (PID=2015) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:22:20.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:22:20.226+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:22:20.225+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:22:21.120+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:22:21.114+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:22:21.121+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:22:21.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.939 seconds
[2024-09-06T07:22:51.651+0000] {processor.py:161} INFO - Started process (PID=2034) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:22:51.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:22:51.656+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:22:51.655+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:22:52.749+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:22:52.741+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:22:52.750+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:22:52.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.135 seconds
[2024-09-06T07:23:23.027+0000] {processor.py:161} INFO - Started process (PID=2053) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:23:23.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:23:23.031+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:23:23.031+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:23:24.134+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:23:24.126+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:23:24.137+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:23:24.172+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.157 seconds
[2024-09-06T07:23:54.460+0000] {processor.py:161} INFO - Started process (PID=2071) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:23:54.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:23:54.466+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:23:54.465+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:23:55.693+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:23:55.686+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:23:55.695+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:23:55.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.281 seconds
[2024-09-06T07:24:26.357+0000] {processor.py:161} INFO - Started process (PID=2089) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:24:26.360+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:24:26.365+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:24:26.364+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:24:27.569+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:24:27.560+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:24:27.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:24:27.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.265 seconds
[2024-09-06T07:24:57.812+0000] {processor.py:161} INFO - Started process (PID=2107) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:24:57.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:24:57.818+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:24:57.817+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:24:58.837+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:24:58.817+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:24:58.841+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:24:58.893+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.089 seconds
[2024-09-06T07:25:29.459+0000] {processor.py:161} INFO - Started process (PID=2126) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:25:29.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:25:29.465+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:25:29.464+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:25:30.375+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:25:30.370+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:25:30.377+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:25:30.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.963 seconds
[2024-09-06T07:26:00.797+0000] {processor.py:161} INFO - Started process (PID=2144) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:26:00.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:26:00.802+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:26:00.801+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:26:01.905+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:26:01.898+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:26:01.908+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:26:01.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.162 seconds
[2024-09-06T07:26:32.370+0000] {processor.py:161} INFO - Started process (PID=2162) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:26:32.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:26:32.378+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:26:32.377+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:26:33.399+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:26:33.391+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:26:33.400+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:26:33.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.074 seconds
[2024-09-06T07:27:03.648+0000] {processor.py:161} INFO - Started process (PID=2180) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:27:03.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:27:03.653+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:27:03.653+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:27:04.773+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:27:04.762+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:27:04.776+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:27:04.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.184 seconds
[2024-09-06T07:27:35.347+0000] {processor.py:161} INFO - Started process (PID=2204) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:27:35.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:27:35.353+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:27:35.352+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:27:36.226+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:27:36.217+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:27:36.227+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:27:36.258+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.920 seconds
[2024-09-06T07:28:06.598+0000] {processor.py:161} INFO - Started process (PID=2222) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:28:06.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:28:06.605+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:28:06.604+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:28:07.665+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:28:07.659+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:28:07.666+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:28:07.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.099 seconds
[2024-09-06T07:28:38.134+0000] {processor.py:161} INFO - Started process (PID=2240) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:28:38.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:28:38.140+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:28:38.140+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:28:39.232+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:28:39.225+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:28:39.234+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:28:39.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.138 seconds
[2024-09-06T07:29:09.457+0000] {processor.py:161} INFO - Started process (PID=2258) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:29:09.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:29:09.501+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:29:09.500+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:29:10.971+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:29:10.964+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:29:10.974+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:29:11.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.575 seconds
[2024-09-06T07:29:41.632+0000] {processor.py:161} INFO - Started process (PID=2277) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:29:41.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:29:41.641+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:29:41.640+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:29:43.037+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:29:43.030+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:29:43.039+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:29:43.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.452 seconds
[2024-09-06T07:30:02.988+0000] {processor.py:161} INFO - Started process (PID=2289) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:02.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:30:02.994+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:30:02.993+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:03.026+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:30:03.024+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34
    = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
    ^
SyntaxError: invalid syntax
[2024-09-06T07:30:03.027+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:03.070+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.095 seconds
[2024-09-06T07:30:05.079+0000] {processor.py:161} INFO - Started process (PID=2300) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:05.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:30:05.085+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:30:05.084+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:06.273+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:30:06.267+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:30:06.276+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:06.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.249 seconds
[2024-09-06T07:30:11.464+0000] {processor.py:161} INFO - Started process (PID=2306) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:11.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:30:11.468+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:30:11.468+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:12.815+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:30:12.808+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:30:12.817+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:12.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.403 seconds
[2024-09-06T07:30:15.551+0000] {processor.py:161} INFO - Started process (PID=2312) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:15.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:30:15.555+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:30:15.555+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:16.630+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:30:16.622+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:30:16.633+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:16.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.130 seconds
[2024-09-06T07:30:47.329+0000] {processor.py:161} INFO - Started process (PID=2330) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:47.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:30:47.333+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:30:47.332+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:48.217+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:30:48.211+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:30:48.218+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:30:48.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.929 seconds
[2024-09-06T07:31:18.594+0000] {processor.py:161} INFO - Started process (PID=2348) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:31:18.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:31:18.599+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:31:18.599+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:31:19.798+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:31:19.792+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:31:19.800+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:31:19.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.255 seconds
[2024-09-06T07:31:50.208+0000] {processor.py:161} INFO - Started process (PID=2366) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:31:50.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:31:50.214+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:31:50.213+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:31:51.232+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:31:51.226+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:31:51.234+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:31:51.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.065 seconds
[2024-09-06T07:32:21.736+0000] {processor.py:161} INFO - Started process (PID=2384) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:32:21.738+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:32:21.740+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:32:21.740+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:32:22.954+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:32:22.947+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:32:22.955+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:32:22.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.256 seconds
[2024-09-06T07:32:53.088+0000] {processor.py:161} INFO - Started process (PID=2402) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:32:53.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:32:53.092+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:32:53.091+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:32:53.981+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:32:53.975+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:32:53.983+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:32:54.012+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.935 seconds
[2024-09-06T07:33:24.283+0000] {processor.py:161} INFO - Started process (PID=2420) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:33:24.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:33:24.287+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:33:24.287+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:33:25.277+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:33:25.269+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:33:25.278+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:33:25.308+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.036 seconds
[2024-09-06T07:33:55.644+0000] {processor.py:161} INFO - Started process (PID=2438) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:33:55.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:33:55.648+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:33:55.647+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:33:56.929+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:33:56.922+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:33:56.931+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:33:56.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.333 seconds
[2024-09-06T07:34:27.198+0000] {processor.py:161} INFO - Started process (PID=2457) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:34:27.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:34:27.204+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:34:27.204+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:34:28.206+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:34:28.197+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:34:28.207+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:34:28.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.049 seconds
[2024-09-06T07:34:58.654+0000] {processor.py:161} INFO - Started process (PID=2475) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:34:58.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:34:58.658+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:34:58.657+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:34:59.738+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:34:59.732+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:34:59.740+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:34:59.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.125 seconds
[2024-09-06T07:35:30.146+0000] {processor.py:161} INFO - Started process (PID=2493) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:35:30.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:35:30.149+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:35:30.149+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:35:30.999+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:35:30.993+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:35:31.000+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:35:31.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.895 seconds
[2024-09-06T07:36:01.531+0000] {processor.py:161} INFO - Started process (PID=2511) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:36:01.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:36:01.535+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:36:01.535+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:36:02.522+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:36:02.517+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:36:02.524+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:36:02.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.033 seconds
[2024-09-06T07:36:32.807+0000] {processor.py:161} INFO - Started process (PID=2529) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:36:32.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:36:32.812+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:36:32.811+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:36:33.935+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:36:33.928+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:36:33.936+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:36:33.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.165 seconds
[2024-09-06T07:37:04.100+0000] {processor.py:161} INFO - Started process (PID=2547) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:37:04.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:37:04.104+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:37:04.104+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:37:04.974+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:37:04.968+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:37:04.976+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:37:05.005+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.913 seconds
[2024-09-06T07:37:35.279+0000] {processor.py:161} INFO - Started process (PID=2565) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:37:35.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:37:35.283+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:37:35.282+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:37:36.347+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:37:36.339+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:37:36.348+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:37:36.380+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.109 seconds
[2024-09-06T07:38:06.642+0000] {processor.py:161} INFO - Started process (PID=2590) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:38:06.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:38:06.648+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:38:06.647+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:38:07.702+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:38:07.696+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:38:07.703+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:38:07.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.119 seconds
[2024-09-06T07:38:37.898+0000] {processor.py:161} INFO - Started process (PID=2609) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:38:37.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:38:37.907+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:38:37.906+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:38:39.374+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:38:39.366+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:38:39.375+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:38:39.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.532 seconds
[2024-09-06T07:39:09.760+0000] {processor.py:161} INFO - Started process (PID=2627) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:39:09.761+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:39:09.765+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:39:09.765+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:39:11.514+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:39:11.505+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:39:11.516+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:39:11.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.824 seconds
[2024-09-06T07:39:41.983+0000] {processor.py:161} INFO - Started process (PID=2645) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:39:41.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:39:41.988+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:39:41.988+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:39:43.625+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:39:43.612+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:39:43.628+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:39:43.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.703 seconds
[2024-09-06T07:40:14.012+0000] {processor.py:161} INFO - Started process (PID=2663) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:40:14.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:40:14.016+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:40:14.016+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:40:15.186+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:40:15.178+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:40:15.189+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:40:15.230+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.227 seconds
[2024-09-06T07:40:45.443+0000] {processor.py:161} INFO - Started process (PID=2682) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:40:45.444+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:40:45.447+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:40:45.446+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:40:46.361+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:40:46.354+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:40:46.362+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:40:46.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.951 seconds
[2024-09-06T07:41:16.640+0000] {processor.py:161} INFO - Started process (PID=2700) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:41:16.642+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:41:16.645+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:41:16.645+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:41:18.203+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:41:18.155+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:41:18.210+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:41:18.261+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.636 seconds
[2024-09-06T07:41:48.653+0000] {processor.py:161} INFO - Started process (PID=2718) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:41:48.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:41:48.657+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:41:48.657+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:41:50.226+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:41:50.076+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:41:50.232+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:41:50.278+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.634 seconds
[2024-09-06T07:42:20.448+0000] {processor.py:161} INFO - Started process (PID=2736) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:42:20.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:42:20.452+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:42:20.452+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:42:21.852+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:42:21.844+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:42:21.853+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:42:21.892+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.456 seconds
[2024-09-06T07:42:52.516+0000] {processor.py:161} INFO - Started process (PID=2754) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:42:52.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:42:52.524+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:42:52.523+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:42:54.864+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:42:54.850+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:42:54.867+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:42:54.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.411 seconds
[2024-09-06T07:43:25.479+0000] {processor.py:161} INFO - Started process (PID=2772) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:43:25.482+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:43:25.485+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:43:25.485+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:43:26.584+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:43:26.575+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:43:26.586+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:43:26.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.165 seconds
[2024-09-06T07:43:56.958+0000] {processor.py:161} INFO - Started process (PID=2790) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:43:56.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:43:56.964+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:43:56.963+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:43:57.910+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:43:57.905+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:43:57.911+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:43:57.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.990 seconds
[2024-09-06T07:44:28.071+0000] {processor.py:161} INFO - Started process (PID=2808) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:44:28.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:44:28.076+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:44:28.075+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:44:29.758+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:44:29.721+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:44:29.761+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:44:29.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.803 seconds
[2024-09-06T07:47:24.738+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:47:24.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:47:24.761+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:47:24.760+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:47:29.371+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:47:29.363+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:47:29.372+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:47:29.405+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.692 seconds
[2024-09-06T07:47:59.691+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:47:59.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:47:59.695+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:47:59.695+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:48:00.495+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:48:00.489+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:48:00.497+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:48:00.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.843 seconds
[2024-09-06T07:48:30.747+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:48:30.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:48:30.750+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:48:30.750+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:48:31.531+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:48:31.526+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:48:31.532+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:48:31.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.822 seconds
[2024-09-06T07:49:01.913+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:49:01.922+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:49:01.931+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:49:01.930+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:49:03.477+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:49:03.471+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:49:03.478+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:49:03.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.623 seconds
[2024-09-06T07:49:33.877+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:49:33.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:49:33.881+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:49:33.881+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:49:34.950+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:49:34.940+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:49:34.952+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:49:34.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.122 seconds
[2024-09-06T07:50:05.384+0000] {processor.py:161} INFO - Started process (PID=264) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:50:05.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:50:05.388+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:50:05.388+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:50:06.477+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:50:06.473+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:50:06.478+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:50:06.520+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.145 seconds
[2024-09-06T07:50:36.789+0000] {processor.py:161} INFO - Started process (PID=282) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:50:36.790+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:50:36.793+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:50:36.792+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:50:37.817+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:50:37.810+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:50:37.819+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:50:37.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.066 seconds
[2024-09-06T07:51:07.909+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:51:07.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:51:07.913+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:51:07.912+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:51:08.830+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:51:08.826+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:51:08.831+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:51:08.859+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.959 seconds
[2024-09-06T07:51:39.336+0000] {processor.py:161} INFO - Started process (PID=318) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:51:39.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:51:39.340+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:51:39.339+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:51:40.510+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:51:40.504+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:51:40.512+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:51:40.557+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.229 seconds
[2024-09-06T07:52:10.619+0000] {processor.py:161} INFO - Started process (PID=336) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:52:10.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:52:10.623+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:52:10.622+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:52:11.448+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:52:11.443+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:52:11.449+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:52:11.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.870 seconds
[2024-09-06T07:52:42.166+0000] {processor.py:161} INFO - Started process (PID=354) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:52:42.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:52:42.171+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:52:42.170+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:52:43.465+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:52:43.450+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:52:43.467+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:52:43.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.357 seconds
[2024-09-06T07:53:13.805+0000] {processor.py:161} INFO - Started process (PID=372) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:53:13.812+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:53:13.816+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:53:13.816+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:53:14.793+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:53:14.786+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:53:14.794+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:53:14.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.068 seconds
[2024-09-06T07:53:44.959+0000] {processor.py:161} INFO - Started process (PID=390) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:53:44.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:53:44.963+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:53:44.962+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:53:45.684+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:53:45.679+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:53:45.685+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:53:45.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.756 seconds
[2024-09-06T07:54:16.195+0000] {processor.py:161} INFO - Started process (PID=409) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:54:16.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:54:16.211+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:54:16.210+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:54:17.277+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:54:17.273+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:54:17.278+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:54:17.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.126 seconds
[2024-09-06T07:54:47.575+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:54:47.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:54:47.579+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:54:47.578+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:54:48.594+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:54:48.588+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:54:48.595+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:54:48.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.059 seconds
[2024-09-06T07:55:18.890+0000] {processor.py:161} INFO - Started process (PID=452) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:55:18.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:55:18.894+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:55:18.893+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:55:19.953+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:55:19.946+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:55:19.954+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:55:19.989+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.107 seconds
[2024-09-06T07:55:50.231+0000] {processor.py:161} INFO - Started process (PID=470) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:55:50.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:55:50.235+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:55:50.234+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:55:51.231+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:55:51.227+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:55:51.232+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:55:51.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.038 seconds
[2024-09-06T07:56:21.586+0000] {processor.py:161} INFO - Started process (PID=488) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:56:21.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:56:21.594+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:56:21.594+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:56:23.074+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:56:23.064+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:56:23.076+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:56:23.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.551 seconds
[2024-09-06T07:56:54.109+0000] {processor.py:161} INFO - Started process (PID=505) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:56:54.111+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:56:54.113+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:56:54.113+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:56:54.987+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:56:54.981+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:56:54.988+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:56:55.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.914 seconds
[2024-09-06T07:57:25.437+0000] {processor.py:161} INFO - Started process (PID=529) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:57:25.438+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:57:25.441+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:57:25.441+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:57:26.356+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:57:26.350+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:57:26.358+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:57:26.392+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.962 seconds
[2024-09-06T07:57:56.755+0000] {processor.py:161} INFO - Started process (PID=547) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:57:56.756+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:57:56.759+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:57:56.758+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:57:57.880+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:57:57.873+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:57:57.881+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:57:57.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.178 seconds
[2024-09-06T07:58:28.030+0000] {processor.py:161} INFO - Started process (PID=565) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:58:28.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:58:28.036+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:58:28.036+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:58:29.526+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:58:29.516+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:58:29.528+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:58:29.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.550 seconds
[2024-09-06T07:58:59.943+0000] {processor.py:161} INFO - Started process (PID=583) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:58:59.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:58:59.954+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:58:59.953+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:59:02.005+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:59:01.999+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:59:02.007+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:59:02.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.118 seconds
[2024-09-06T07:59:32.511+0000] {processor.py:161} INFO - Started process (PID=602) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:59:32.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T07:59:32.515+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:59:32.515+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:59:34.105+0000] {logging_mixin.py:188} INFO - [2024-09-06T07:59:34.100+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T07:59:34.108+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T07:59:34.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.640 seconds
[2024-09-06T08:00:04.435+0000] {processor.py:161} INFO - Started process (PID=621) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:00:04.438+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:00:04.441+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:00:04.440+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:00:05.411+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:00:05.406+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:00:05.412+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:00:05.447+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.023 seconds
[2024-09-06T08:00:35.572+0000] {processor.py:161} INFO - Started process (PID=639) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:00:35.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:00:35.575+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:00:35.575+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:00:36.394+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:00:36.387+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:00:36.395+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:00:36.415+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.851 seconds
[2024-09-06T08:01:06.717+0000] {processor.py:161} INFO - Started process (PID=657) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:01:06.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:01:06.722+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:01:06.721+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:01:07.964+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:01:07.954+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:01:07.965+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:01:08.023+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.317 seconds
[2024-09-06T08:01:38.356+0000] {processor.py:161} INFO - Started process (PID=675) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:01:38.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:01:38.360+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:01:38.360+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:01:39.331+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:01:39.318+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:01:39.332+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:01:39.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.022 seconds
[2024-09-06T08:02:09.609+0000] {processor.py:161} INFO - Started process (PID=693) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:02:09.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:02:09.613+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:02:09.613+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:02:10.951+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:02:10.946+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:02:10.952+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:02:10.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.390 seconds
[2024-09-06T08:02:41.302+0000] {processor.py:161} INFO - Started process (PID=711) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:02:41.304+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:02:41.307+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:02:41.307+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:02:42.410+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:02:42.404+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:02:42.412+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:02:42.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.157 seconds
[2024-09-06T08:03:12.743+0000] {processor.py:161} INFO - Started process (PID=729) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:03:12.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:03:12.751+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:03:12.750+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:03:14.378+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:03:14.372+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:03:14.381+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:03:14.423+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.691 seconds
[2024-09-06T08:03:44.761+0000] {processor.py:161} INFO - Started process (PID=747) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:03:44.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:03:44.766+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:03:44.765+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:03:45.589+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:03:45.583+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:03:45.590+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:03:45.615+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.863 seconds
[2024-09-06T08:04:15.861+0000] {processor.py:161} INFO - Started process (PID=765) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:04:15.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:04:15.865+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:04:15.865+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:04:16.751+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:04:16.746+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:04:16.752+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:04:16.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.928 seconds
[2024-09-06T08:04:47.077+0000] {processor.py:161} INFO - Started process (PID=783) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:04:47.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:04:47.089+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:04:47.088+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:04:47.971+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:04:47.965+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:04:47.972+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:04:47.994+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.928 seconds
[2024-09-06T08:05:18.285+0000] {processor.py:161} INFO - Started process (PID=801) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:05:18.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:05:18.288+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:05:18.288+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:05:19.287+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:05:19.283+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:05:19.288+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:05:19.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.032 seconds
[2024-09-06T08:05:49.557+0000] {processor.py:161} INFO - Started process (PID=819) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:05:49.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:05:49.561+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:05:49.560+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:05:50.623+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:05:50.620+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:05:50.625+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:05:50.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.099 seconds
[2024-09-06T08:06:20.868+0000] {processor.py:161} INFO - Started process (PID=837) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:06:20.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:06:20.874+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:06:20.871+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:06:21.915+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:06:21.911+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:06:21.917+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:06:21.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.101 seconds
[2024-09-06T08:06:52.071+0000] {processor.py:161} INFO - Started process (PID=855) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:06:52.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:06:52.075+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:06:52.074+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:06:52.887+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:06:52.881+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:06:52.888+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:06:52.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.859 seconds
[2024-09-06T08:07:23.005+0000] {processor.py:161} INFO - Started process (PID=873) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:07:23.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:07:23.008+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:07:23.008+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:07:24.139+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:07:24.133+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:07:24.140+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:07:24.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.175 seconds
[2024-09-06T08:07:54.491+0000] {processor.py:161} INFO - Started process (PID=891) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:07:54.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:07:54.496+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:07:54.495+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:07:55.587+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:07:55.582+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:07:55.588+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:07:55.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.132 seconds
[2024-09-06T08:08:25.860+0000] {processor.py:161} INFO - Started process (PID=909) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:08:25.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:08:25.864+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:08:25.863+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:08:26.947+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:08:26.941+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:08:26.948+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:08:26.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.121 seconds
[2024-09-06T08:08:57.233+0000] {processor.py:161} INFO - Started process (PID=934) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:08:57.235+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:08:57.237+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:08:57.237+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:08:58.109+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:08:58.104+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:08:58.110+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:08:58.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.907 seconds
[2024-09-06T08:09:28.568+0000] {processor.py:161} INFO - Started process (PID=953) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:09:28.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:09:28.571+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:09:28.571+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:09:29.368+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:09:29.363+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:09:29.369+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:09:29.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.836 seconds
[2024-09-06T08:09:59.738+0000] {processor.py:161} INFO - Started process (PID=971) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:09:59.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:09:59.742+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:09:59.742+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:10:01.319+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:10:01.313+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:10:01.321+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:10:01.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.636 seconds
[2024-09-06T08:10:31.621+0000] {processor.py:161} INFO - Started process (PID=989) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:10:31.623+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:10:31.626+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:10:31.626+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:10:32.330+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:10:32.325+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:10:32.331+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:10:32.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.742 seconds
[2024-09-06T08:11:02.653+0000] {processor.py:161} INFO - Started process (PID=1007) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:11:02.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:11:02.657+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:11:02.656+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:11:03.564+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:11:03.558+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:11:03.566+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:11:03.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.948 seconds
[2024-09-06T08:11:33.855+0000] {processor.py:161} INFO - Started process (PID=1025) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:11:33.857+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:11:33.859+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:11:33.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:11:34.573+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:11:34.569+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:11:34.574+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:11:34.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.750 seconds
[2024-09-06T08:12:04.860+0000] {processor.py:161} INFO - Started process (PID=1043) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:12:04.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:12:04.864+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:12:04.864+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:12:05.664+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:12:05.658+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:12:05.665+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:12:05.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.840 seconds
[2024-09-06T08:12:35.911+0000] {processor.py:161} INFO - Started process (PID=1061) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:12:35.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:12:35.915+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:12:35.914+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:12:36.641+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:12:36.635+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:12:36.642+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:12:36.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.764 seconds
[2024-09-06T08:13:06.931+0000] {processor.py:161} INFO - Started process (PID=1080) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:13:06.932+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:13:06.937+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:13:06.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:13:08.032+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:13:08.026+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:13:08.033+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:13:08.067+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.154 seconds
[2024-09-06T08:13:38.364+0000] {processor.py:161} INFO - Started process (PID=1097) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:13:38.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:13:38.370+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:13:38.370+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:13:39.762+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:13:39.757+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:13:39.763+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:13:39.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.437 seconds
[2024-09-06T08:14:10.634+0000] {processor.py:161} INFO - Started process (PID=1114) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:14:10.642+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:14:10.648+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:14:10.647+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:14:11.582+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:14:11.577+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:14:11.583+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:14:11.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.008 seconds
[2024-09-06T08:14:41.899+0000] {processor.py:161} INFO - Started process (PID=1133) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:14:41.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:14:41.902+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:14:41.902+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:14:42.587+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:14:42.583+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:14:42.588+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:14:42.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.721 seconds
[2024-09-06T08:15:12.872+0000] {processor.py:161} INFO - Started process (PID=1152) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:15:12.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:15:12.875+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:15:12.875+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:15:13.792+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:15:13.788+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:15:13.793+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:15:13.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.958 seconds
[2024-09-06T08:15:43.992+0000] {processor.py:161} INFO - Started process (PID=1170) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:15:43.993+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:15:43.995+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:15:43.995+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:15:44.684+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:15:44.679+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:15:44.685+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:15:44.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.726 seconds
[2024-09-06T08:16:14.964+0000] {processor.py:161} INFO - Started process (PID=1188) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:16:14.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:16:14.974+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:16:14.974+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:16:15.819+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:16:15.813+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:16:15.820+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:16:15.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.898 seconds
[2024-09-06T08:16:46.111+0000] {processor.py:161} INFO - Started process (PID=1206) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:16:46.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:16:46.115+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:16:46.114+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:16:46.805+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:16:46.801+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:16:46.806+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:16:46.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.722 seconds
[2024-09-06T08:17:17.086+0000] {processor.py:161} INFO - Started process (PID=1224) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:17:17.087+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:17:17.091+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:17:17.091+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:17:17.881+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:17:17.877+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:17:17.882+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:17:17.902+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.825 seconds
[2024-09-06T08:17:48.150+0000] {processor.py:161} INFO - Started process (PID=1242) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:17:48.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:17:48.154+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:17:48.153+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:17:48.909+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:17:48.903+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:17:48.910+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:17:48.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.793 seconds
[2024-09-06T08:18:19.171+0000] {processor.py:161} INFO - Started process (PID=1260) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:18:19.172+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:18:19.175+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:18:19.174+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:18:19.841+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:18:19.836+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:18:19.842+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:18:19.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.703 seconds
[2024-09-06T08:18:50.115+0000] {processor.py:161} INFO - Started process (PID=1278) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:18:50.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:18:50.119+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:18:50.118+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:18:51.111+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:18:51.106+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:18:51.112+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:18:51.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.026 seconds
[2024-09-06T08:19:21.337+0000] {processor.py:161} INFO - Started process (PID=1296) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:19:21.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:19:21.342+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:19:21.341+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:19:22.114+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:19:22.110+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:19:22.115+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:19:22.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.809 seconds
[2024-09-06T08:19:52.562+0000] {processor.py:161} INFO - Started process (PID=1314) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:19:52.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:19:52.567+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:19:52.566+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:19:53.418+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:19:53.412+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:19:53.420+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:19:53.463+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.910 seconds
[2024-09-06T08:20:23.729+0000] {processor.py:161} INFO - Started process (PID=1332) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:20:23.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:20:23.734+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:20:23.734+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:20:24.463+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:20:24.458+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:20:24.465+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:20:24.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.776 seconds
[2024-09-06T08:20:54.735+0000] {processor.py:161} INFO - Started process (PID=1351) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:20:54.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:20:54.739+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:20:54.738+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:20:55.482+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:20:55.477+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:20:55.483+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:20:55.510+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.781 seconds
[2024-09-06T08:21:25.761+0000] {processor.py:161} INFO - Started process (PID=1370) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:21:25.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:21:25.764+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:21:25.764+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:21:26.467+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:21:26.462+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:21:26.468+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:21:26.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.741 seconds
[2024-09-06T08:21:56.637+0000] {processor.py:161} INFO - Started process (PID=1388) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:21:56.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:21:56.642+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:21:56.642+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:21:57.328+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:21:57.323+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:21:57.329+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:21:57.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.723 seconds
[2024-09-06T08:22:27.618+0000] {processor.py:161} INFO - Started process (PID=1412) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:22:27.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:22:27.623+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:22:27.622+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:22:28.429+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:22:28.422+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:22:28.430+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:22:28.459+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.850 seconds
[2024-09-06T08:22:58.714+0000] {processor.py:161} INFO - Started process (PID=1430) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:22:58.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:22:58.719+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:22:58.718+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:22:59.574+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:22:59.569+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:22:59.575+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:22:59.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.900 seconds
[2024-09-06T08:23:29.841+0000] {processor.py:161} INFO - Started process (PID=1449) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:23:29.842+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:23:29.845+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:23:29.844+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:23:30.578+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:23:30.575+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:23:30.579+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:23:30.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.769 seconds
[2024-09-06T08:24:01.315+0000] {processor.py:161} INFO - Started process (PID=1467) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:24:01.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:24:01.320+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:24:01.319+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:24:02.124+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:24:02.118+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:24:02.125+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:24:02.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.844 seconds
[2024-09-06T08:24:32.406+0000] {processor.py:161} INFO - Started process (PID=1485) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:24:32.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:24:32.410+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:24:32.409+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:24:33.117+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:24:33.111+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:24:33.118+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:24:33.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.749 seconds
[2024-09-06T08:25:03.472+0000] {processor.py:161} INFO - Started process (PID=1504) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:25:03.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:25:03.486+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:25:03.486+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:25:05.072+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:25:05.068+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:25:05.073+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:25:05.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.641 seconds
[2024-09-06T08:25:35.462+0000] {processor.py:161} INFO - Started process (PID=1522) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:25:35.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:25:35.465+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:25:35.465+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:25:36.167+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:25:36.161+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:25:36.168+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:25:36.194+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.739 seconds
[2024-09-06T08:26:06.443+0000] {processor.py:161} INFO - Started process (PID=1540) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:26:06.444+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:26:06.447+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:26:06.446+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:26:07.554+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:26:07.548+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:26:07.555+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:26:07.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.168 seconds
[2024-09-06T08:26:37.667+0000] {processor.py:161} INFO - Started process (PID=1558) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:26:37.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:26:37.670+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:26:37.670+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:26:38.352+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:26:38.346+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:26:38.353+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:26:38.378+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.718 seconds
[2024-09-06T08:27:08.584+0000] {processor.py:161} INFO - Started process (PID=1576) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:27:08.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:27:08.587+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:27:08.587+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:27:09.412+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:27:09.406+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:27:09.413+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:27:09.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.862 seconds
[2024-09-06T08:27:40.087+0000] {processor.py:161} INFO - Started process (PID=1594) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:27:40.088+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:27:40.091+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:27:40.091+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:27:40.857+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:27:40.852+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:27:40.858+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:27:40.902+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.822 seconds
[2024-09-06T08:28:11.222+0000] {processor.py:161} INFO - Started process (PID=1612) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:28:11.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:28:11.227+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:28:11.226+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:28:12.135+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:28:12.130+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:28:12.136+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:28:12.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.965 seconds
[2024-09-06T08:28:42.429+0000] {processor.py:161} INFO - Started process (PID=1631) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:28:42.430+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:28:42.433+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:28:42.432+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:28:43.285+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:28:43.281+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:28:43.286+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:28:43.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.887 seconds
[2024-09-06T08:29:13.549+0000] {processor.py:161} INFO - Started process (PID=1649) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:29:13.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:29:13.552+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:29:13.552+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:29:14.477+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:29:14.472+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:29:14.478+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:29:14.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.963 seconds
[2024-09-06T08:29:44.773+0000] {processor.py:161} INFO - Started process (PID=1667) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:29:44.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:29:44.776+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:29:44.776+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:29:45.482+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:29:45.477+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:29:45.483+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:29:45.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.742 seconds
[2024-09-06T08:30:15.750+0000] {processor.py:161} INFO - Started process (PID=1685) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:30:15.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:30:15.754+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:30:15.753+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:30:16.532+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:30:16.527+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:30:16.533+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:30:16.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.827 seconds
[2024-09-06T08:30:46.821+0000] {processor.py:161} INFO - Started process (PID=1703) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:30:46.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:30:46.824+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:30:46.823+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:30:47.569+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:30:47.563+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:30:47.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:30:47.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.781 seconds
[2024-09-06T08:31:17.839+0000] {processor.py:161} INFO - Started process (PID=1721) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:31:17.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:31:17.842+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:31:17.842+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:31:18.667+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:31:18.662+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:31:18.668+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:31:18.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.883 seconds
[2024-09-06T08:31:48.954+0000] {processor.py:161} INFO - Started process (PID=1739) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:31:48.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:31:48.959+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:31:48.958+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:31:49.681+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:31:49.675+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:31:49.682+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:31:49.709+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.763 seconds
[2024-09-06T08:32:19.875+0000] {processor.py:161} INFO - Started process (PID=1757) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:32:19.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:32:19.879+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:32:19.878+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:32:20.741+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:32:20.736+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:32:20.742+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:32:20.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.903 seconds
[2024-09-06T08:32:51.025+0000] {processor.py:161} INFO - Started process (PID=1775) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:32:51.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:32:51.029+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:32:51.028+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:32:51.877+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:32:51.872+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:32:51.878+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:32:51.904+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.885 seconds
[2024-09-06T08:33:22.149+0000] {processor.py:161} INFO - Started process (PID=1793) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:33:22.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:33:22.153+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:33:22.153+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:33:22.862+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:33:22.856+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:33:22.863+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:33:22.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.748 seconds
[2024-09-06T08:33:53.140+0000] {processor.py:161} INFO - Started process (PID=1812) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:33:53.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:33:53.144+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:33:53.144+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:33:54.131+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:33:54.126+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:33:54.133+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:33:54.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.065 seconds
[2024-09-06T08:34:24.561+0000] {processor.py:161} INFO - Started process (PID=1831) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:34:24.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:34:24.566+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:34:24.565+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:34:26.207+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:34:26.201+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:34:26.208+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:34:26.258+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.720 seconds
[2024-09-06T08:34:56.539+0000] {processor.py:161} INFO - Started process (PID=1849) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:34:56.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:34:56.542+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:34:56.542+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:34:57.208+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:34:57.204+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:34:57.209+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:34:57.226+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.694 seconds
[2024-09-06T08:35:27.492+0000] {processor.py:161} INFO - Started process (PID=1867) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:35:27.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:35:27.497+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:35:27.497+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:35:28.163+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:35:28.157+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:35:28.164+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:35:28.190+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.705 seconds
[2024-09-06T08:35:58.435+0000] {processor.py:161} INFO - Started process (PID=1886) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:35:58.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:35:58.438+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:35:58.438+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:35:59.172+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:35:59.167+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:35:59.172+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:35:59.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.769 seconds
[2024-09-06T08:36:29.449+0000] {processor.py:161} INFO - Started process (PID=1909) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:36:29.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:36:29.453+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:36:29.453+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:36:30.183+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:36:30.178+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:36:30.184+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:36:30.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.769 seconds
[2024-09-06T08:37:00.510+0000] {processor.py:161} INFO - Started process (PID=1927) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:37:00.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:37:00.515+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:37:00.514+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:37:01.396+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:37:01.392+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:37:01.397+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:37:01.424+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.943 seconds
[2024-09-06T08:37:31.933+0000] {processor.py:161} INFO - Started process (PID=1945) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:37:31.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:37:31.936+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:37:31.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:37:32.785+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:37:32.781+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:37:32.786+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:37:32.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.883 seconds
[2024-09-06T08:38:03.049+0000] {processor.py:161} INFO - Started process (PID=1963) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:38:03.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:38:03.053+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:38:03.053+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:38:04.049+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:38:04.043+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:38:04.050+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:38:04.083+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.043 seconds
[2024-09-06T08:38:34.327+0000] {processor.py:161} INFO - Started process (PID=1982) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:38:34.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:38:34.332+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:38:34.331+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:38:35.172+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:38:35.168+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:38:35.173+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:38:35.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.883 seconds
[2024-09-06T08:39:05.461+0000] {processor.py:161} INFO - Started process (PID=2000) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:39:05.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:39:05.465+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:39:05.464+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:39:06.275+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:39:06.268+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:39:06.277+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:39:06.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.870 seconds
[2024-09-06T08:39:36.599+0000] {processor.py:161} INFO - Started process (PID=2018) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:39:36.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:39:36.604+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:39:36.603+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:39:37.591+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:39:37.585+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:39:37.592+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:39:37.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.028 seconds
[2024-09-06T08:40:07.750+0000] {processor.py:161} INFO - Started process (PID=2036) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:40:07.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:40:07.754+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:40:07.753+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:40:08.590+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:40:08.585+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:40:08.591+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:40:08.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.886 seconds
[2024-09-06T08:40:39.491+0000] {processor.py:161} INFO - Started process (PID=2054) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:40:39.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:40:39.495+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:40:39.495+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:40:40.182+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:40:40.176+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:40:40.183+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:40:40.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.723 seconds
[2024-09-06T08:41:10.470+0000] {processor.py:161} INFO - Started process (PID=2072) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:41:10.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:41:10.474+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:41:10.474+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:41:11.265+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:41:11.261+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:41:11.266+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:41:11.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.849 seconds
[2024-09-06T08:41:41.783+0000] {processor.py:161} INFO - Started process (PID=2090) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:41:41.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:41:41.789+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:41:41.788+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:41:42.606+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:41:42.601+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:41:42.607+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:41:42.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.863 seconds
[2024-09-06T08:42:12.908+0000] {processor.py:161} INFO - Started process (PID=2108) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:42:12.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:42:12.913+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:42:12.912+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:42:13.783+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:42:13.778+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:42:13.785+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:42:13.813+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.912 seconds
[2024-09-06T08:42:44.105+0000] {processor.py:161} INFO - Started process (PID=2126) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:42:44.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:42:44.109+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:42:44.109+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:42:44.899+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:42:44.895+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:42:44.900+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:42:44.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.827 seconds
[2024-09-06T08:43:15.040+0000] {processor.py:161} INFO - Started process (PID=2144) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:43:15.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:43:15.047+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:43:15.047+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:43:16.003+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:43:15.997+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:43:16.005+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:43:16.033+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.004 seconds
[2024-09-06T08:43:46.279+0000] {processor.py:161} INFO - Started process (PID=2162) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:43:46.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:43:46.283+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:43:46.282+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:43:46.976+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:43:46.971+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:43:46.977+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:43:47.003+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.730 seconds
[2024-09-06T08:44:17.247+0000] {processor.py:161} INFO - Started process (PID=2180) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:44:17.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:44:17.251+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:44:17.251+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:44:18.040+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:44:18.034+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:44:18.042+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:44:18.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.827 seconds
[2024-09-06T08:44:48.326+0000] {processor.py:161} INFO - Started process (PID=2198) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:44:48.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:44:48.329+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:44:48.329+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:44:49.025+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:44:49.017+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:44:49.026+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:44:49.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.734 seconds
[2024-09-06T08:45:19.333+0000] {processor.py:161} INFO - Started process (PID=2216) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:45:19.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:45:19.338+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:45:19.338+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:45:20.148+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:45:20.143+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:45:20.149+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:45:20.210+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.884 seconds
[2024-09-06T08:45:50.472+0000] {processor.py:161} INFO - Started process (PID=2234) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:45:50.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:45:50.476+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:45:50.475+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:45:51.162+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:45:51.158+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:45:51.163+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:45:51.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.721 seconds
[2024-09-06T08:46:21.415+0000] {processor.py:161} INFO - Started process (PID=2252) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:46:21.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:46:21.418+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:46:21.418+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:46:22.281+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:46:22.275+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:46:22.282+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:46:22.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.899 seconds
[2024-09-06T08:46:52.545+0000] {processor.py:161} INFO - Started process (PID=2270) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:46:52.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:46:52.548+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:46:52.548+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:46:53.236+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:46:53.231+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:46:53.237+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:46:53.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.724 seconds
[2024-09-06T08:47:23.510+0000] {processor.py:161} INFO - Started process (PID=2288) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:47:23.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:47:23.515+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:47:23.514+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:47:24.289+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:47:24.283+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:47:24.290+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:47:24.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.824 seconds
[2024-09-06T08:47:54.573+0000] {processor.py:161} INFO - Started process (PID=2306) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:47:54.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:47:54.576+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:47:54.575+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:47:55.367+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:47:55.360+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:47:55.368+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:47:55.395+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.829 seconds
[2024-09-06T08:48:25.647+0000] {processor.py:161} INFO - Started process (PID=2324) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:48:25.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:48:25.651+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:48:25.651+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:48:26.375+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:48:26.369+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:48:26.377+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:48:26.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.772 seconds
[2024-09-06T08:48:56.667+0000] {processor.py:161} INFO - Started process (PID=2342) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:48:56.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:48:56.670+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:48:56.670+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:48:57.361+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:48:57.355+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:48:57.362+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:48:57.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.727 seconds
[2024-09-06T08:49:27.649+0000] {processor.py:161} INFO - Started process (PID=2360) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:49:27.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:49:27.652+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:49:27.652+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:49:28.486+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:49:28.481+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:49:28.488+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:49:28.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.878 seconds
[2024-09-06T08:49:58.778+0000] {processor.py:161} INFO - Started process (PID=2379) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:49:58.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:49:58.782+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:49:58.781+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:49:59.454+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:49:59.449+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:49:59.455+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:49:59.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.710 seconds
[2024-09-06T08:50:29.754+0000] {processor.py:161} INFO - Started process (PID=2397) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:50:29.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:50:29.758+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:50:29.757+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:50:30.457+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:50:30.451+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:50:30.458+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:50:30.485+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.739 seconds
[2024-09-06T08:51:01.156+0000] {processor.py:161} INFO - Started process (PID=2421) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:51:01.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:51:01.160+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:51:01.160+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:51:01.941+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:51:01.935+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:51:01.942+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:51:01.968+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.819 seconds
[2024-09-06T08:51:32.022+0000] {processor.py:161} INFO - Started process (PID=2440) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:51:32.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:51:32.025+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:51:32.025+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:51:32.860+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:51:32.854+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:51:32.861+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:51:32.886+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.870 seconds
[2024-09-06T08:52:03.084+0000] {processor.py:161} INFO - Started process (PID=2458) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:52:03.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:52:03.088+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:52:03.087+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:52:03.881+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:52:03.874+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:52:03.882+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:52:03.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.853 seconds
[2024-09-06T08:52:34.084+0000] {processor.py:161} INFO - Started process (PID=2476) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:52:34.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:52:34.088+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:52:34.087+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:52:34.786+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:52:34.781+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:52:34.787+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:52:34.813+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.735 seconds
[2024-09-06T08:53:05.072+0000] {processor.py:161} INFO - Started process (PID=2494) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:53:05.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:53:05.077+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:53:05.076+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:53:06.037+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:53:06.032+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:53:06.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:53:06.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.004 seconds
[2024-09-06T08:53:36.303+0000] {processor.py:161} INFO - Started process (PID=2512) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:53:36.304+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:53:36.306+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:53:36.306+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:53:37.049+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:53:37.044+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:53:37.050+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:53:37.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.778 seconds
[2024-09-06T08:54:07.327+0000] {processor.py:161} INFO - Started process (PID=2530) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:54:07.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:54:07.330+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:54:07.330+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:54:08.344+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:54:08.339+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:54:08.345+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:54:08.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.056 seconds
[2024-09-06T08:54:38.664+0000] {processor.py:161} INFO - Started process (PID=2548) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:54:38.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:54:38.667+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:54:38.667+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:54:39.441+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:54:39.437+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:54:39.442+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:54:39.460+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.803 seconds
[2024-09-06T08:55:09.777+0000] {processor.py:161} INFO - Started process (PID=2566) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:55:09.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:55:09.792+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:55:09.786+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:55:10.989+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:55:10.983+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:55:10.991+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:55:11.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.256 seconds
[2024-09-06T08:55:41.102+0000] {processor.py:161} INFO - Started process (PID=2584) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:55:41.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:55:41.105+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:55:41.105+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:55:41.825+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:55:41.821+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:55:41.826+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:55:41.845+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.749 seconds
[2024-09-06T08:56:12.335+0000] {processor.py:161} INFO - Started process (PID=2603) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:56:12.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:56:12.341+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:56:12.340+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:56:13.383+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:56:13.378+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:56:13.385+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:56:13.405+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.083 seconds
[2024-09-06T08:56:43.641+0000] {processor.py:161} INFO - Started process (PID=2620) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:56:43.642+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:56:43.644+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:56:43.644+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:56:44.313+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:56:44.306+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:56:44.315+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:56:44.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.700 seconds
[2024-09-06T08:57:14.594+0000] {processor.py:161} INFO - Started process (PID=2638) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:57:14.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:57:14.598+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:57:14.597+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:57:15.639+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:57:15.633+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:57:15.640+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:57:15.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.083 seconds
[2024-09-06T08:57:45.947+0000] {processor.py:161} INFO - Started process (PID=2656) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:57:45.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:57:45.950+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:57:45.950+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:57:46.624+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:57:46.620+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:57:46.625+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:57:46.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.702 seconds
[2024-09-06T08:58:16.903+0000] {processor.py:161} INFO - Started process (PID=2674) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:58:16.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:58:16.907+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:58:16.906+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:58:17.650+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:58:17.645+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:58:17.651+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:58:17.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.782 seconds
[2024-09-06T08:58:48.047+0000] {processor.py:161} INFO - Started process (PID=2692) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:58:48.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:58:48.050+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:58:48.050+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:58:48.766+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:58:48.761+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:58:48.767+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:58:48.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.753 seconds
[2024-09-06T08:59:19.042+0000] {processor.py:161} INFO - Started process (PID=2710) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:59:19.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:59:19.046+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:59:19.045+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:59:19.930+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:59:19.923+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:59:19.931+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:59:19.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.925 seconds
[2024-09-06T08:59:50.232+0000] {processor.py:161} INFO - Started process (PID=2728) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:59:50.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T08:59:50.235+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:59:50.235+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:59:50.917+0000] {logging_mixin.py:188} INFO - [2024-09-06T08:59:50.910+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T08:59:50.918+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T08:59:50.944+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.719 seconds
[2024-09-06T09:00:21.194+0000] {processor.py:161} INFO - Started process (PID=2746) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:00:21.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:00:21.198+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:00:21.198+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:00:21.919+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:00:21.914+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:00:21.919+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:00:21.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.757 seconds
[2024-09-06T09:00:52.192+0000] {processor.py:161} INFO - Started process (PID=2764) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:00:52.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:00:52.195+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:00:52.195+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:00:53.062+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:00:53.056+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:00:53.063+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:00:53.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.902 seconds
[2024-09-06T09:01:23.343+0000] {processor.py:161} INFO - Started process (PID=2782) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:01:23.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:01:23.347+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:01:23.346+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:01:24.223+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:01:24.217+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:01:24.224+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:01:24.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.918 seconds
[2024-09-06T09:01:54.717+0000] {processor.py:161} INFO - Started process (PID=2800) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:01:54.719+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:01:54.721+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:01:54.720+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:01:55.628+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:01:55.620+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:01:55.630+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:01:55.687+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.982 seconds
[2024-09-06T09:02:25.954+0000] {processor.py:161} INFO - Started process (PID=2818) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:02:25.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:02:25.957+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:02:25.957+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:02:26.672+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:02:26.667+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:02:26.673+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:02:26.699+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.751 seconds
[2024-09-06T09:02:56.955+0000] {processor.py:161} INFO - Started process (PID=2836) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:02:56.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:02:56.958+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:02:56.957+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:02:57.649+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:02:57.643+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:02:57.650+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:02:57.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.728 seconds
[2024-09-06T09:03:27.958+0000] {processor.py:161} INFO - Started process (PID=2854) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:03:27.959+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:03:27.962+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:03:27.961+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:03:28.676+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:03:28.670+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:03:28.677+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:03:28.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.756 seconds
[2024-09-06T09:03:58.941+0000] {processor.py:161} INFO - Started process (PID=2872) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:03:58.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:03:58.945+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:03:58.944+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:03:59.654+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:03:59.648+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:03:59.655+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:03:59.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.747 seconds
[2024-09-06T09:04:29.767+0000] {processor.py:161} INFO - Started process (PID=2891) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:04:29.768+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:04:29.770+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:04:29.770+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:04:30.528+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:04:30.523+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:04:30.529+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:04:30.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.790 seconds
[2024-09-06T09:05:00.628+0000] {processor.py:161} INFO - Started process (PID=2909) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:05:00.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:05:00.633+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:05:00.632+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:05:01.685+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:05:01.679+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:05:01.687+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:05:01.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.102 seconds
[2024-09-06T09:05:31.833+0000] {processor.py:161} INFO - Started process (PID=2933) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:05:31.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:05:31.839+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:05:31.837+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:05:32.825+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:05:32.815+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:05:32.827+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:05:32.875+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.049 seconds
[2024-09-06T09:06:03.491+0000] {processor.py:161} INFO - Started process (PID=2951) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:06:03.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:06:03.497+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:06:03.496+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:06:04.545+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:06:04.540+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:06:04.546+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:06:04.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.100 seconds
[2024-09-06T09:06:34.945+0000] {processor.py:161} INFO - Started process (PID=2969) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:06:34.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:06:34.950+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:06:34.950+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:06:36.955+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:06:36.944+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:06:36.956+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:06:36.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.061 seconds
[2024-09-06T09:07:07.653+0000] {processor.py:161} INFO - Started process (PID=2987) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:07:07.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:07:07.657+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:07:07.657+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:07:08.590+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:07:08.584+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:07:08.592+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:07:08.625+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.979 seconds
[2024-09-06T09:07:39.247+0000] {processor.py:161} INFO - Started process (PID=3005) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:07:39.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:07:39.251+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:07:39.251+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:07:40.287+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:07:40.279+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:07:40.288+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:07:40.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.091 seconds
[2024-09-06T09:08:10.609+0000] {processor.py:161} INFO - Started process (PID=3024) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:08:10.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:08:10.613+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:08:10.613+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:08:11.777+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:08:11.770+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:08:11.778+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:08:11.810+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.212 seconds
[2024-09-06T09:08:42.186+0000] {processor.py:161} INFO - Started process (PID=3042) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:08:42.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:08:42.190+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:08:42.189+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:08:43.856+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:08:43.850+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:08:43.857+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:08:43.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.716 seconds
[2024-09-06T09:17:41.394+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:17:41.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:17:41.409+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:17:41.409+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:17:53.988+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:17:53.347+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:17:54.148+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:17:54.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 13.177 seconds
[2024-09-06T09:18:32.219+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:18:32.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:18:32.357+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:18:32.356+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:18:43.625+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:18:42.928+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:18:43.661+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:18:43.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 11.605 seconds
[2024-09-06T09:19:17.745+0000] {processor.py:161} INFO - Started process (PID=213) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:19:18.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:19:18.967+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:19:18.966+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:19:28.661+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:19:27.800+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:19:28.859+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:19:29.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 11.725 seconds
[2024-09-06T09:20:03.647+0000] {processor.py:161} INFO - Started process (PID=232) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:20:03.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:20:03.804+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:20:03.804+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:20:14.785+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:20:14.659+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:20:14.788+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:20:14.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 11.385 seconds
[2024-09-06T09:20:45.404+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:20:45.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:20:45.423+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:20:45.422+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:20:49.810+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:20:49.782+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:20:49.816+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:20:49.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.522 seconds
[2024-09-06T09:21:20.507+0000] {processor.py:161} INFO - Started process (PID=276) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:21:20.508+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:21:20.511+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:21:20.511+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:21:21.798+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:21:21.792+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:21:21.800+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:21:21.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.335 seconds
[2024-09-06T09:21:52.126+0000] {processor.py:161} INFO - Started process (PID=294) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:21:52.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:21:52.133+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:21:52.132+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:21:53.052+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:21:53.044+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:21:53.053+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:21:53.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.969 seconds
[2024-09-06T09:22:23.211+0000] {processor.py:161} INFO - Started process (PID=312) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:22:23.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:22:23.215+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:22:23.215+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:22:24.201+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:22:24.192+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:22:24.203+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:22:24.239+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.036 seconds
[2024-09-06T09:22:54.835+0000] {processor.py:161} INFO - Started process (PID=330) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:22:54.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:22:54.840+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:22:54.840+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:22:55.996+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:22:55.988+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:22:55.998+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:22:56.022+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.195 seconds
[2024-09-06T09:23:26.175+0000] {processor.py:161} INFO - Started process (PID=348) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:23:26.177+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:23:26.180+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:23:26.180+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:23:27.094+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:23:27.088+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:23:27.095+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:23:27.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.968 seconds
[2024-09-06T09:23:57.453+0000] {processor.py:161} INFO - Started process (PID=366) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:23:57.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:23:57.461+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:23:57.460+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:23:58.470+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:23:58.463+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:23:58.471+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:23:58.500+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.067 seconds
[2024-09-06T09:24:28.770+0000] {processor.py:161} INFO - Started process (PID=383) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:24:28.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:24:28.775+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:24:28.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:24:30.557+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:24:30.547+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:24:30.558+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:24:30.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.837 seconds
[2024-09-06T09:25:00.705+0000] {processor.py:161} INFO - Started process (PID=401) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:25:00.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:25:00.710+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:25:00.710+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:25:01.718+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:25:01.712+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:25:01.720+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:25:01.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.053 seconds
[2024-09-06T09:25:32.289+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:25:32.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:25:32.312+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:25:32.311+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:25:33.327+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:25:33.321+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:25:33.328+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:25:33.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.085 seconds
[2024-09-06T09:26:03.979+0000] {processor.py:161} INFO - Started process (PID=437) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:26:03.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:26:03.987+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:26:03.987+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:26:07.673+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:26:07.662+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:26:07.675+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:26:07.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.791 seconds
[2024-09-06T09:26:37.999+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:26:38.003+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:26:38.007+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:26:38.006+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:26:39.244+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:26:39.238+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:26:39.245+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:26:39.278+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.297 seconds
[2024-09-06T09:27:10.056+0000] {processor.py:161} INFO - Started process (PID=479) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:27:10.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:27:10.065+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:27:10.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:27:11.204+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:27:11.198+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:27:11.206+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:27:11.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.200 seconds
[2024-09-06T09:27:41.480+0000] {processor.py:161} INFO - Started process (PID=497) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:27:41.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:27:41.486+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:27:41.484+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:27:42.446+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:27:42.438+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:27:42.448+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:27:42.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.010 seconds
[2024-09-06T09:28:12.786+0000] {processor.py:161} INFO - Started process (PID=515) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:28:12.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:28:12.791+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:28:12.790+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:28:14.106+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:28:14.098+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:28:14.108+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:28:14.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.372 seconds
[2024-09-06T09:28:44.603+0000] {processor.py:161} INFO - Started process (PID=534) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:28:44.605+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:28:44.608+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:28:44.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:28:45.913+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:28:45.905+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:28:45.915+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:28:45.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.357 seconds
[2024-09-06T09:29:16.185+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:29:16.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:29:16.190+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:29:16.189+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:29:17.121+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:29:17.114+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:29:17.123+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:29:17.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.973 seconds
[2024-09-06T09:29:47.627+0000] {processor.py:161} INFO - Started process (PID=572) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:29:47.628+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:29:47.631+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:29:47.630+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:29:48.743+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:29:48.737+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:29:48.744+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:29:48.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.153 seconds
[2024-09-06T09:30:18.882+0000] {processor.py:161} INFO - Started process (PID=590) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:30:18.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:30:18.886+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:30:18.885+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:30:19.880+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:30:19.874+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:30:19.881+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:30:19.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.041 seconds
[2024-09-06T09:30:50.104+0000] {processor.py:161} INFO - Started process (PID=608) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:30:50.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:30:50.108+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:30:50.107+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:30:51.052+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:30:51.044+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:30:51.053+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:30:51.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.980 seconds
[2024-09-06T09:31:21.510+0000] {processor.py:161} INFO - Started process (PID=626) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:31:21.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:31:21.516+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:31:21.515+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:31:22.406+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:31:22.398+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:31:22.408+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:31:22.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.940 seconds
[2024-09-06T09:31:52.923+0000] {processor.py:161} INFO - Started process (PID=644) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:31:52.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:31:52.927+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:31:52.927+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:31:53.762+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:31:53.755+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:31:53.763+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:31:53.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.882 seconds
[2024-09-06T09:32:24.058+0000] {processor.py:161} INFO - Started process (PID=662) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:32:24.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:32:24.062+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:32:24.061+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:32:25.075+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:32:25.070+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:32:25.076+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:32:25.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.055 seconds
[2024-09-06T09:32:55.587+0000] {processor.py:161} INFO - Started process (PID=680) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:32:55.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:32:55.593+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:32:55.592+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:32:56.521+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:32:56.514+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:32:56.523+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:32:56.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.992 seconds
[2024-09-06T09:33:26.780+0000] {processor.py:161} INFO - Started process (PID=698) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:33:26.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:33:26.785+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:33:26.785+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:33:28.041+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:33:28.035+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:33:28.042+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:33:28.067+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.297 seconds
[2024-09-06T09:33:58.581+0000] {processor.py:161} INFO - Started process (PID=717) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:33:58.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:33:58.593+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:33:58.592+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:34:00.217+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:34:00.209+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:34:00.218+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:34:00.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.702 seconds
[2024-09-06T09:34:30.432+0000] {processor.py:161} INFO - Started process (PID=735) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:34:30.433+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:34:30.436+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:34:30.435+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:34:31.899+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:34:31.888+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:34:31.903+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:34:31.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.515 seconds
[2024-09-06T09:35:02.415+0000] {processor.py:161} INFO - Started process (PID=753) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:35:02.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:35:02.419+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:35:02.419+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:35:03.470+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:35:03.462+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:35:03.474+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:35:03.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.125 seconds
[2024-09-06T09:35:34.452+0000] {processor.py:161} INFO - Started process (PID=771) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:35:34.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:35:34.457+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:35:34.456+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:35:35.473+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:35:35.466+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:35:35.475+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:35:35.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.056 seconds
[2024-09-06T09:36:06.488+0000] {processor.py:161} INFO - Started process (PID=795) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:36:06.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:36:06.496+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:36:06.495+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:36:07.496+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:36:07.489+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:36:07.498+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:36:07.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.075 seconds
[2024-09-06T09:36:38.083+0000] {processor.py:161} INFO - Started process (PID=813) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:36:38.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:36:38.087+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:36:38.087+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:36:39.411+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:36:39.369+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:36:39.415+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:36:39.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.374 seconds
[2024-09-06T09:37:09.575+0000] {processor.py:161} INFO - Started process (PID=831) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:37:09.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:37:09.579+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:37:09.579+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:37:11.666+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:37:11.574+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:37:11.680+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:37:11.891+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.324 seconds
[2024-09-06T09:37:42.623+0000] {processor.py:161} INFO - Started process (PID=848) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:37:42.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:37:42.630+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:37:42.629+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:37:44.940+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:37:44.931+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:37:44.945+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:37:44.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.405 seconds
[2024-09-06T09:38:15.541+0000] {processor.py:161} INFO - Started process (PID=866) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:38:15.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:38:15.546+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:38:15.546+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:38:17.301+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:38:17.294+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:38:17.303+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:38:17.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.809 seconds
[2024-09-06T09:38:48.035+0000] {processor.py:161} INFO - Started process (PID=884) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:38:48.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:38:48.041+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:38:48.040+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:38:49.098+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:38:49.089+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:38:49.100+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:38:49.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.127 seconds
[2024-09-06T09:39:19.440+0000] {processor.py:161} INFO - Started process (PID=902) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:39:19.442+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:39:19.445+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:39:19.445+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:39:20.464+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:39:20.456+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:39:20.467+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:39:20.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.076 seconds
[2024-09-06T09:39:51.369+0000] {processor.py:161} INFO - Started process (PID=921) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:39:51.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:39:51.387+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:39:51.386+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:39:52.699+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:39:52.690+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:39:52.701+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:39:52.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.392 seconds
[2024-09-06T09:40:23.944+0000] {processor.py:161} INFO - Started process (PID=939) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:40:23.950+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:40:23.974+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:40:23.973+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:40:25.793+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:40:25.785+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:40:25.795+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:40:25.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.910 seconds
[2024-09-06T09:40:56.227+0000] {processor.py:161} INFO - Started process (PID=957) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:40:56.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:40:56.253+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:40:56.252+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:40:58.559+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:40:58.553+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:40:58.561+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:40:58.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.408 seconds
[2024-09-06T09:41:29.211+0000] {processor.py:161} INFO - Started process (PID=975) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:41:29.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:41:29.232+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:41:29.232+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:41:31.765+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:41:31.656+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:41:31.772+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:41:31.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.695 seconds
[2024-09-06T09:42:02.057+0000] {processor.py:161} INFO - Started process (PID=992) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:42:02.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:42:02.062+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:42:02.062+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:42:03.721+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:42:03.713+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:42:03.723+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:42:03.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.720 seconds
[2024-09-06T09:42:37.936+0000] {processor.py:161} INFO - Started process (PID=1007) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:42:37.938+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:42:37.951+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:42:37.942+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:42:41.740+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:42:41.730+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:42:41.742+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:42:41.794+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.880 seconds
[2024-09-06T09:43:12.372+0000] {processor.py:161} INFO - Started process (PID=1026) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:43:12.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:43:12.378+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:43:12.378+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:43:13.792+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:43:13.780+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:43:13.793+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:43:13.833+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.473 seconds
[2024-09-06T09:43:44.027+0000] {processor.py:161} INFO - Started process (PID=1050) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:43:44.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:43:44.031+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:43:44.031+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:43:45.458+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:43:45.452+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:43:45.460+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:43:45.502+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.484 seconds
[2024-09-06T09:44:15.827+0000] {processor.py:161} INFO - Started process (PID=1068) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:44:15.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:44:15.834+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:44:15.833+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:44:17.052+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:44:17.008+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:44:17.055+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:44:17.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.306 seconds
[2024-09-06T09:44:47.369+0000] {processor.py:161} INFO - Started process (PID=1086) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:44:47.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:44:47.384+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:44:47.383+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:44:49.364+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:44:49.359+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:44:49.365+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:44:49.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.040 seconds
[2024-09-06T09:45:19.471+0000] {processor.py:161} INFO - Started process (PID=1104) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:45:19.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:45:19.477+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:45:19.476+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:45:21.199+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:45:21.187+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:45:21.208+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:45:21.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.786 seconds
[2024-09-06T09:45:51.921+0000] {processor.py:161} INFO - Started process (PID=1124) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:45:51.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:45:51.928+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:45:51.927+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:45:53.128+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:45:53.122+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:45:53.129+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:45:53.159+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.254 seconds
[2024-09-06T09:46:23.434+0000] {processor.py:161} INFO - Started process (PID=1142) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:46:23.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:46:23.443+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:46:23.442+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:46:24.616+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:46:24.611+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:46:24.618+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:46:24.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.223 seconds
[2024-09-06T09:46:55.081+0000] {processor.py:161} INFO - Started process (PID=1160) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:46:55.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:46:55.085+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:46:55.085+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:46:56.294+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:46:56.288+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:46:56.296+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:46:56.326+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.257 seconds
[2024-09-06T09:47:26.472+0000] {processor.py:161} INFO - Started process (PID=1179) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:47:26.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:47:26.486+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:47:26.485+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:47:27.905+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:47:27.899+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:47:27.906+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:47:27.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.470 seconds
[2024-09-06T09:47:58.073+0000] {processor.py:161} INFO - Started process (PID=1197) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:47:58.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:47:58.087+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:47:58.086+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:47:59.161+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:47:59.155+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:47:59.163+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:47:59.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.159 seconds
[2024-09-06T09:48:29.708+0000] {processor.py:161} INFO - Started process (PID=1215) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:48:29.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:48:29.712+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:48:29.712+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:48:30.767+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:48:30.761+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:48:30.768+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:48:30.801+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.103 seconds
[2024-09-06T09:49:01.194+0000] {processor.py:161} INFO - Started process (PID=1233) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:49:01.195+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:49:01.199+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:49:01.198+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:49:02.682+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:49:02.676+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:49:02.684+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:49:02.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.536 seconds
[2024-09-06T09:49:33.261+0000] {processor.py:161} INFO - Started process (PID=1251) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:49:33.263+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:49:33.267+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:49:33.266+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:49:34.460+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:49:34.455+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:49:34.462+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:49:34.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.242 seconds
[2024-09-06T09:50:04.813+0000] {processor.py:161} INFO - Started process (PID=1270) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:50:04.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:50:04.817+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:50:04.817+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:50:05.916+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:50:05.910+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:50:05.919+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:50:05.957+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.152 seconds
[2024-09-06T09:50:36.313+0000] {processor.py:161} INFO - Started process (PID=1288) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:50:36.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:50:36.318+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:50:36.317+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:50:37.769+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:50:37.761+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:50:37.770+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:50:37.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.515 seconds
[2024-09-06T09:51:08.278+0000] {processor.py:161} INFO - Started process (PID=1306) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:51:08.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:51:08.284+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:51:08.284+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:51:09.585+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:51:09.544+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:51:09.587+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:51:09.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.364 seconds
[2024-09-06T09:51:40.025+0000] {processor.py:161} INFO - Started process (PID=1324) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:51:40.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:51:40.033+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:51:40.032+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:51:41.282+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:51:41.275+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:51:41.283+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:51:41.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.305 seconds
[2024-09-06T09:52:11.438+0000] {processor.py:161} INFO - Started process (PID=1342) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:52:11.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:52:11.444+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:52:11.443+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:52:12.612+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:52:12.607+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:52:12.614+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:52:12.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.219 seconds
[2024-09-06T09:52:43.159+0000] {processor.py:161} INFO - Started process (PID=1360) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:52:43.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:52:43.163+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:52:43.163+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:52:44.256+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:52:44.250+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:52:44.258+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:52:44.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.131 seconds
[2024-09-06T09:53:14.668+0000] {processor.py:161} INFO - Started process (PID=1377) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:53:14.670+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:53:14.675+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:53:14.674+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:53:16.060+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:53:16.054+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:53:16.062+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:53:16.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.435 seconds
[2024-09-06T09:53:46.195+0000] {processor.py:161} INFO - Started process (PID=1401) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:53:46.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:53:46.200+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:53:46.199+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:53:47.495+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:53:47.484+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:53:47.496+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:53:47.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.357 seconds
[2024-09-06T09:54:17.950+0000] {processor.py:161} INFO - Started process (PID=1419) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:54:17.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:54:17.954+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:54:17.954+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:54:19.046+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:54:19.039+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:54:19.048+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:54:19.078+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.136 seconds
[2024-09-06T09:54:49.473+0000] {processor.py:161} INFO - Started process (PID=1437) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:54:49.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:54:49.479+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:54:49.478+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:54:50.696+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:54:50.690+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:54:50.697+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:54:50.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.268 seconds
[2024-09-06T09:55:21.290+0000] {processor.py:161} INFO - Started process (PID=1455) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:55:21.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:55:21.299+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:55:21.298+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:55:22.853+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:55:22.822+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:55:22.858+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:55:22.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.647 seconds
[2024-09-06T09:55:53.176+0000] {processor.py:161} INFO - Started process (PID=1472) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:55:53.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:55:53.181+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:55:53.180+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:55:54.428+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:55:54.419+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:55:54.430+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:55:54.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.309 seconds
[2024-09-06T09:56:24.900+0000] {processor.py:161} INFO - Started process (PID=1490) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:56:24.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:56:24.905+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:56:24.904+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:56:25.968+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:56:25.957+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:56:25.974+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:56:26.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.139 seconds
[2024-09-06T09:56:56.506+0000] {processor.py:161} INFO - Started process (PID=1508) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:56:56.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:56:56.516+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:56:56.515+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:56:58.280+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:56:58.273+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:56:58.281+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:56:58.313+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.817 seconds
[2024-09-06T09:57:28.600+0000] {processor.py:161} INFO - Started process (PID=1526) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:57:28.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:57:28.605+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:57:28.604+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:57:29.812+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:57:29.803+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:57:29.813+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:57:29.852+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.260 seconds
[2024-09-06T09:58:00.062+0000] {processor.py:161} INFO - Started process (PID=1544) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:58:00.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:58:00.067+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:58:00.066+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:58:01.322+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:58:01.314+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:58:01.324+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:58:01.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.300 seconds
[2024-09-06T09:58:31.596+0000] {processor.py:161} INFO - Started process (PID=1562) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:58:31.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:58:31.610+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:58:31.609+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:58:32.796+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:58:32.788+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:58:32.797+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:58:32.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.255 seconds
[2024-09-06T09:59:02.951+0000] {processor.py:161} INFO - Started process (PID=1580) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:59:02.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:59:02.955+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:59:02.955+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:59:04.044+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:59:04.036+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:59:04.045+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:59:04.067+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.129 seconds
[2024-09-06T09:59:34.467+0000] {processor.py:161} INFO - Started process (PID=1597) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:59:34.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T09:59:34.473+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:59:34.472+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:59:35.713+0000] {logging_mixin.py:188} INFO - [2024-09-06T09:59:35.708+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T09:59:35.714+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T09:59:35.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.285 seconds
[2024-09-06T10:00:05.909+0000] {processor.py:161} INFO - Started process (PID=1615) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:00:05.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:00:05.914+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:00:05.913+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:00:07.021+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:00:07.009+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:00:07.024+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:00:07.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.166 seconds
[2024-09-06T10:00:37.415+0000] {processor.py:161} INFO - Started process (PID=1633) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:00:37.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:00:37.419+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:00:37.419+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:00:38.833+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:00:38.827+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:00:38.834+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:00:38.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.464 seconds
[2024-09-06T10:01:09.702+0000] {processor.py:161} INFO - Started process (PID=1651) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:01:09.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:01:09.706+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:01:09.706+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:01:10.707+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:01:10.699+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:01:10.709+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:01:10.770+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.078 seconds
[2024-09-06T10:01:41.425+0000] {processor.py:161} INFO - Started process (PID=1668) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:01:41.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:01:41.429+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:01:41.429+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:01:42.569+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:01:42.563+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:01:42.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:01:42.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.183 seconds
[2024-09-06T10:02:12.991+0000] {processor.py:161} INFO - Started process (PID=1687) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:02:12.993+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:02:12.995+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:02:12.995+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:02:13.834+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:02:13.827+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:02:13.836+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:02:13.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.885 seconds
[2024-09-06T10:02:44.555+0000] {processor.py:161} INFO - Started process (PID=1705) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:02:44.556+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:02:44.559+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:02:44.559+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:02:45.716+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:02:45.710+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:02:45.718+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:02:45.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.211 seconds
[2024-09-06T10:03:16.258+0000] {processor.py:161} INFO - Started process (PID=1723) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:03:16.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:03:16.265+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:03:16.264+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:03:18.428+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:03:18.412+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:03:18.437+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:03:18.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.262 seconds
[2024-09-06T10:03:48.756+0000] {processor.py:161} INFO - Started process (PID=1747) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:03:48.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:03:48.764+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:03:48.763+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:03:49.731+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:03:49.724+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:03:49.733+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:03:49.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.030 seconds
[2024-09-06T10:04:20.098+0000] {processor.py:161} INFO - Started process (PID=1765) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:04:20.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:04:20.104+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:04:20.103+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:04:22.089+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:04:22.080+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:04:22.091+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:04:22.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.048 seconds
[2024-09-06T10:04:52.372+0000] {processor.py:161} INFO - Started process (PID=1783) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:04:52.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:04:52.390+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:04:52.389+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:04:54.134+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:04:54.126+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:04:54.136+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:04:54.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.817 seconds
[2024-09-06T10:05:24.761+0000] {processor.py:161} INFO - Started process (PID=1802) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:05:24.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:05:24.766+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:05:24.766+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:05:25.623+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:05:25.615+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:05:25.625+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:05:25.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.904 seconds
[2024-09-06T10:05:55.989+0000] {processor.py:161} INFO - Started process (PID=1820) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:05:55.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:05:55.998+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:05:55.998+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:05:57.161+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:05:57.153+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:05:57.164+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:05:57.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.224 seconds
[2024-09-06T10:06:28.132+0000] {processor.py:161} INFO - Started process (PID=1838) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:06:28.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:06:28.141+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:06:28.140+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:06:30.619+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:06:30.597+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:06:30.632+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:06:30.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.625 seconds
[2024-09-06T10:07:01.306+0000] {processor.py:161} INFO - Started process (PID=1856) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:07:01.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:07:01.310+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:07:01.310+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:07:02.375+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:07:02.366+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:07:02.376+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:07:02.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.111 seconds
[2024-09-06T10:07:32.773+0000] {processor.py:161} INFO - Started process (PID=1874) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:07:32.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:07:32.777+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:07:32.777+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:07:33.961+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:07:33.954+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:07:33.963+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:07:33.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.228 seconds
[2024-09-06T10:08:04.159+0000] {processor.py:161} INFO - Started process (PID=1892) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:08:04.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:08:04.169+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:08:04.168+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:08:05.192+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:08:05.185+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:08:05.195+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:08:05.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.089 seconds
[2024-09-06T10:08:35.500+0000] {processor.py:161} INFO - Started process (PID=1910) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:08:35.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:08:35.505+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:08:35.504+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:08:36.634+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:08:36.628+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:08:36.635+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:08:36.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.168 seconds
[2024-09-06T10:09:06.975+0000] {processor.py:161} INFO - Started process (PID=1928) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:09:06.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:09:06.979+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:09:06.979+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:09:07.937+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:09:07.928+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:09:07.949+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:09:07.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.023 seconds
[2024-09-06T10:09:38.227+0000] {processor.py:161} INFO - Started process (PID=1947) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:09:38.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:09:38.233+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:09:38.232+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:09:39.224+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:09:39.219+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:09:39.225+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:09:39.258+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.039 seconds
[2024-09-06T10:10:09.837+0000] {processor.py:161} INFO - Started process (PID=1966) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:10:09.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:10:09.842+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:10:09.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:10:10.710+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:10:10.701+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:10:10.711+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:10:10.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.908 seconds
[2024-09-06T10:10:41.195+0000] {processor.py:161} INFO - Started process (PID=1985) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:10:41.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:10:41.201+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:10:41.200+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:10:42.125+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:10:42.118+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:10:42.126+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:10:42.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.972 seconds
[2024-09-06T10:11:12.564+0000] {processor.py:161} INFO - Started process (PID=2003) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:11:12.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:11:12.569+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:11:12.569+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:11:14.274+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:11:14.269+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:11:14.276+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:11:14.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.757 seconds
[2024-09-06T10:11:44.574+0000] {processor.py:161} INFO - Started process (PID=2021) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:11:44.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:11:44.581+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:11:44.580+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:11:45.560+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:11:45.551+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:11:45.561+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:11:45.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.043 seconds
[2024-09-06T10:12:15.926+0000] {processor.py:161} INFO - Started process (PID=2039) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:12:15.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:12:15.931+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:12:15.930+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:12:17.144+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:12:17.137+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:12:17.146+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:12:17.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.266 seconds
[2024-09-06T10:12:47.273+0000] {processor.py:161} INFO - Started process (PID=2057) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:12:47.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:12:47.277+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:12:47.276+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:12:48.316+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:12:48.310+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:12:48.317+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:12:48.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.075 seconds
[2024-09-06T10:13:18.846+0000] {processor.py:161} INFO - Started process (PID=2084) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:13:18.848+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:13:18.852+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:13:18.851+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:13:19.780+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:13:19.773+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:13:19.781+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:13:19.814+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.974 seconds
[2024-09-06T10:13:50.127+0000] {processor.py:161} INFO - Started process (PID=2102) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:13:50.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:13:50.136+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:13:50.136+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:13:51.236+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:13:51.226+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:13:51.237+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:13:51.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.159 seconds
[2024-09-06T10:14:21.657+0000] {processor.py:161} INFO - Started process (PID=2120) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:14:21.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:14:21.663+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:14:21.662+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:14:22.507+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:14:22.500+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:14:22.509+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:14:22.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.896 seconds
[2024-09-06T10:14:52.812+0000] {processor.py:161} INFO - Started process (PID=2138) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:14:52.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:14:52.816+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:14:52.816+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:14:54.347+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:14:54.341+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:14:54.349+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:14:54.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.578 seconds
[2024-09-06T10:15:24.561+0000] {processor.py:161} INFO - Started process (PID=2156) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:15:24.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:15:24.565+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:15:24.565+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:15:25.470+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:15:25.459+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:15:25.471+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:15:25.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.962 seconds
[2024-09-06T10:15:55.988+0000] {processor.py:161} INFO - Started process (PID=2174) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:15:55.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:15:55.994+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:15:55.993+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:15:57.377+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:15:57.368+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:15:57.378+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:15:57.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.448 seconds
[2024-09-06T10:18:30.914+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:18:30.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:18:30.919+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:18:30.918+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:18:36.063+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:18:36.051+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:18:36.065+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:18:36.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.195 seconds
[2024-09-06T10:19:07.111+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:19:07.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:19:07.123+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:19:07.120+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:19:08.750+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:19:08.741+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:19:08.752+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:19:08.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.691 seconds
[2024-09-06T10:19:39.395+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:19:39.398+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:19:39.401+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:19:39.400+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:19:40.548+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:19:40.542+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:19:40.549+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:19:40.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.200 seconds
[2024-09-06T10:20:10.664+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:20:10.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:20:10.669+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:20:10.668+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:20:11.569+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:20:11.562+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:20:11.571+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:20:11.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.962 seconds
[2024-09-06T10:20:42.294+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:20:42.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:20:42.298+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:20:42.298+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:20:43.820+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:20:43.813+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:20:43.821+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:20:43.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.578 seconds
[2024-09-06T10:21:14.691+0000] {processor.py:161} INFO - Started process (PID=262) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:21:14.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:21:14.699+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:21:14.698+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:21:16.314+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:21:16.308+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:21:16.316+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:21:16.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.670 seconds
[2024-09-06T10:21:46.598+0000] {processor.py:161} INFO - Started process (PID=287) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:21:46.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:21:46.605+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:21:46.604+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:21:47.907+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:21:47.891+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:21:47.909+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:21:47.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.371 seconds
[2024-09-06T10:22:18.119+0000] {processor.py:161} INFO - Started process (PID=305) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:22:18.120+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:22:18.123+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:22:18.123+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:22:20.813+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:22:20.791+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflo/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:22:20.817+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:22:20.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.735 seconds
[2024-09-06T10:22:50.987+0000] {processor.py:161} INFO - Started process (PID=323) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:22:50.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:22:50.997+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:22:50.996+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:22:52.073+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:22:52.066+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:22:52.074+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:22:52.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.144 seconds
[2024-09-06T10:23:22.833+0000] {processor.py:161} INFO - Started process (PID=341) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:23:22.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:23:22.838+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:23:22.837+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:23:23.993+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:23:23.986+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:23:23.995+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:23:24.022+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.205 seconds
[2024-09-06T10:23:44.345+0000] {processor.py:161} INFO - Started process (PID=347) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:23:44.346+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:23:44.349+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:23:44.348+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:23:45.812+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:23:45.537+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/da/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/k/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T10:23:45.878+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:23:45.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.627 seconds
[2024-09-06T10:23:46.479+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:23:46.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:23:46.485+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:23:46.485+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:23:47.890+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:23:48.231+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:23:48.229+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T10:23:48.324+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:23:48.322+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-01 00:00:00+00:00, run_after=2024-09-02 00:00:00+00:00
[2024-09-06T10:23:48.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.006 seconds
[2024-09-06T10:24:19.028+0000] {processor.py:161} INFO - Started process (PID=394) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:24:19.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:24:19.034+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:24:19.033+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:24:20.497+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:24:20.536+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:24:20.535+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T10:24:20.570+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:24:20.570+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T10:24:20.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.595 seconds
[2024-09-06T10:26:27.471+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:26:27.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:26:27.486+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:26:27.485+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:26:33.218+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:26:33.547+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:26:33.546+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T10:26:33.604+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:26:33.604+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T10:26:33.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.217 seconds
[2024-09-06T10:27:03.820+0000] {processor.py:161} INFO - Started process (PID=192) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:27:03.821+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:27:03.825+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:27:03.825+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:27:05.065+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:27:05.118+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:27:05.117+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T10:27:05.160+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:27:05.160+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T10:27:05.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.404 seconds
[2024-09-06T10:27:35.444+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:27:35.446+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:27:35.450+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:27:35.449+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:27:36.669+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:27:36.746+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:27:36.745+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T10:27:36.809+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:27:36.807+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T10:27:36.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.430 seconds
[2024-09-06T10:28:07.008+0000] {processor.py:161} INFO - Started process (PID=228) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:28:07.009+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:28:07.012+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:28:07.011+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:28:09.921+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:28:10.046+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:28:10.045+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T10:28:10.162+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:28:10.161+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T10:28:10.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.262 seconds
[2024-09-06T10:28:40.705+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:28:40.706+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:28:40.709+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:28:40.709+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:28:41.923+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:28:41.983+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:28:41.982+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T10:28:42.064+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:28:42.063+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T10:28:42.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.415 seconds
[2024-09-06T10:29:12.752+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:29:12.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:29:12.756+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:29:12.756+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:29:13.791+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:29:13.827+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:29:13.826+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T10:29:13.859+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:29:13.859+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T10:29:13.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.156 seconds
[2024-09-06T10:32:43.129+0000] {processor.py:161} INFO - Started process (PID=173) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:32:43.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:32:43.227+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:32:43.226+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:32:59.224+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:32:59.839+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:32:59.838+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T10:32:59.990+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:32:59.989+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T10:33:00.166+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 17.093 seconds
[2024-09-06T10:36:09.462+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:36:09.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:36:09.478+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:36:09.477+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:36:14.918+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:36:15.257+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:36:15.256+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T10:36:15.291+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:36:15.290+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T10:36:15.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.889 seconds
[2024-09-06T10:36:45.797+0000] {processor.py:161} INFO - Started process (PID=190) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:36:45.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:36:45.802+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:36:45.802+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:36:47.468+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:36:47.507+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:36:47.506+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T10:36:47.545+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:36:47.544+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T10:36:47.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.798 seconds
[2024-09-06T10:37:18.002+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:37:18.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T10:37:18.032+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:37:18.032+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:37:20.043+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T10:37:20.105+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:37:20.104+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T10:37:20.180+0000] {logging_mixin.py:188} INFO - [2024-09-06T10:37:20.180+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T10:37:29.709+0000] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1094, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 686, in do_commit
    dbapi_connection.commit()
psycopg2.OperationalError: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 896, in save_dag_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 839, in commit
    trans.commit()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2469, in commit
    self._do_commit()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2659, in _do_commit
    self._connection_commit_impl()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2630, in _connection_commit_impl
    self.connection._commit_impl()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1096, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1094, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 686, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-09-06T12:20:45.150+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:20:45.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:20:45.167+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:20:45.157+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:20:51.995+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:20:52.291+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:20:52.290+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:20:52.320+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:20:52.319+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:20:52.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 7.220 seconds
[2024-09-06T12:21:22.719+0000] {processor.py:161} INFO - Started process (PID=191) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:21:22.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:21:22.722+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:21:22.722+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:21:23.845+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:21:23.877+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:21:23.877+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:21:23.909+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:21:23.909+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:21:23.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.235 seconds
[2024-09-06T12:32:54.493+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:32:54.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:32:54.500+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:32:54.499+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:33:01.987+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:33:02.336+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:33:02.335+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:33:02.405+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:33:02.404+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:33:02.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 7.993 seconds
[2024-09-06T12:33:33.068+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:33:33.092+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:33:33.105+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:33:33.104+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:33:39.517+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:33:39.701+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:33:39.699+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:33:39.789+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:33:39.788+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:33:39.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.891 seconds
[2024-09-06T12:34:10.604+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:34:10.605+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:34:10.608+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:34:10.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:34:11.980+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:34:12.014+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:34:12.013+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:34:12.047+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:34:12.047+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:34:12.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.500 seconds
[2024-09-06T12:34:42.386+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:34:42.387+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:34:42.391+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:34:42.390+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:34:44.385+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:34:44.425+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:34:44.424+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:34:44.462+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:34:44.461+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:34:44.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.145 seconds
[2024-09-06T12:35:14.841+0000] {processor.py:161} INFO - Started process (PID=252) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:35:14.845+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:35:14.850+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:35:14.848+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:35:16.020+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:35:16.058+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:35:16.057+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:35:16.096+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:35:16.096+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:35:16.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.312 seconds
[2024-09-06T12:35:46.590+0000] {processor.py:161} INFO - Started process (PID=270) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:35:46.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:35:46.594+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:35:46.594+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:35:47.630+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:35:47.663+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:35:47.663+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:35:47.693+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:35:47.692+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:35:47.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.155 seconds
[2024-09-06T12:36:17.960+0000] {processor.py:161} INFO - Started process (PID=288) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:36:17.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:36:17.964+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:36:17.964+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:36:18.937+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:36:18.970+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:36:18.969+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:36:19.003+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:36:19.002+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:36:19.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.091 seconds
[2024-09-06T12:36:49.205+0000] {processor.py:161} INFO - Started process (PID=306) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:36:49.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:36:49.210+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:36:49.209+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:36:50.239+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:36:50.274+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:36:50.274+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:36:50.302+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:36:50.302+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:36:50.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.140 seconds
[2024-09-06T12:37:20.719+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:37:20.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:37:20.724+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:37:20.724+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:37:21.732+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:37:21.819+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:37:21.812+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:37:21.886+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:37:21.885+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:37:21.970+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.259 seconds
[2024-09-06T12:37:52.485+0000] {processor.py:161} INFO - Started process (PID=343) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:37:52.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:37:52.490+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:37:52.489+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:37:53.514+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:37:53.550+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:37:53.550+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:37:53.580+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:37:53.580+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:37:53.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.145 seconds
[2024-09-06T12:38:24.289+0000] {processor.py:161} INFO - Started process (PID=362) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:38:24.292+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:38:24.295+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:38:24.294+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:38:25.622+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:38:25.655+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:38:25.654+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:38:25.687+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:38:25.686+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:38:25.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.453 seconds
[2024-09-06T12:38:56.208+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:38:56.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:38:56.212+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:38:56.212+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:39:30.526+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:39:30.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:39:30.533+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:39:30.532+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:39:33.247+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:39:33.230+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:39:33.249+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:39:33.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.780 seconds
[2024-09-06T12:40:03.854+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:40:03.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:40:03.862+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:40:03.861+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:40:05.155+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:40:05.148+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:40:05.157+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:40:05.189+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.350 seconds
[2024-09-06T12:40:20.485+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:40:20.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:40:20.492+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:40:20.491+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:40:22.986+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:40:22.980+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:40:22.989+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:40:23.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.544 seconds
[2024-09-06T12:41:08.648+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:41:08.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:41:08.655+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:41:08.654+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:41:11.382+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:41:11.375+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:41:11.383+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:41:11.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.795 seconds
[2024-09-06T12:41:42.501+0000] {processor.py:161} INFO - Started process (PID=192) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:41:42.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:41:42.506+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:41:42.505+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:41:43.915+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:41:43.909+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:41:43.916+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:41:43.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.457 seconds
[2024-09-06T12:41:53.779+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:41:53.781+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:41:53.785+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:41:53.785+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:41:55.182+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:41:55.170+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/k/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:41:55.184+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:41:55.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.506 seconds
[2024-09-06T12:42:58.973+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:42:58.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:42:58.979+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:42:58.978+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:43:01.034+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:43:01.027+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:43:01.037+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:43:01.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.125 seconds
[2024-09-06T12:43:31.212+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:43:31.217+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:43:31.221+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:43:31.220+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:43:33.354+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:43:33.345+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:43:33.355+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:43:33.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.191 seconds
[2024-09-06T12:44:02.746+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:44:02.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:44:02.765+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:44:02.765+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:44:05.383+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:44:05.345+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow//my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:44:05.385+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:44:05.423+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.701 seconds
[2024-09-06T12:44:43.653+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:44:43.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:44:43.660+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:44:43.659+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:44:46.208+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:44:46.197+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:44:46.210+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:44:46.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.633 seconds
[2024-09-06T12:45:17.053+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:45:17.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:45:17.058+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:45:17.058+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:45:18.037+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:45:18.029+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:45:18.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:45:18.070+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.031 seconds
[2024-09-06T12:45:26.285+0000] {processor.py:161} INFO - Started process (PID=196) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:45:26.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:45:26.291+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:45:26.290+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:45:28.158+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:45:28.145+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow//my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:45:28.160+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:45:28.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.923 seconds
[2024-09-06T12:45:34.449+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:45:34.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:45:34.465+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:45:34.459+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:45:36.525+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:45:36.509+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/keymy-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:45:36.527+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:45:36.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.166 seconds
[2024-09-06T12:46:32.173+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:46:32.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:46:32.181+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:46:32.178+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:46:34.330+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:46:34.322+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:46:34.331+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:46:34.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.212 seconds
[2024-09-06T12:47:04.907+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:47:05.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:47:05.047+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:47:05.046+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:47:06.269+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:47:06.261+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:47:06.271+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:47:06.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.461 seconds
[2024-09-06T12:47:36.661+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:47:36.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:47:36.667+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:47:36.667+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:47:37.480+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:47:37.475+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:47:37.482+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:47:37.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.857 seconds
[2024-09-06T12:47:38.574+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:47:38.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:47:38.578+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:47:38.577+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:47:39.891+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:47:39.879+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/kemy-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:47:39.892+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:47:39.940+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.373 seconds
[2024-09-06T12:48:15.663+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:48:15.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:48:15.668+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:48:15.667+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:48:18.103+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:48:18.096+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:48:18.106+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:48:18.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.503 seconds
[2024-09-06T12:48:48.297+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:48:48.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:48:48.301+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:48:48.301+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:48:49.202+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:48:49.197+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:48:49.203+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:48:49.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.938 seconds
[2024-09-06T12:49:19.533+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:49:19.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:49:19.544+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:49:19.543+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:49:20.519+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:49:20.513+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:49:20.521+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:49:20.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.027 seconds
[2024-09-06T12:50:41.613+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:50:41.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:50:41.633+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:50:41.632+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:50:43.917+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:50:43.908+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:50:43.920+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:50:43.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.380 seconds
[2024-09-06T12:51:14.679+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:51:14.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:51:14.695+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:51:14.694+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:51:16.873+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:51:16.863+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:51:16.875+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:51:16.917+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.271 seconds
[2024-09-06T12:51:47.679+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:51:47.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:51:47.687+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:51:47.686+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:52:42.468+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:52:42.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:52:42.478+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:52:42.478+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:52:45.237+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:52:45.607+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:52:45.604+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:52:45.823+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:52:45.823+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:52:46.013+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.559 seconds
[2024-09-06T12:53:16.284+0000] {processor.py:161} INFO - Started process (PID=192) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:53:16.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:53:16.288+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:53:16.288+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:53:17.474+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:53:17.506+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:53:17.505+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:53:17.548+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:53:17.548+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:53:17.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.304 seconds
[2024-09-06T12:53:48.137+0000] {processor.py:161} INFO - Started process (PID=211) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:53:48.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:53:48.143+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:53:48.142+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:53:49.215+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:53:49.256+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:53:49.256+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:53:49.288+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:53:49.288+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:53:49.319+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.196 seconds
[2024-09-06T12:55:30.814+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:55:30.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:55:30.830+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:55:30.830+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:55:33.194+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:55:33.572+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:55:33.571+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:55:33.694+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:55:33.691+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:55:33.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.092 seconds
[2024-09-06T12:56:04.575+0000] {processor.py:161} INFO - Started process (PID=191) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:56:04.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:56:04.583+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:56:04.581+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:56:06.187+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:56:06.238+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:56:06.237+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T12:56:06.280+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:56:06.279+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T12:56:06.319+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.757 seconds
[2024-09-06T12:56:14.912+0000] {processor.py:161} INFO - Started process (PID=199) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:56:14.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:56:14.917+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:56:14.916+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:56:16.792+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:56:16.786+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:56:16.800+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:56:16.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.924 seconds
[2024-09-06T12:57:00.488+0000] {processor.py:161} INFO - Started process (PID=162) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:57:00.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:57:00.497+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:57:00.495+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:57:02.488+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:57:02.481+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:57:02.489+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:57:02.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.055 seconds
[2024-09-06T12:57:33.400+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:57:33.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:57:33.431+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:57:33.430+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:57:35.980+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:57:35.972+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:57:35.981+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:57:36.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.649 seconds
[2024-09-06T12:58:06.503+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:58:06.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:58:06.507+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:58:06.507+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:58:08.618+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:58:08.531+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("/omy-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/datamy-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:58:08.621+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:58:08.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.163 seconds
[2024-09-06T12:58:09.699+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:58:09.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:58:09.723+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:58:09.722+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:58:13.378+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:58:13.370+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:58:13.379+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:58:13.452+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.774 seconds
[2024-09-06T12:59:01.165+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:59:01.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:59:01.175+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:59:01.174+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:59:03.959+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:59:03.947+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:59:03.962+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:59:04.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.860 seconds
[2024-09-06T12:59:34.587+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:59:34.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T12:59:34.614+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:59:34.613+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:59:36.978+0000] {logging_mixin.py:188} INFO - [2024-09-06T12:59:36.963+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T12:59:36.980+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T12:59:37.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.479 seconds
[2024-09-06T13:00:07.905+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:00:07.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:00:07.911+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:00:07.910+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:00:09.090+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:00:09.080+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:00:09.092+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:00:09.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.230 seconds
[2024-09-06T13:00:44.866+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:00:44.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:00:44.873+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:00:44.872+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:00:46.332+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:00:46.315+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:00:46.334+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:00:46.392+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.539 seconds
[2024-09-06T13:01:17.058+0000] {processor.py:161} INFO - Started process (PID=183) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:01:17.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:01:17.068+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:01:17.067+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:01:18.401+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:01:18.395+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:01:18.402+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:01:18.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.380 seconds
[2024-09-06T13:01:49.105+0000] {processor.py:161} INFO - Started process (PID=206) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:01:49.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:01:49.112+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:01:49.112+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:01:50.711+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:01:50.703+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:01:50.717+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:01:50.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.678 seconds
[2024-09-06T13:02:20.994+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:02:20.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:02:21.003+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:02:21.002+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:02:22.539+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:02:22.532+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:02:22.542+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:02:22.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.605 seconds
[2024-09-06T13:03:17.257+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:03:17.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:03:17.264+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:03:17.263+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:03:18.517+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:03:18.510+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:03:18.519+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:03:18.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.324 seconds
[2024-09-06T13:03:49.315+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:03:49.318+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:03:49.321+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:03:49.321+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:03:52.088+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:03:52.077+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:03:52.090+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:03:52.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.851 seconds
[2024-09-06T13:03:55.040+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:03:55.041+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:03:55.046+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:03:55.045+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:03:57.835+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:03:57.808+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("opt/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'opmy-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:03:57.836+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:03:57.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.845 seconds
[2024-09-06T13:04:05.808+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:04:05.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:04:05.816+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:04:05.815+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:04:08.893+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:04:08.870+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("opt/airflow/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'opt/amy-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:04:08.894+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:04:08.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.141 seconds
[2024-09-06T13:04:10.014+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:04:10.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:04:10.018+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:04:10.018+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:04:12.306+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:04:12.279+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'opt/airflow/datamy-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:04:12.309+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:04:12.369+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.367 seconds
[2024-09-06T13:04:49.797+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:04:49.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:04:49.808+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:04:49.807+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:04:51.355+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:04:51.349+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:04:51.357+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:04:51.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.617 seconds
[2024-09-06T13:05:21.700+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:05:21.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:05:21.707+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:05:21.706+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:05:23.095+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:05:23.084+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'opt/airflow/data/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:05:23.100+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:05:23.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.460 seconds
[2024-09-06T13:05:32.585+0000] {processor.py:161} INFO - Started process (PID=196) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:05:32.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:05:32.602+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:05:32.601+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:05:35.832+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:05:35.800+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'opt/airflow/data/keymy-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:05:35.834+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:05:35.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.308 seconds
[2024-09-06T13:06:10.315+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:06:10.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:06:10.320+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:06:10.320+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:06:11.685+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:06:11.678+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:06:11.687+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:06:11.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.419 seconds
[2024-09-06T13:06:42.100+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:06:42.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:06:42.117+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:06:42.115+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:06:43.419+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:06:43.410+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 34, in <module>
    credentials = service_account.Credentials.from_service_account_file("opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'opt/airflow/data/key/my-etl-project-434409-3e70c40f6d3a.json'
[2024-09-06T13:06:43.420+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:06:43.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.392 seconds
[2024-09-06T13:07:14.008+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:07:14.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:07:14.024+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:07:14.023+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:07:16.684+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:07:17.061+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:07:17.055+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:07:17.127+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:07:17.126+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:07:17.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.213 seconds
[2024-09-06T13:07:50.179+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:07:50.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:07:50.184+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:07:50.183+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:07:51.854+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:07:51.918+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:07:51.917+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:07:51.951+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:07:51.951+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:07:51.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.829 seconds
[2024-09-06T13:08:22.216+0000] {processor.py:161} INFO - Started process (PID=190) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:08:22.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:08:22.223+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:08:22.222+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:08:23.787+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:08:23.820+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:08:23.819+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:08:23.852+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:08:23.851+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:08:23.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.688 seconds
[2024-09-06T13:08:54.509+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:08:54.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:08:54.515+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:08:54.514+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:08:55.963+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:08:56.002+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:08:56.001+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:08:56.031+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:08:56.031+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:08:56.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.568 seconds
[2024-09-06T13:09:26.325+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:09:26.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:09:26.333+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:09:26.332+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:09:27.993+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:09:28.061+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:09:28.060+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:09:28.122+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:09:28.121+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:09:28.181+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.876 seconds
[2024-09-06T13:09:58.716+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:09:58.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:09:58.720+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:09:58.720+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:10:00.181+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:10:00.222+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:10:00.221+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:10:00.258+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:10:00.258+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:10:00.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.592 seconds
[2024-09-06T13:10:30.676+0000] {processor.py:161} INFO - Started process (PID=263) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:10:30.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:10:30.682+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:10:30.681+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:10:31.764+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:10:31.800+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:10:31.799+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:10:31.834+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:10:31.834+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:10:31.870+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.207 seconds
[2024-09-06T13:11:02.209+0000] {processor.py:161} INFO - Started process (PID=283) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:11:02.212+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:11:02.217+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:11:02.216+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:11:03.639+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:11:03.703+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:11:03.702+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:11:03.745+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:11:03.745+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:11:03.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.599 seconds
[2024-09-06T13:11:33.968+0000] {processor.py:161} INFO - Started process (PID=301) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:11:33.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:11:33.972+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:11:33.972+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:11:35.376+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:11:35.422+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:11:35.421+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:11:35.459+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:11:35.458+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:11:35.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.552 seconds
[2024-09-06T13:12:05.690+0000] {processor.py:161} INFO - Started process (PID=319) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:12:05.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:12:05.700+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:12:05.699+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:12:07.057+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:12:07.105+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:12:07.104+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:12:07.147+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:12:07.147+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:12:07.195+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.525 seconds
[2024-09-06T13:12:37.525+0000] {processor.py:161} INFO - Started process (PID=337) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:12:37.531+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:12:37.539+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:12:37.538+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:12:39.649+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:12:39.715+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:12:39.713+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:12:39.777+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:12:39.776+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:12:39.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.339 seconds
[2024-09-06T13:13:10.591+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:13:10.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:13:10.601+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:13:10.600+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:13:12.698+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:13:12.747+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:13:12.746+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:13:12.782+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:13:12.782+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:13:12.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.297 seconds
[2024-09-06T13:13:43.078+0000] {processor.py:161} INFO - Started process (PID=373) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:13:43.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:13:43.084+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:13:43.083+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:13:46.231+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:13:46.329+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:13:46.327+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:13:46.518+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:13:46.518+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:13:46.609+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.544 seconds
[2024-09-06T13:14:16.982+0000] {processor.py:161} INFO - Started process (PID=390) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:14:16.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:14:16.988+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:14:16.987+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:14:19.323+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:14:19.430+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:14:19.428+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:14:19.504+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:14:19.504+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:14:19.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.588 seconds
[2024-09-06T13:14:49.634+0000] {processor.py:161} INFO - Started process (PID=407) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:14:49.635+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:14:49.639+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:14:49.639+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:14:51.287+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:14:51.345+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:14:51.344+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:14:51.381+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:14:51.381+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:14:51.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.809 seconds
[2024-09-06T13:15:21.956+0000] {processor.py:161} INFO - Started process (PID=425) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:15:21.958+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:15:21.963+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:15:21.962+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:15:23.305+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:15:23.357+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:15:23.356+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:15:23.394+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:15:23.394+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:15:23.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.507 seconds
[2024-09-06T13:15:54.195+0000] {processor.py:161} INFO - Started process (PID=449) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:15:54.199+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:15:54.210+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:15:54.209+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:15:55.519+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:15:55.555+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:15:55.554+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:15:55.587+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:15:55.587+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:15:55.622+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.449 seconds
[2024-09-06T13:16:26.108+0000] {processor.py:161} INFO - Started process (PID=466) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:16:26.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:16:26.135+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:16:26.133+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:16:28.021+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:16:28.079+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:16:28.078+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:16:28.143+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:16:28.143+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:16:28.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.134 seconds
[2024-09-06T13:16:59.026+0000] {processor.py:161} INFO - Started process (PID=484) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:16:59.029+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:16:59.034+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:16:59.033+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:17:00.441+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:17:00.484+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:17:00.483+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:17:00.525+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:17:00.525+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:17:00.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.603 seconds
[2024-09-06T13:17:31.677+0000] {processor.py:161} INFO - Started process (PID=502) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:17:31.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:17:31.682+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:17:31.681+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:17:32.688+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:17:32.720+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:17:32.720+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:17:32.746+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:17:32.746+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:17:32.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.110 seconds
[2024-09-06T13:18:03.043+0000] {processor.py:161} INFO - Started process (PID=520) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:18:03.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:18:03.048+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:18:03.047+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:18:04.019+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:18:04.064+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:18:04.063+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:18:04.103+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:18:04.102+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:18:04.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.127 seconds
[2024-09-06T13:18:34.251+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:18:34.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:18:34.255+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:18:34.254+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:18:35.188+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:18:35.215+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:18:35.215+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:18:35.241+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:18:35.241+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:18:35.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.031 seconds
[2024-09-06T13:19:05.528+0000] {processor.py:161} INFO - Started process (PID=556) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:19:05.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:19:05.533+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:19:05.533+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:19:06.534+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:19:06.564+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:19:06.564+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:19:06.592+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:19:06.592+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:19:06.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.108 seconds
[2024-09-06T13:19:37.013+0000] {processor.py:161} INFO - Started process (PID=574) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:19:37.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:19:37.020+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:19:37.019+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:19:37.922+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:19:37.971+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:19:37.970+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:19:38.017+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:19:38.017+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:19:38.080+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.088 seconds
[2024-09-06T13:20:08.371+0000] {processor.py:161} INFO - Started process (PID=592) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:20:08.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:20:08.377+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:20:08.377+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:20:09.275+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:20:09.338+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:20:09.337+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:20:09.383+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:20:09.382+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:20:09.419+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.059 seconds
[2024-09-06T13:20:39.589+0000] {processor.py:161} INFO - Started process (PID=610) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:20:39.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:20:39.593+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:20:39.592+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:20:40.808+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:20:40.888+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:20:40.887+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:20:40.930+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:20:40.930+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:20:40.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.400 seconds
[2024-09-06T13:21:11.399+0000] {processor.py:161} INFO - Started process (PID=628) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:21:11.401+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:21:11.404+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:21:11.404+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:21:12.869+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:21:12.923+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:21:12.922+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:21:12.988+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:21:12.987+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:21:13.080+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.693 seconds
[2024-09-06T13:21:43.876+0000] {processor.py:161} INFO - Started process (PID=647) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:21:43.878+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:21:43.882+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:21:43.882+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:21:46.030+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:21:46.119+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:21:46.117+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:21:46.200+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:21:46.200+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:21:46.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.392 seconds
[2024-09-06T13:22:16.713+0000] {processor.py:161} INFO - Started process (PID=666) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:22:16.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:22:16.740+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:22:16.740+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:22:19.524+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:22:19.572+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:22:19.571+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:22:19.620+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:22:19.619+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:22:19.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.059 seconds
[2024-09-06T13:22:50.151+0000] {processor.py:161} INFO - Started process (PID=684) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:22:50.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:22:50.176+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:22:50.175+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:22:52.163+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:22:52.217+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:22:52.216+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:22:52.250+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:22:52.249+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:22:52.283+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.144 seconds
[2024-09-06T13:23:22.953+0000] {processor.py:161} INFO - Started process (PID=702) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:23:22.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:23:23.036+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:23:23.035+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:23:36.676+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:23:36.790+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:23:36.789+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:23:36.855+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:23:36.855+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:23:36.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 13.982 seconds
[2024-09-06T13:24:07.660+0000] {processor.py:161} INFO - Started process (PID=725) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:24:07.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:24:07.666+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:24:07.665+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:24:08.959+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:24:09.014+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:24:09.014+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:24:09.079+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:24:09.079+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:24:09.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.466 seconds
[2024-09-06T13:24:39.600+0000] {processor.py:161} INFO - Started process (PID=744) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:24:39.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:24:39.605+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:24:39.605+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:24:40.714+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:24:40.760+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:24:40.759+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:24:40.813+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:24:40.812+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:24:40.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.289 seconds
[2024-09-06T13:25:11.162+0000] {processor.py:161} INFO - Started process (PID=762) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:25:11.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:25:11.173+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:25:11.172+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:25:12.614+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:25:12.688+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:25:12.686+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:25:12.749+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:25:12.749+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:25:12.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.658 seconds
[2024-09-06T13:25:43.560+0000] {processor.py:161} INFO - Started process (PID=780) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:25:43.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:25:43.570+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:25:43.569+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:25:45.107+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:25:45.180+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:25:45.179+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:25:45.223+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:25:45.222+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:25:45.270+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.724 seconds
[2024-09-06T13:26:16.272+0000] {processor.py:161} INFO - Started process (PID=797) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:26:16.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:26:16.278+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:26:16.277+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:26:17.623+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:26:17.668+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:26:17.666+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:26:17.725+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:26:17.725+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:26:17.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.531 seconds
[2024-09-06T13:26:48.044+0000] {processor.py:161} INFO - Started process (PID=815) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:26:48.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:26:48.052+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:26:48.051+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:26:49.486+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:26:49.528+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:26:49.527+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:26:49.556+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:26:49.556+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:26:49.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.561 seconds
[2024-09-06T13:27:19.984+0000] {processor.py:161} INFO - Started process (PID=833) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:27:19.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:27:19.988+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:27:19.988+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:27:21.208+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:27:21.302+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:27:21.301+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:27:21.404+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:27:21.403+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:27:21.463+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.496 seconds
[2024-09-06T13:27:51.637+0000] {processor.py:161} INFO - Started process (PID=851) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:27:51.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:27:51.644+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:27:51.643+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:27:53.210+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:27:53.337+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:27:53.336+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:27:53.433+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:27:53.433+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:27:53.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.845 seconds
[2024-09-06T13:28:24.107+0000] {processor.py:161} INFO - Started process (PID=869) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:28:24.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:28:24.112+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:28:24.112+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:28:25.492+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:28:25.551+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:28:25.550+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:28:25.626+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:28:25.625+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:28:25.674+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.583 seconds
[2024-09-06T13:28:56.365+0000] {processor.py:161} INFO - Started process (PID=887) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:28:56.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:28:56.375+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:28:56.374+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:28:57.871+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:28:57.924+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:28:57.923+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:28:57.956+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:28:57.955+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:28:58.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.662 seconds
[2024-09-06T13:29:28.684+0000] {processor.py:161} INFO - Started process (PID=911) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:29:28.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:29:28.699+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:29:28.698+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:29:29.980+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:29:30.026+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:29:30.026+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:29:30.099+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:29:30.099+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:29:30.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.493 seconds
[2024-09-06T13:30:00.654+0000] {processor.py:161} INFO - Started process (PID=929) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:30:00.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:30:00.703+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:30:00.702+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:30:02.231+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:30:02.277+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:30:02.276+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:30:02.328+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:30:02.327+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:30:02.377+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.756 seconds
[2024-09-06T13:30:33.377+0000] {processor.py:161} INFO - Started process (PID=947) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:30:33.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:30:33.394+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:30:33.393+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:30:35.276+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:30:35.361+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:30:35.360+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:30:35.400+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:30:35.399+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:30:35.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.184 seconds
[2024-09-06T13:31:06.203+0000] {processor.py:161} INFO - Started process (PID=965) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:31:06.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:31:06.210+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:31:06.209+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:31:07.954+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:31:07.993+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:31:07.993+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:31:08.027+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:31:08.026+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:31:08.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.889 seconds
[2024-09-06T13:31:38.324+0000] {processor.py:161} INFO - Started process (PID=983) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:31:38.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:31:38.334+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:31:38.333+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:31:39.736+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:31:39.804+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:31:39.802+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:31:39.871+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:31:39.871+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:31:39.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.624 seconds
[2024-09-06T13:32:10.925+0000] {processor.py:161} INFO - Started process (PID=1001) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:32:10.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:32:10.928+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:32:10.928+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:32:11.714+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:32:11.745+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:32:11.745+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:32:11.769+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:32:11.768+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:32:11.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.878 seconds
[2024-09-06T13:32:42.147+0000] {processor.py:161} INFO - Started process (PID=1019) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:32:42.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:32:42.158+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:32:42.158+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:32:43.176+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:32:43.254+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:32:43.251+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:32:43.329+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:32:43.329+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:32:43.398+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.259 seconds
[2024-09-06T13:33:13.671+0000] {processor.py:161} INFO - Started process (PID=1037) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:33:13.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:33:13.674+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:33:13.674+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:33:15.144+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:33:15.196+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:33:15.195+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:33:15.233+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:33:15.232+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:33:15.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.607 seconds
[2024-09-06T13:33:45.758+0000] {processor.py:161} INFO - Started process (PID=1055) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:33:45.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:33:45.762+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:33:45.761+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:33:47.095+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:33:47.123+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:33:47.122+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:33:47.147+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:33:47.146+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:33:47.171+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.424 seconds
[2024-09-06T13:34:17.536+0000] {processor.py:161} INFO - Started process (PID=1077) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:34:17.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:34:17.542+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:34:17.541+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:34:18.731+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:34:18.761+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:34:18.761+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:34:18.794+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:34:18.794+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:34:18.828+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.300 seconds
[2024-09-06T13:34:49.088+0000] {processor.py:161} INFO - Started process (PID=1095) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:34:49.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:34:49.093+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:34:49.092+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:34:50.016+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:34:50.047+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:34:50.047+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:34:50.089+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:34:50.088+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:34:50.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.050 seconds
[2024-09-06T13:35:20.417+0000] {processor.py:161} INFO - Started process (PID=1115) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:35:20.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:35:20.421+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:35:20.420+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:35:21.360+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:35:21.396+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:35:21.395+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:35:21.426+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:35:21.425+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:35:21.460+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.051 seconds
[2024-09-06T13:35:51.968+0000] {processor.py:161} INFO - Started process (PID=1133) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:35:51.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:35:51.971+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:35:51.971+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:35:52.760+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:35:52.785+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:35:52.784+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:35:52.809+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:35:52.809+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:35:52.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.888 seconds
[2024-09-06T13:36:23.957+0000] {processor.py:161} INFO - Started process (PID=1149) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:36:23.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:36:23.972+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:36:23.963+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:36:28.492+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:36:28.608+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:36:28.608+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:36:28.702+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:36:28.702+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:36:28.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.885 seconds
[2024-09-06T13:36:59.141+0000] {processor.py:161} INFO - Started process (PID=1175) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:36:59.143+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:36:59.145+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:36:59.145+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:37:00.899+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:37:00.957+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:37:00.956+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:37:01.042+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:37:01.033+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:37:01.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.977 seconds
[2024-09-06T13:37:31.408+0000] {processor.py:161} INFO - Started process (PID=1193) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:37:31.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:37:31.412+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:37:31.411+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:37:32.576+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:37:32.603+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:37:32.603+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:37:32.626+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:37:32.625+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:37:32.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.255 seconds
[2024-09-06T13:38:03.204+0000] {processor.py:161} INFO - Started process (PID=1211) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:38:03.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:38:03.233+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:38:03.232+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:38:05.027+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:38:05.087+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:38:05.086+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:38:05.152+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:38:05.152+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:38:05.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.016 seconds
[2024-09-06T13:38:35.456+0000] {processor.py:161} INFO - Started process (PID=1228) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:38:35.458+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:38:35.462+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:38:35.461+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:38:36.530+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:38:36.645+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:38:36.644+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:38:36.752+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:38:36.752+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:38:36.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.383 seconds
[2024-09-06T13:39:06.955+0000] {processor.py:161} INFO - Started process (PID=1246) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:39:06.957+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:39:06.960+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:39:06.959+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:39:08.934+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:39:08.976+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:39:08.975+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:39:09.018+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:39:09.017+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:39:09.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.150 seconds
[2024-09-06T13:39:39.216+0000] {processor.py:161} INFO - Started process (PID=1264) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:39:39.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:39:39.221+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:39:39.221+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:39:40.128+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:39:40.158+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:39:40.157+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:39:40.182+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:39:40.182+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:39:40.213+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.011 seconds
[2024-09-06T13:40:10.298+0000] {processor.py:161} INFO - Started process (PID=1282) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:40:10.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:40:10.303+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:40:10.302+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:40:11.206+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:40:11.239+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:40:11.238+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:40:11.274+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:40:11.274+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:40:11.299+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.009 seconds
[2024-09-06T13:40:41.612+0000] {processor.py:161} INFO - Started process (PID=1300) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:40:41.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:40:41.616+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:40:41.616+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:40:42.575+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:40:42.611+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:40:42.610+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:40:42.645+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:40:42.644+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:40:42.669+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.063 seconds
[2024-09-06T13:41:12.987+0000] {processor.py:161} INFO - Started process (PID=1318) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:41:12.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:41:12.994+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:41:12.993+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:41:14.326+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:41:14.355+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:41:14.354+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:41:14.381+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:41:14.381+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:41:14.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.441 seconds
[2024-09-06T13:41:44.763+0000] {processor.py:161} INFO - Started process (PID=1336) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:41:44.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:41:44.768+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:41:44.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:41:45.547+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:41:45.592+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:41:45.591+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:41:45.657+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:41:45.657+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:41:45.709+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.957 seconds
[2024-09-06T13:42:16.091+0000] {processor.py:161} INFO - Started process (PID=1354) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:42:16.092+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:42:16.094+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:42:16.094+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:42:17.189+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:42:17.224+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:42:17.223+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:42:17.257+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:42:17.257+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:42:17.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.200 seconds
[2024-09-06T13:42:47.521+0000] {processor.py:161} INFO - Started process (PID=1373) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:42:47.523+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:42:47.525+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:42:47.524+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:42:48.283+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:42:48.322+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:42:48.321+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:42:48.348+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:42:48.348+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:42:48.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.865 seconds
[2024-09-06T13:43:18.679+0000] {processor.py:161} INFO - Started process (PID=1391) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:43:18.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:43:18.683+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:43:18.682+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:43:19.637+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:43:19.680+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:43:19.679+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:43:19.714+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:43:19.714+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:43:19.747+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.077 seconds
[2024-09-06T13:43:50.053+0000] {processor.py:161} INFO - Started process (PID=1409) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:43:50.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:43:50.056+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:43:50.056+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:43:50.807+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:43:50.834+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:43:50.833+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:43:50.856+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:43:50.856+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:43:50.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.839 seconds
[2024-09-06T13:44:21.133+0000] {processor.py:161} INFO - Started process (PID=1427) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:44:21.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:44:21.137+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:44:21.137+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:44:21.921+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:44:21.948+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:44:21.948+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:44:21.970+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:44:21.970+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:44:22.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.875 seconds
[2024-09-06T13:44:52.301+0000] {processor.py:161} INFO - Started process (PID=1446) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:44:52.303+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:44:52.306+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:44:52.305+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:44:53.420+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:44:53.461+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:44:53.460+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:44:53.501+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:44:53.500+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:44:53.537+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.247 seconds
[2024-09-06T13:45:23.880+0000] {processor.py:161} INFO - Started process (PID=1463) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:45:23.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:45:23.897+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:45:23.897+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:45:25.370+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:45:25.411+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:45:25.411+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:45:25.445+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:45:25.445+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:45:25.485+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.625 seconds
[2024-09-06T13:45:56.218+0000] {processor.py:161} INFO - Started process (PID=1481) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:45:56.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:45:56.223+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:45:56.223+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:45:57.480+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:45:57.547+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:45:57.546+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:45:57.614+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:45:57.614+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:45:57.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.460 seconds
[2024-09-06T13:46:28.198+0000] {processor.py:161} INFO - Started process (PID=1499) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:46:28.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:46:28.204+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:46:28.204+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:46:30.271+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:46:30.358+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:46:30.355+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:46:30.416+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:46:30.415+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:46:30.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.285 seconds
[2024-09-06T13:47:00.909+0000] {processor.py:161} INFO - Started process (PID=1523) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:47:00.940+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:47:00.964+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:47:00.963+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:47:02.666+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:47:02.723+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:47:02.721+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:47:02.800+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:47:02.800+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:47:02.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.988 seconds
[2024-09-06T13:47:33.322+0000] {processor.py:161} INFO - Started process (PID=1541) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:47:33.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:47:33.331+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:47:33.330+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:47:34.629+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:47:34.665+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:47:34.664+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:47:34.696+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:47:34.695+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:47:34.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.423 seconds
[2024-09-06T13:48:04.876+0000] {processor.py:161} INFO - Started process (PID=1560) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:48:04.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:48:04.881+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:48:04.880+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:48:07.499+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:48:07.575+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:48:07.574+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:48:07.656+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:48:07.655+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:48:07.766+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.910 seconds
[2024-09-06T13:48:08.978+0000] {processor.py:161} INFO - Started process (PID=1566) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:48:08.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:48:08.988+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:48:08.987+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:48:10.819+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:48:10.884+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:48:10.882+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:48:10.936+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:48:10.935+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:48:10.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.027 seconds
[2024-09-06T13:48:12.066+0000] {processor.py:161} INFO - Started process (PID=1572) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:48:12.070+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:48:12.073+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:48:12.072+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:48:15.045+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:48:15.098+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:48:15.097+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:48:15.148+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:48:15.147+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:48:15.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.207 seconds
[2024-09-06T13:52:24.199+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:52:24.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:52:24.216+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:52:24.209+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:52:32.953+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:52:33.461+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:52:33.460+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:52:33.542+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:52:33.541+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:52:33.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 9.447 seconds
[2024-09-06T13:53:04.057+0000] {processor.py:161} INFO - Started process (PID=196) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:53:04.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:53:04.060+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:53:04.060+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:53:05.342+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:53:05.381+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:53:05.380+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:53:05.427+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:53:05.426+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:53:05.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.430 seconds
[2024-09-06T13:53:35.700+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:53:35.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:53:35.705+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:53:35.704+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:53:36.780+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:53:36.852+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:53:36.851+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:53:36.897+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:53:36.897+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:53:36.957+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.264 seconds
[2024-09-06T13:54:07.257+0000] {processor.py:161} INFO - Started process (PID=232) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:54:07.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:54:07.262+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:54:07.261+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:54:08.685+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:54:08.741+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:54:08.739+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:54:08.792+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:54:08.791+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:54:08.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.595 seconds
[2024-09-06T13:54:41.096+0000] {processor.py:161} INFO - Started process (PID=277) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:54:41.154+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:54:41.174+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:54:41.173+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:54:57.743+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:54:57.916+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:54:57.900+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:54:58.308+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:54:58.308+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:54:58.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 17.727 seconds
[2024-09-06T13:55:28.759+0000] {processor.py:161} INFO - Started process (PID=299) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:55:28.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2024-09-06T13:55:28.768+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:55:28.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:55:30.288+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2024-09-06T13:55:30.367+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:55:30.364+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-09-06T13:55:30.452+0000] {logging_mixin.py:188} INFO - [2024-09-06T13:55:30.452+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2024-09-06 00:00:00+00:00, run_after=2024-09-07 00:00:00+00:00
[2024-09-06T13:55:33.817+0000] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1094, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 686, in do_commit
    dbapi_connection.commit()
psycopg2.OperationalError: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 896, in save_dag_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 839, in commit
    trans.commit()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2469, in commit
    self._do_commit()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2659, in _do_commit
    self._connection_commit_impl()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2630, in _connection_commit_impl
    self.connection._commit_impl()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1096, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1094, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 686, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/14/e3q8)
