[2025-06-02T08:08:26.312+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:08:26.318+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:08:26.349+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:08:26.348+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:08:36.324+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:08:36.313+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:08:36.325+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:08:36.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 10.133 seconds
[2025-06-02T08:09:06.764+0000] {processor.py:161} INFO - Started process (PID=183) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:09:06.769+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:09:06.774+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:09:06.773+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:09:08.979+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:09:08.963+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:09:08.981+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:09:09.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.320 seconds
[2025-06-02T08:09:39.746+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:09:39.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:09:39.754+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:09:39.753+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:09:40.850+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:09:40.839+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:09:40.851+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:09:40.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.168 seconds
[2025-06-02T08:10:11.363+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:10:11.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:10:11.413+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:10:11.412+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:10:12.686+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:10:12.675+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:10:12.687+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:10:12.735+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.396 seconds
[2025-06-02T08:10:42.995+0000] {processor.py:161} INFO - Started process (PID=233) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:10:43.003+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:10:43.010+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:10:43.009+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:10:44.296+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:10:44.285+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:10:44.299+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:10:44.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.365 seconds
[2025-06-02T08:11:14.983+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:11:14.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:11:14.998+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:11:14.997+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:11:17.300+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:11:17.260+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:11:17.307+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:11:17.397+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.438 seconds
[2025-06-02T08:11:47.587+0000] {processor.py:161} INFO - Started process (PID=263) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:11:47.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:11:47.610+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:11:47.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:11:49.224+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:11:49.215+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:11:49.226+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:11:49.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.700 seconds
[2025-06-02T08:12:19.466+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:12:19.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:12:19.473+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:12:19.472+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:12:20.795+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:12:20.789+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:12:20.797+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:12:20.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.401 seconds
[2025-06-02T08:12:50.988+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:12:50.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:12:50.993+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:12:50.993+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:12:52.428+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:12:52.421+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:12:52.429+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:12:52.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.498 seconds
[2025-06-02T08:13:23.371+0000] {processor.py:161} INFO - Started process (PID=303) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:13:23.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:13:23.380+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:13:23.379+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:13:25.705+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:13:25.698+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:13:25.707+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:13:25.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.393 seconds
[2025-06-02T08:13:56.390+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:13:56.405+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:13:56.425+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:13:56.423+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:13:58.195+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:13:58.186+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:13:58.196+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:13:58.242+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.916 seconds
[2025-06-02T08:14:29.557+0000] {processor.py:161} INFO - Started process (PID=333) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:14:29.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:14:29.596+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:14:29.595+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:14:32.984+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:14:32.976+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:14:32.986+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:14:33.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.542 seconds
[2025-06-02T08:15:06.104+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:15:06.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:15:06.170+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:15:06.169+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:15:11.020+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:15:11.008+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:15:11.022+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:15:11.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.019 seconds
[2025-06-02T08:15:44.573+0000] {processor.py:161} INFO - Started process (PID=371) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:15:44.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:15:44.624+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:15:44.623+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:15:47.371+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:15:47.361+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:15:47.374+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:15:47.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.902 seconds
[2025-06-02T08:16:18.277+0000] {processor.py:161} INFO - Started process (PID=383) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:16:18.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:16:18.286+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:16:18.285+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:16:19.640+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:16:19.631+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:16:19.641+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:16:19.683+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.420 seconds
[2025-06-02T08:16:50.075+0000] {processor.py:161} INFO - Started process (PID=402) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:16:50.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:16:50.085+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:16:50.083+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:16:51.721+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:16:51.710+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:16:51.722+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:16:51.770+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.721 seconds
[2025-06-02T08:17:22.581+0000] {processor.py:161} INFO - Started process (PID=414) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:17:22.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:17:22.585+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:17:22.585+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:17:23.627+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:17:23.618+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:17:23.629+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:17:23.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.103 seconds
[2025-06-02T08:17:54.331+0000] {processor.py:161} INFO - Started process (PID=432) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:17:54.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:17:54.338+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:17:54.338+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:17:57.591+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:17:57.576+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:17:57.596+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:17:57.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.350 seconds
[2025-06-02T08:18:29.143+0000] {processor.py:161} INFO - Started process (PID=445) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:18:29.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:18:29.164+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:18:29.163+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:18:32.069+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:18:32.063+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:18:32.071+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:18:32.105+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.019 seconds
[2025-06-02T08:19:02.888+0000] {processor.py:161} INFO - Started process (PID=465) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:19:02.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:19:02.895+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:19:02.894+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:19:03.903+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:19:03.892+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:19:03.905+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:19:03.944+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.077 seconds
[2025-06-02T08:19:34.589+0000] {processor.py:161} INFO - Started process (PID=477) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:19:34.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:19:34.594+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:19:34.593+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:19:35.624+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:19:35.618+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:19:35.625+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:19:35.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.087 seconds
[2025-06-02T08:20:06.291+0000] {processor.py:161} INFO - Started process (PID=495) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:20:06.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:20:06.297+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:20:06.297+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:20:07.521+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:20:07.514+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:20:07.522+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:20:07.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.278 seconds
[2025-06-02T08:20:38.066+0000] {processor.py:161} INFO - Started process (PID=507) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:20:38.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:20:38.075+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:20:38.074+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:20:42.659+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:20:42.608+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:20:42.665+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:20:42.756+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.710 seconds
[2025-06-02T08:21:13.306+0000] {processor.py:161} INFO - Started process (PID=525) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:21:13.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:21:13.333+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:21:13.332+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:21:15.758+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:21:15.745+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:21:15.760+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:21:15.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.546 seconds
[2025-06-02T08:21:46.212+0000] {processor.py:161} INFO - Started process (PID=543) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:21:46.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:21:46.229+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:21:46.228+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:21:48.930+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:21:48.893+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:21:48.938+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:21:48.989+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.831 seconds
[2025-06-02T08:22:19.337+0000] {processor.py:161} INFO - Started process (PID=555) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:22:19.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:22:19.348+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:22:19.347+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:22:23.002+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:22:22.991+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:22:23.004+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:22:23.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.750 seconds
[2025-06-02T08:22:53.748+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:22:53.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:22:53.859+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:22:53.858+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:22:57.358+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:22:57.350+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:22:57.360+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:22:57.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.756 seconds
[2025-06-02T08:23:28.342+0000] {processor.py:161} INFO - Started process (PID=585) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:23:28.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:23:28.373+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:23:28.372+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:23:31.357+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:23:31.340+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:23:31.361+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:23:31.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.193 seconds
[2025-06-02T08:24:01.855+0000] {processor.py:161} INFO - Started process (PID=603) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:24:01.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:24:01.859+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:24:01.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:24:03.451+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:24:03.436+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:24:03.454+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:24:03.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.735 seconds
[2025-06-02T08:24:33.981+0000] {processor.py:161} INFO - Started process (PID=618) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:24:33.982+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:24:33.986+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:24:33.985+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:24:35.716+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:24:35.706+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:24:35.718+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:24:35.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.902 seconds
[2025-06-02T08:25:06.814+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:25:06.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:25:06.853+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:25:06.852+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:25:08.333+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:25:08.312+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:25:08.335+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:25:08.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.593 seconds
[2025-06-02T08:25:38.831+0000] {processor.py:161} INFO - Started process (PID=648) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:25:38.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:25:38.841+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:25:38.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:25:40.901+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:25:40.891+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:25:40.903+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:25:40.967+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.156 seconds
[2025-06-02T08:26:11.553+0000] {processor.py:161} INFO - Started process (PID=666) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:26:11.556+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:26:11.562+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:26:11.560+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:26:13.196+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:26:13.188+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:26:13.197+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:26:13.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.691 seconds
[2025-06-02T08:26:43.610+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:26:43.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:26:43.616+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:26:43.615+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:26:45.147+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:26:45.141+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:26:45.149+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:26:45.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.576 seconds
[2025-06-02T08:27:15.342+0000] {processor.py:161} INFO - Started process (PID=696) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:27:15.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:27:15.347+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:27:15.347+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:27:16.459+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:27:16.449+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:27:16.460+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:27:16.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.166 seconds
[2025-06-02T08:27:47.088+0000] {processor.py:161} INFO - Started process (PID=714) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:27:47.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:27:47.117+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:27:47.116+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:27:49.102+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:27:49.077+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:27:49.113+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:27:49.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.219 seconds
[2025-06-02T08:28:19.504+0000] {processor.py:161} INFO - Started process (PID=726) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:28:19.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:28:19.510+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:28:19.509+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:28:20.956+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:28:20.941+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:28:20.958+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:28:21.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.530 seconds
[2025-06-02T08:28:51.821+0000] {processor.py:161} INFO - Started process (PID=744) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:28:51.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:28:51.828+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:28:51.828+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:28:53.064+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:28:53.052+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:28:53.066+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:28:53.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.296 seconds
[2025-06-02T08:29:23.825+0000] {processor.py:161} INFO - Started process (PID=756) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:29:23.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:29:23.830+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:29:23.830+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:29:25.125+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:29:25.118+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:29:25.126+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:29:25.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.344 seconds
[2025-06-02T08:29:55.751+0000] {processor.py:161} INFO - Started process (PID=774) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:29:55.756+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:29:55.765+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:29:55.764+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:29:56.907+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:29:56.898+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:29:56.909+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:29:56.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.207 seconds
[2025-06-02T08:30:27.772+0000] {processor.py:161} INFO - Started process (PID=786) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:30:27.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:30:27.783+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:30:27.782+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:30:29.515+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:30:29.506+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:30:29.517+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:30:29.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.834 seconds
[2025-06-02T08:30:59.704+0000] {processor.py:161} INFO - Started process (PID=804) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:30:59.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:30:59.712+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:30:59.712+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:31:01.359+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:31:01.350+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:31:01.360+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:31:01.397+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.707 seconds
[2025-06-02T08:31:31.823+0000] {processor.py:161} INFO - Started process (PID=816) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:31:31.825+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:31:31.830+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:31:31.829+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:31:32.945+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:31:32.936+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:31:32.947+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:31:32.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.176 seconds
[2025-06-02T08:32:03.667+0000] {processor.py:161} INFO - Started process (PID=834) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:32:03.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:32:03.672+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:32:03.671+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:32:04.785+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:32:04.776+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:32:04.787+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:32:04.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.174 seconds
[2025-06-02T08:32:35.430+0000] {processor.py:161} INFO - Started process (PID=846) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:32:35.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:32:35.436+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:32:35.435+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:32:36.425+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:32:36.415+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:32:36.427+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:32:36.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.043 seconds
[2025-06-02T08:33:07.038+0000] {processor.py:161} INFO - Started process (PID=865) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:33:07.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:33:07.054+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:33:07.053+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:33:08.908+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:33:08.900+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:33:08.910+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:33:08.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.921 seconds
[2025-06-02T08:33:39.998+0000] {processor.py:161} INFO - Started process (PID=877) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:33:40.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:33:40.004+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:33:40.002+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:33:41.840+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:33:41.831+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:33:41.842+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:33:41.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.896 seconds
[2025-06-02T08:34:12.547+0000] {processor.py:161} INFO - Started process (PID=895) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:34:12.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:34:12.555+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:34:12.555+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:34:13.616+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:34:13.609+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:34:13.617+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:34:13.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.126 seconds
[2025-06-02T08:34:44.150+0000] {processor.py:161} INFO - Started process (PID=907) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:34:44.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:34:44.158+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:34:44.157+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:34:45.377+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:34:45.368+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:34:45.378+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:34:45.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.280 seconds
[2025-06-02T08:35:16.128+0000] {processor.py:161} INFO - Started process (PID=925) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:35:16.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:35:16.150+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:35:16.149+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:35:17.277+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:35:17.267+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:35:17.279+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:35:17.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.233 seconds
[2025-06-02T08:35:47.958+0000] {processor.py:161} INFO - Started process (PID=943) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:35:47.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:35:47.985+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:35:47.984+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:35:49.742+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:35:49.732+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:35:49.744+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:35:49.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.893 seconds
[2025-06-02T08:36:20.734+0000] {processor.py:161} INFO - Started process (PID=955) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:36:20.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:36:20.759+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:36:20.758+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:36:22.249+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:36:22.243+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:36:22.254+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:36:22.308+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.600 seconds
[2025-06-02T08:36:53.282+0000] {processor.py:161} INFO - Started process (PID=973) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:36:53.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:36:53.292+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:36:53.291+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:36:54.364+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:36:54.356+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:36:54.365+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:36:54.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.138 seconds
[2025-06-02T08:37:25.203+0000] {processor.py:161} INFO - Started process (PID=985) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:37:25.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:37:25.209+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:37:25.208+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:37:26.256+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:37:26.247+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:37:26.257+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:37:26.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.092 seconds
[2025-06-02T08:37:56.795+0000] {processor.py:161} INFO - Started process (PID=1003) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:37:56.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:37:56.800+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:37:56.800+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:37:58.068+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:37:58.062+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:37:58.069+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:37:58.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.319 seconds
[2025-06-02T08:38:28.643+0000] {processor.py:161} INFO - Started process (PID=1015) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:38:28.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:38:28.650+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:38:28.649+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:38:30.036+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:38:30.028+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:38:30.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:38:30.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.439 seconds
[2025-06-02T08:39:00.866+0000] {processor.py:161} INFO - Started process (PID=1033) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:39:00.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:39:00.874+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:39:00.873+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:39:02.444+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:39:02.436+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:39:02.448+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:39:02.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.671 seconds
[2025-06-02T08:39:33.273+0000] {processor.py:161} INFO - Started process (PID=1045) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:39:33.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:39:33.294+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:39:33.293+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:39:34.404+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:39:34.394+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:39:34.406+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:39:34.440+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.204 seconds
[2025-06-02T08:40:05.053+0000] {processor.py:161} INFO - Started process (PID=1063) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:40:05.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:40:05.065+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:40:05.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:40:06.285+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:40:06.279+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:40:06.290+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:40:06.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.318 seconds
[2025-06-02T08:40:36.689+0000] {processor.py:161} INFO - Started process (PID=1075) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:40:36.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:40:36.694+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:40:36.693+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:40:38.026+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:40:38.015+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:40:38.027+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:40:38.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.396 seconds
[2025-06-02T08:41:08.347+0000] {processor.py:161} INFO - Started process (PID=1093) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:41:08.351+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:41:08.357+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:41:08.355+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:41:09.622+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:41:09.613+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:41:09.623+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:41:09.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.335 seconds
[2025-06-02T08:41:40.210+0000] {processor.py:161} INFO - Started process (PID=1105) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:41:40.212+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:41:40.215+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:41:40.214+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:41:41.702+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:41:41.674+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:41:41.704+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:41:41.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.586 seconds
[2025-06-02T08:42:12.221+0000] {processor.py:161} INFO - Started process (PID=1123) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:42:12.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:42:12.227+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:42:12.226+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:42:13.847+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:42:13.840+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:42:13.848+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:42:13.886+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.679 seconds
[2025-06-02T08:42:44.484+0000] {processor.py:161} INFO - Started process (PID=1135) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:42:44.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:42:44.491+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:42:44.490+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:42:45.412+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:42:45.404+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:42:45.413+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:42:45.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.962 seconds
[2025-06-02T08:43:16.197+0000] {processor.py:161} INFO - Started process (PID=1153) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:43:16.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:43:16.204+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:43:16.203+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:43:17.962+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:43:17.950+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:43:17.964+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:43:18.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.878 seconds
[2025-06-02T08:43:48.339+0000] {processor.py:161} INFO - Started process (PID=1171) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:43:48.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:43:48.352+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:43:48.351+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:43:49.601+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:43:49.594+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:43:49.602+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:43:49.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.317 seconds
[2025-06-02T08:44:20.190+0000] {processor.py:161} INFO - Started process (PID=1183) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:44:20.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:44:20.196+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:44:20.195+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:44:21.813+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:44:21.806+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:44:21.815+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:44:21.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.670 seconds
[2025-06-02T08:44:52.476+0000] {processor.py:161} INFO - Started process (PID=1200) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:44:52.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:44:52.481+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:44:52.481+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:44:53.516+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:44:53.509+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:44:53.517+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:44:53.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.087 seconds
[2025-06-02T08:45:24.084+0000] {processor.py:161} INFO - Started process (PID=1212) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:45:24.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:45:24.089+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:45:24.089+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:45:25.322+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:45:25.313+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:45:25.323+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:45:25.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.297 seconds
[2025-06-02T08:45:55.940+0000] {processor.py:161} INFO - Started process (PID=1230) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:45:55.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:45:55.946+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:45:55.946+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:45:57.274+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:45:57.264+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:45:57.276+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:45:57.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.391 seconds
[2025-06-02T08:46:27.882+0000] {processor.py:161} INFO - Started process (PID=1242) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:46:27.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:46:27.903+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:46:27.901+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:46:29.764+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:46:29.758+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:46:29.765+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:46:29.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.948 seconds
[2025-06-02T08:47:00.040+0000] {processor.py:161} INFO - Started process (PID=1260) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:47:00.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:47:00.045+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:47:00.044+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:47:01.551+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:47:01.545+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:47:01.552+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:47:01.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.560 seconds
[2025-06-02T08:47:32.282+0000] {processor.py:161} INFO - Started process (PID=1272) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:47:32.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:47:32.298+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:47:32.297+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:47:33.510+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:47:33.501+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:47:33.511+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:47:33.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.279 seconds
[2025-06-02T08:48:03.809+0000] {processor.py:161} INFO - Started process (PID=1290) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:48:03.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:48:03.813+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:48:03.812+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:48:04.833+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:48:04.828+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:48:04.834+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:48:04.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.076 seconds
[2025-06-02T08:48:35.685+0000] {processor.py:161} INFO - Started process (PID=1302) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:48:35.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:48:35.691+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:48:35.690+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:48:36.808+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:48:36.800+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:48:36.810+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:48:36.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.163 seconds
[2025-06-02T08:49:07.081+0000] {processor.py:161} INFO - Started process (PID=1320) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:49:07.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:49:07.085+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:49:07.085+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:49:07.989+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:49:07.983+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:49:07.990+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:49:08.014+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.943 seconds
[2025-06-02T08:49:38.216+0000] {processor.py:161} INFO - Started process (PID=1332) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:49:38.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:49:38.223+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:49:38.222+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:49:39.448+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:49:39.440+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:49:39.449+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:49:39.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.298 seconds
[2025-06-02T08:50:09.755+0000] {processor.py:161} INFO - Started process (PID=1350) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:50:09.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:50:09.763+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:50:09.762+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:50:10.693+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:50:10.685+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:50:10.694+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:50:10.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.988 seconds
[2025-06-02T08:50:41.321+0000] {processor.py:161} INFO - Started process (PID=1362) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:50:41.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:50:41.330+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:50:41.330+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:50:43.423+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:50:43.413+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:50:43.426+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:50:43.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.165 seconds
[2025-06-02T08:51:13.650+0000] {processor.py:161} INFO - Started process (PID=1381) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:51:13.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:51:13.663+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:51:13.662+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:51:14.925+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:51:14.918+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:51:14.927+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:51:14.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.348 seconds
[2025-06-02T08:51:47.392+0000] {processor.py:161} INFO - Started process (PID=1393) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:51:47.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:51:47.412+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:51:47.411+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:51:49.230+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:51:49.223+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:51:49.231+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:51:49.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.914 seconds
[2025-06-02T08:52:19.828+0000] {processor.py:161} INFO - Started process (PID=1411) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:52:19.831+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:52:19.835+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:52:19.834+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:52:22.214+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:52:22.204+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:52:22.216+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:52:22.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.453 seconds
[2025-06-02T08:52:52.875+0000] {processor.py:161} INFO - Started process (PID=1429) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:52:52.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:52:52.881+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:52:52.880+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:52:54.231+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:52:54.223+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:52:54.233+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:52:54.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.430 seconds
[2025-06-02T08:53:25.223+0000] {processor.py:161} INFO - Started process (PID=1441) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:53:25.226+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:53:25.231+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:53:25.230+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:53:27.518+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:53:27.509+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:53:27.520+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:53:27.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.402 seconds
[2025-06-02T08:53:58.149+0000] {processor.py:161} INFO - Started process (PID=1459) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:53:58.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:53:58.155+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:53:58.154+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:54:00.008+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:53:59.993+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:54:00.027+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:54:00.084+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.945 seconds
[2025-06-02T08:54:30.520+0000] {processor.py:161} INFO - Started process (PID=1471) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:54:30.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:54:30.550+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:54:30.549+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:54:33.730+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:54:33.723+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:54:33.732+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:54:33.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.292 seconds
[2025-06-02T08:55:04.035+0000] {processor.py:161} INFO - Started process (PID=1489) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:55:04.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:55:04.044+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:55:04.043+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:55:06.538+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:55:06.531+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:55:06.539+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:55:06.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.559 seconds
[2025-06-02T08:55:37.536+0000] {processor.py:161} INFO - Started process (PID=1501) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:55:37.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:55:37.548+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:55:37.547+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:55:39.475+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:55:39.462+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:55:39.477+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:55:39.537+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.012 seconds
[2025-06-02T08:56:10.228+0000] {processor.py:161} INFO - Started process (PID=1518) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:56:10.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:56:10.236+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:56:10.236+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:56:11.966+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:56:11.950+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:56:11.969+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:56:12.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.854 seconds
[2025-06-02T08:56:42.975+0000] {processor.py:161} INFO - Started process (PID=1530) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:56:42.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:56:42.996+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:56:42.994+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:56:46.951+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:56:46.906+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:56:46.956+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:56:47.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.163 seconds
[2025-06-02T08:57:17.606+0000] {processor.py:161} INFO - Started process (PID=1548) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:57:17.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:57:17.622+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:57:17.621+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:57:19.498+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:57:19.488+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:57:19.500+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:57:19.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.969 seconds
[2025-06-02T08:57:50.545+0000] {processor.py:161} INFO - Started process (PID=1566) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:57:50.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:57:50.551+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:57:50.550+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:57:52.053+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:57:52.041+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:57:52.055+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:57:52.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.588 seconds
[2025-06-02T08:58:22.325+0000] {processor.py:161} INFO - Started process (PID=1578) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:58:22.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:58:22.333+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:58:22.331+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:58:23.695+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:58:23.687+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:58:23.697+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:58:23.770+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.458 seconds
[2025-06-02T08:58:54.332+0000] {processor.py:161} INFO - Started process (PID=1596) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:58:54.350+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:58:54.363+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:58:54.362+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:58:58.321+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:58:58.306+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:58:58.323+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:58:58.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.118 seconds
[2025-06-02T08:59:29.872+0000] {processor.py:161} INFO - Started process (PID=1608) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:59:29.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T08:59:29.889+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:59:29.888+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:59:31.196+0000] {logging_mixin.py:188} INFO - [2025-06-02T08:59:31.191+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T08:59:31.197+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T08:59:31.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.381 seconds
[2025-06-02T09:00:01.835+0000] {processor.py:161} INFO - Started process (PID=1626) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:00:01.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:00:01.878+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:00:01.877+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:00:05.942+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:00:05.927+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:00:05.944+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:00:06.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.230 seconds
[2025-06-02T09:00:36.535+0000] {processor.py:161} INFO - Started process (PID=1638) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:00:36.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:00:36.539+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:00:36.539+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:00:37.668+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:00:37.661+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:00:37.669+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:00:37.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.177 seconds
[2025-06-02T09:01:08.481+0000] {processor.py:161} INFO - Started process (PID=1657) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:01:08.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:01:08.494+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:01:08.493+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:01:11.256+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:01:11.238+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:01:11.258+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:01:11.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.867 seconds
[2025-06-02T09:01:41.730+0000] {processor.py:161} INFO - Started process (PID=1669) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:01:41.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:01:41.737+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:01:41.736+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:01:43.241+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:01:43.235+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:01:43.243+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:01:43.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.568 seconds
[2025-06-02T09:02:13.832+0000] {processor.py:161} INFO - Started process (PID=1687) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:02:13.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:02:13.838+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:02:13.838+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:02:16.440+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:02:16.383+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:02:16.447+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:02:16.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.717 seconds
[2025-06-02T09:02:47.405+0000] {processor.py:161} INFO - Started process (PID=1699) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:02:47.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:02:47.409+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:02:47.409+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:02:50.455+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:02:50.448+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:02:50.457+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:02:50.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.105 seconds
[2025-06-02T09:03:21.360+0000] {processor.py:161} INFO - Started process (PID=1716) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:03:21.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:03:21.367+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:03:21.366+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:03:23.136+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:03:23.130+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:03:23.137+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:03:23.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.844 seconds
[2025-06-02T09:03:53.523+0000] {processor.py:161} INFO - Started process (PID=1737) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:03:53.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:03:53.540+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:03:53.540+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:03:55.086+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:03:55.082+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:03:55.087+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:03:55.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.624 seconds
[2025-06-02T09:04:25.358+0000] {processor.py:161} INFO - Started process (PID=1746) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:04:25.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:04:25.364+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:04:25.364+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:04:27.595+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:04:27.577+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:04:27.600+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:04:27.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.335 seconds
[2025-06-02T09:04:57.881+0000] {processor.py:161} INFO - Started process (PID=1769) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:04:57.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:04:57.887+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:04:57.886+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:05:01.585+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:05:01.578+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:05:01.586+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:05:01.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.798 seconds
[2025-06-02T09:05:32.043+0000] {processor.py:161} INFO - Started process (PID=1782) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:05:32.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:05:32.058+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:05:32.057+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:05:33.570+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:05:33.565+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:05:33.571+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:05:33.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.578 seconds
[2025-06-02T09:06:04.102+0000] {processor.py:161} INFO - Started process (PID=1800) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:06:04.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:06:04.154+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:06:04.153+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:06:07.458+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:06:07.429+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:06:07.461+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:06:07.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.468 seconds
[2025-06-02T09:06:37.787+0000] {processor.py:161} INFO - Started process (PID=1816) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:06:37.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:06:37.794+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:06:37.793+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:06:40.517+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:06:40.510+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:06:40.518+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:06:40.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.795 seconds
[2025-06-02T09:07:10.783+0000] {processor.py:161} INFO - Started process (PID=1834) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:07:10.790+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:07:10.799+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:07:10.798+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:07:15.289+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:07:15.262+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:07:15.292+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:07:15.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.583 seconds
[2025-06-02T09:07:45.808+0000] {processor.py:161} INFO - Started process (PID=1848) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:07:45.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:07:45.817+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:07:45.816+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:07:46.836+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:07:46.831+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:07:46.837+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:07:46.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.065 seconds
[2025-06-02T09:08:17.437+0000] {processor.py:161} INFO - Started process (PID=1864) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:08:17.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:08:17.447+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:08:17.446+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:08:19.283+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:08:19.278+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:08:19.285+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:08:19.313+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.899 seconds
[2025-06-02T09:08:50.337+0000] {processor.py:161} INFO - Started process (PID=1876) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:08:50.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:08:50.365+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:08:50.364+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:08:52.873+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:08:52.865+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:08:52.874+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:08:52.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.620 seconds
[2025-06-02T09:09:23.520+0000] {processor.py:161} INFO - Started process (PID=1893) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:09:23.523+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:09:23.530+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:09:23.529+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:09:25.617+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:09:25.603+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:09:25.619+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:09:25.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.151 seconds
[2025-06-02T09:09:56.242+0000] {processor.py:161} INFO - Started process (PID=1913) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:09:56.244+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:09:56.246+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:09:56.246+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:09:57.090+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:09:57.082+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:09:57.091+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:09:57.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.882 seconds
[2025-06-02T09:10:27.592+0000] {processor.py:161} INFO - Started process (PID=1925) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:10:27.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:10:27.597+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:10:27.597+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:10:28.650+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:10:28.642+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:10:28.652+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:10:28.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.110 seconds
[2025-06-02T09:10:59.118+0000] {processor.py:161} INFO - Started process (PID=1943) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:10:59.120+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:10:59.123+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:10:59.122+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:11:00.080+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:11:00.073+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:11:00.081+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:11:00.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.004 seconds
[2025-06-02T09:11:30.521+0000] {processor.py:161} INFO - Started process (PID=1955) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:11:30.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:11:30.525+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:11:30.524+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:11:31.523+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:11:31.423+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:11:31.525+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:11:31.590+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.078 seconds
[2025-06-02T09:12:02.047+0000] {processor.py:161} INFO - Started process (PID=1973) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:12:02.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:12:02.074+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:12:02.073+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:12:03.220+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:12:03.207+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:12:03.222+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:12:03.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.280 seconds
[2025-06-02T09:12:33.437+0000] {processor.py:161} INFO - Started process (PID=1988) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:12:33.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:12:33.442+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:12:33.442+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:12:34.366+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:12:34.361+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:12:34.367+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:12:34.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.964 seconds
[2025-06-02T09:13:05.239+0000] {processor.py:161} INFO - Started process (PID=2003) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:13:05.245+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:13:05.266+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:13:05.265+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:13:10.845+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:13:10.825+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:13:10.851+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:13:10.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.745 seconds
[2025-06-02T09:13:41.566+0000] {processor.py:161} INFO - Started process (PID=2017) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:13:41.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:13:41.582+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:13:41.581+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:13:42.774+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:13:42.766+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:13:42.776+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:13:42.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.265 seconds
[2025-06-02T09:14:13.391+0000] {processor.py:161} INFO - Started process (PID=2035) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:14:13.395+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:14:13.399+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:14:13.398+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:14:15.427+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:14:15.298+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:14:15.443+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:14:15.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.168 seconds
[2025-06-02T09:14:45.698+0000] {processor.py:161} INFO - Started process (PID=2047) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:14:45.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:14:45.702+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:14:45.701+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:14:46.934+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:14:46.929+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:14:46.935+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:14:46.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.293 seconds
[2025-06-02T09:15:17.489+0000] {processor.py:161} INFO - Started process (PID=2065) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:15:17.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:15:17.493+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:15:17.493+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:15:18.646+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:15:18.637+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:15:18.648+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:15:18.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.211 seconds
[2025-06-02T09:15:49.086+0000] {processor.py:161} INFO - Started process (PID=2077) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:15:49.088+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:15:49.090+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:15:49.090+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:15:49.892+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:15:49.885+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:15:49.893+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:15:49.948+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.870 seconds
[2025-06-02T09:16:20.158+0000] {processor.py:161} INFO - Started process (PID=2095) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:16:20.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:16:20.167+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:16:20.166+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:16:21.479+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:16:21.472+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:16:21.480+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:16:21.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.395 seconds
[2025-06-02T09:16:51.641+0000] {processor.py:161} INFO - Started process (PID=2107) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:16:51.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:16:51.648+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:16:51.648+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:16:53.242+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:16:53.236+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:16:53.243+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:16:53.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.648 seconds
[2025-06-02T09:17:23.562+0000] {processor.py:161} INFO - Started process (PID=2125) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:17:23.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:17:23.566+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:17:23.566+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:17:24.764+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:17:24.756+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:17:24.767+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:17:24.813+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.260 seconds
[2025-06-02T09:17:55.005+0000] {processor.py:161} INFO - Started process (PID=2143) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:17:55.007+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:17:55.010+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:17:55.010+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:17:56.315+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:17:56.308+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:17:56.317+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:17:56.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.365 seconds
[2025-06-02T09:18:26.893+0000] {processor.py:161} INFO - Started process (PID=2155) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:18:26.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:18:26.900+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:18:26.899+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:18:29.924+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:18:29.908+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:18:29.926+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:18:30.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.154 seconds
[2025-06-02T09:19:00.878+0000] {processor.py:161} INFO - Started process (PID=2173) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:19:00.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:19:00.884+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:19:00.883+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:19:02.798+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:19:02.788+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:19:02.800+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:19:02.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.998 seconds
[2025-06-02T09:19:33.276+0000] {processor.py:161} INFO - Started process (PID=2185) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:19:33.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:19:33.280+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:19:33.280+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:19:34.335+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:19:34.330+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:19:34.336+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:19:34.377+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.109 seconds
[2025-06-02T09:20:04.828+0000] {processor.py:161} INFO - Started process (PID=2203) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:20:04.831+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:20:04.836+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:20:04.836+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:20:07.018+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:20:07.006+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:20:07.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:20:07.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.294 seconds
[2025-06-02T09:20:37.607+0000] {processor.py:161} INFO - Started process (PID=2215) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:20:37.609+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:20:37.612+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:20:37.612+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:20:39.116+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:20:39.110+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:20:39.117+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:20:39.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.557 seconds
[2025-06-02T09:21:09.663+0000] {processor.py:161} INFO - Started process (PID=2233) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:21:09.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:21:09.670+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:21:09.669+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:21:11.401+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:21:11.390+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:21:11.404+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:21:11.459+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.811 seconds
[2025-06-02T09:21:41.672+0000] {processor.py:161} INFO - Started process (PID=2245) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:21:41.675+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:21:41.683+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:21:41.682+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:21:43.995+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:21:43.968+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:21:43.997+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:21:44.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.412 seconds
[2025-06-02T09:22:14.745+0000] {processor.py:161} INFO - Started process (PID=2263) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:22:14.747+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:22:14.752+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:22:14.751+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:22:16.072+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:22:16.055+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:22:16.075+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:22:16.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.453 seconds
[2025-06-02T09:22:46.533+0000] {processor.py:161} INFO - Started process (PID=2275) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:22:46.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:22:46.538+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:22:46.537+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:22:47.838+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:22:47.831+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:22:47.841+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:22:47.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.432 seconds
[2025-06-02T09:23:18.232+0000] {processor.py:161} INFO - Started process (PID=2293) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:23:18.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:23:18.237+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:23:18.236+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:23:19.336+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:23:19.329+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:23:19.337+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:23:19.374+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.154 seconds
[2025-06-02T09:23:49.863+0000] {processor.py:161} INFO - Started process (PID=2305) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:23:49.865+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:23:49.867+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:23:49.867+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:23:51.026+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:23:51.017+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:23:51.028+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:23:51.083+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.231 seconds
[2025-06-02T09:24:21.435+0000] {processor.py:161} INFO - Started process (PID=2323) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:24:21.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:24:21.444+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:24:21.441+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:24:23.138+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:24:23.129+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:24:23.140+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:24:23.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.772 seconds
[2025-06-02T09:24:53.579+0000] {processor.py:161} INFO - Started process (PID=2341) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:24:53.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:24:53.589+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:24:53.588+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:24:54.895+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:24:54.887+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:24:54.897+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:24:54.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.392 seconds
[2025-06-02T09:25:25.723+0000] {processor.py:161} INFO - Started process (PID=2353) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:25:25.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:25:25.730+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:25:25.729+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:25:26.495+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:25:26.489+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:25:26.497+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:25:26.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.847 seconds
[2025-06-02T09:25:56.994+0000] {processor.py:161} INFO - Started process (PID=2371) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:25:56.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:25:56.999+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:25:56.999+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:25:57.646+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:25:57.639+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:25:57.647+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:25:57.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.697 seconds
[2025-06-02T09:26:28.253+0000] {processor.py:161} INFO - Started process (PID=2383) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:26:28.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:26:28.257+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:26:28.257+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:26:31.673+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:26:31.665+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:26:31.674+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:26:31.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.472 seconds
[2025-06-02T09:27:01.947+0000] {processor.py:161} INFO - Started process (PID=2401) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:27:01.949+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:27:01.952+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:27:01.952+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:27:02.866+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:27:02.860+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:27:02.867+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:27:02.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.967 seconds
[2025-06-02T09:27:33.691+0000] {processor.py:161} INFO - Started process (PID=2413) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:27:33.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:27:33.705+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:27:33.704+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:27:34.535+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:27:34.527+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:27:34.536+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:27:34.563+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.894 seconds
[2025-06-02T09:28:04.929+0000] {processor.py:161} INFO - Started process (PID=2431) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:28:04.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:28:04.934+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:28:04.934+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:28:05.808+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:28:05.793+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:28:05.810+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:28:05.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.961 seconds
[2025-06-02T09:28:36.151+0000] {processor.py:161} INFO - Started process (PID=2443) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:28:36.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:28:36.157+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:28:36.156+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:28:36.967+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:28:36.958+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:28:36.969+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:28:37.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.861 seconds
[2025-06-02T09:29:08.079+0000] {processor.py:161} INFO - Started process (PID=2461) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:29:08.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:29:08.108+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:29:08.107+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:29:10.015+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:29:10.006+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:29:10.016+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:29:10.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.022 seconds
[2025-06-02T09:29:40.150+0000] {processor.py:161} INFO - Started process (PID=2473) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:29:40.152+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:29:40.155+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:29:40.154+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:29:40.951+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:29:40.944+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:29:40.952+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:29:40.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.848 seconds
[2025-06-02T09:30:52.951+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:30:52.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:30:52.960+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:30:52.959+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:30:55.551+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:30:55.542+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:30:55.552+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:30:55.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.648 seconds
[2025-06-02T09:31:26.450+0000] {processor.py:161} INFO - Started process (PID=183) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:31:26.482+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:31:26.500+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:31:26.498+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:31:29.392+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:31:29.375+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:31:29.394+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:31:29.441+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.153 seconds
[2025-06-02T09:31:59.811+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:31:59.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:31:59.819+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:31:59.818+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:32:02.150+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:32:02.144+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:32:02.151+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:32:02.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.398 seconds
[2025-06-02T09:32:32.647+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:32:32.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:32:32.651+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:32:32.651+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:32:33.596+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:32:33.590+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:32:33.598+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:32:33.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.017 seconds
[2025-06-02T09:33:04.373+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:33:04.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:33:04.390+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:33:04.384+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:33:06.183+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:33:06.178+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:33:06.185+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:33:06.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.874 seconds
[2025-06-02T09:37:33.279+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:37:33.282+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:37:33.296+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:37:33.295+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:37:41.473+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:37:41.438+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:37:41.480+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:37:41.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 8.376 seconds
[2025-06-02T09:38:12.740+0000] {processor.py:161} INFO - Started process (PID=185) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:38:12.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:38:12.749+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:38:12.748+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:38:13.767+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:38:13.761+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:38:13.768+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:38:13.801+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.074 seconds
[2025-06-02T09:38:44.273+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:38:44.277+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:38:44.281+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:38:44.280+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:38:45.249+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:38:45.240+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:38:45.252+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:38:45.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.029 seconds
[2025-06-02T09:39:15.762+0000] {processor.py:161} INFO - Started process (PID=218) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:39:15.764+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:39:15.768+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:39:15.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:39:18.528+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:39:18.522+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:39:18.530+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:39:18.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.844 seconds
[2025-06-02T09:39:48.906+0000] {processor.py:161} INFO - Started process (PID=248) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:39:48.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:39:48.914+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:39:48.913+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:39:50.861+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:39:50.851+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:39:50.864+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:39:50.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.055 seconds
[2025-06-02T09:40:24.048+0000] {processor.py:161} INFO - Started process (PID=269) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:40:24.068+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:40:24.100+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:40:24.099+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:40:29.809+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:40:29.780+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:40:29.811+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:40:29.892+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.871 seconds
[2025-06-02T09:41:00.151+0000] {processor.py:161} INFO - Started process (PID=301) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:41:00.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:41:00.159+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:41:00.159+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:41:04.367+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:41:04.326+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:41:04.377+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:41:04.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.356 seconds
[2025-06-02T09:41:37.135+0000] {processor.py:161} INFO - Started process (PID=317) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:41:37.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:41:37.176+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:41:37.176+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:41:43.300+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:41:43.256+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:41:43.308+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:41:43.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.349 seconds
[2025-06-02T09:42:14.996+0000] {processor.py:161} INFO - Started process (PID=346) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:42:15.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:42:15.033+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:42:15.032+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:42:25.591+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:42:25.301+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:42:25.605+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:42:25.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 10.898 seconds
[2025-06-02T09:42:56.942+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:42:56.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:42:56.960+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:42:56.959+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:43:00.319+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:43:00.311+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:43:00.321+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:43:00.385+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.465 seconds
[2025-06-02T09:43:30.629+0000] {processor.py:161} INFO - Started process (PID=375) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:43:30.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:43:30.638+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:43:30.637+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:43:33.762+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:43:33.749+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:43:33.772+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:43:33.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.278 seconds
[2025-06-02T09:44:04.372+0000] {processor.py:161} INFO - Started process (PID=393) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:44:04.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:44:04.379+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:44:04.378+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:44:06.107+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:44:06.075+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:44:06.108+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:44:06.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.785 seconds
[2025-06-02T09:44:59.116+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:44:59.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:44:59.123+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:44:59.121+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:45:04.058+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:45:04.033+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:45:04.061+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:45:04.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.045 seconds
[2025-06-02T09:45:34.654+0000] {processor.py:161} INFO - Started process (PID=185) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:45:34.657+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:45:34.661+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:45:34.660+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:45:35.563+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:45:35.557+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:45:35.564+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:45:35.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.952 seconds
[2025-06-02T09:46:06.307+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:46:06.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:46:06.358+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:46:06.357+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:46:09.673+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:46:09.661+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:46:09.675+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:46:09.708+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.425 seconds
[2025-06-02T09:46:40.268+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:46:40.270+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:46:40.273+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:46:40.273+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:46:42.178+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:46:42.135+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:46:42.186+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:46:42.258+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.999 seconds
[2025-06-02T09:47:13.076+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:47:13.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:47:13.081+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:47:13.080+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:47:14.223+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:47:14.216+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:47:14.225+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:47:14.261+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.198 seconds
[2025-06-02T09:47:44.550+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:47:44.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:47:44.559+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:47:44.557+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:47:45.674+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:47:45.662+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:47:45.675+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:47:45.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.181 seconds
[2025-06-02T09:48:16.524+0000] {processor.py:161} INFO - Started process (PID=257) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:48:16.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:48:16.530+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:48:16.529+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:48:17.763+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:48:17.757+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:48:17.765+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:48:17.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.289 seconds
[2025-06-02T09:48:48.035+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:48:48.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:48:48.041+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:48:48.040+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:48:50.565+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:48:50.558+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:48:50.567+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:48:50.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.578 seconds
[2025-06-02T09:49:21.855+0000] {processor.py:161} INFO - Started process (PID=287) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:49:21.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:49:21.937+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:49:21.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:49:25.607+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:49:25.586+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:49:25.618+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:49:25.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.863 seconds
[2025-06-02T09:49:56.149+0000] {processor.py:161} INFO - Started process (PID=305) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:49:56.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:49:56.153+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:49:56.153+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:49:57.497+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:49:57.490+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:49:57.498+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:49:57.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.390 seconds
[2025-06-02T09:50:27.894+0000] {processor.py:161} INFO - Started process (PID=317) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:50:27.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:50:27.927+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:50:27.926+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:50:31.410+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:50:31.404+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:50:31.412+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:50:31.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.577 seconds
[2025-06-02T09:51:02.205+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:51:02.206+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:51:02.211+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:51:02.210+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:51:03.707+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:51:03.698+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:51:03.709+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:51:03.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.553 seconds
[2025-06-02T09:51:34.938+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:51:34.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:51:34.969+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:51:34.968+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:51:38.595+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:51:38.587+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:51:38.596+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:51:38.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.729 seconds
[2025-06-02T09:52:09.251+0000] {processor.py:161} INFO - Started process (PID=365) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:52:09.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:52:09.257+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:52:09.256+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:52:10.676+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:52:10.668+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:52:10.678+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:52:10.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.501 seconds
[2025-06-02T09:52:41.683+0000] {processor.py:161} INFO - Started process (PID=383) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:52:41.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:52:41.692+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:52:41.691+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:52:44.396+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:52:44.330+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:52:44.408+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:52:44.532+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.862 seconds
[2025-06-02T09:53:15.610+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:53:15.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:53:15.618+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:53:15.617+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:53:17.369+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:53:17.359+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:53:17.371+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:53:17.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.828 seconds
[2025-06-02T09:53:47.924+0000] {processor.py:161} INFO - Started process (PID=413) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:53:47.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:53:47.931+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:53:47.930+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:53:49.691+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:53:49.462+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:53:49.740+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:53:49.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.943 seconds
[2025-06-02T09:54:20.579+0000] {processor.py:161} INFO - Started process (PID=425) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:54:20.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:54:20.583+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:54:20.583+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:54:21.426+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:54:21.419+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:54:21.427+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:54:21.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.887 seconds
[2025-06-02T09:54:51.733+0000] {processor.py:161} INFO - Started process (PID=443) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:54:51.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:54:51.738+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:54:51.737+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:54:53.500+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:54:53.487+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:54:53.503+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:54:53.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.871 seconds
[2025-06-02T09:55:24.682+0000] {processor.py:161} INFO - Started process (PID=455) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:55:24.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:55:24.707+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:55:24.707+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:55:25.874+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:55:25.863+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:55:25.879+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:55:25.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.317 seconds
[2025-06-02T09:55:56.337+0000] {processor.py:161} INFO - Started process (PID=473) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:55:56.339+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:55:56.343+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:55:56.342+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:55:57.197+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:55:57.189+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:55:57.198+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:55:57.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.903 seconds
[2025-06-02T09:56:30.545+0000] {processor.py:161} INFO - Started process (PID=485) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:56:30.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:56:30.662+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:56:30.661+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:56:35.166+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:56:35.156+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:56:35.168+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:56:35.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.756 seconds
[2025-06-02T09:57:05.839+0000] {processor.py:161} INFO - Started process (PID=504) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:57:05.844+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:57:05.848+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:57:05.848+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:57:09.588+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:57:09.560+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:57:09.591+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:57:09.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.836 seconds
[2025-06-02T09:57:40.379+0000] {processor.py:161} INFO - Started process (PID=522) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:57:40.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:57:40.396+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:57:40.395+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:57:42.116+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:57:42.111+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:57:42.118+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:57:42.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.785 seconds
[2025-06-02T09:58:12.953+0000] {processor.py:161} INFO - Started process (PID=534) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:58:12.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:58:12.957+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:58:12.957+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:58:15.606+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:58:15.590+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:58:15.608+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:58:15.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.745 seconds
[2025-06-02T09:58:46.278+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:58:46.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:58:46.283+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:58:46.282+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:58:47.897+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:58:47.890+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:58:47.899+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:58:47.930+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.663 seconds
[2025-06-02T09:59:18.214+0000] {processor.py:161} INFO - Started process (PID=564) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:59:18.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:59:18.221+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:59:18.220+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:59:20.937+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:59:20.931+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:59:20.938+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:59:20.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.785 seconds
[2025-06-02T09:59:51.119+0000] {processor.py:161} INFO - Started process (PID=582) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:59:51.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T09:59:51.124+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:59:51.124+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:59:53.572+0000] {logging_mixin.py:188} INFO - [2025-06-02T09:59:53.565+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T09:59:53.574+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T09:59:53.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.504 seconds
[2025-06-02T10:00:24.454+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:00:24.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:00:24.495+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:00:24.494+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:00:27.840+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:00:27.832+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:00:27.843+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:00:27.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.468 seconds
[2025-06-02T10:00:58.410+0000] {processor.py:161} INFO - Started process (PID=613) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:00:58.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:00:58.418+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:00:58.417+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:01:00.653+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:01:00.644+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:01:00.654+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:01:00.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.334 seconds
[2025-06-02T10:01:31.258+0000] {processor.py:161} INFO - Started process (PID=625) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:01:31.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:01:31.269+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:01:31.268+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:01:32.987+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:01:32.982+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:01:32.988+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:01:33.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.777 seconds
[2025-06-02T10:02:03.387+0000] {processor.py:161} INFO - Started process (PID=643) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:02:03.389+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:02:03.394+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:02:03.393+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:02:07.434+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:02:06.928+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:02:07.446+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:02:07.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.195 seconds
[2025-06-02T10:02:38.310+0000] {processor.py:161} INFO - Started process (PID=661) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:02:38.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:02:38.351+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:02:38.350+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:02:41.309+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:02:41.301+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:02:41.310+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:02:41.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.065 seconds
[2025-06-02T10:03:11.910+0000] {processor.py:161} INFO - Started process (PID=673) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:03:11.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:03:11.933+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:03:11.932+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:03:13.781+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:03:13.776+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:03:13.783+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:03:13.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.931 seconds
[2025-06-02T10:03:45.036+0000] {processor.py:161} INFO - Started process (PID=691) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:03:45.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:03:45.045+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:03:45.044+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:03:47.085+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:03:47.078+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:03:47.087+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:03:47.123+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.090 seconds
[2025-06-02T10:04:17.914+0000] {processor.py:161} INFO - Started process (PID=703) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:04:17.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:04:17.940+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:04:17.939+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:04:22.297+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:04:22.287+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:04:22.301+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:04:22.359+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.465 seconds
[2025-06-02T10:04:52.564+0000] {processor.py:161} INFO - Started process (PID=721) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:04:52.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:04:52.571+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:04:52.570+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:04:53.864+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:04:53.855+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:04:53.865+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:04:53.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.346 seconds
[2025-06-02T10:05:24.534+0000] {processor.py:161} INFO - Started process (PID=736) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:05:24.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:05:24.552+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:05:24.551+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:05:29.469+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:05:29.460+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:05:29.472+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:05:29.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.022 seconds
[2025-06-02T10:06:00.018+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:06:00.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:06:00.054+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:06:00.053+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:06:02.875+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:06:02.867+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:06:02.877+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:06:02.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.939 seconds
[2025-06-02T10:06:33.919+0000] {processor.py:161} INFO - Started process (PID=775) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:06:33.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:06:33.925+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:06:33.924+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:06:35.054+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:06:35.048+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:06:35.055+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:06:35.099+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.201 seconds
[2025-06-02T10:07:05.564+0000] {processor.py:161} INFO - Started process (PID=785) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:07:05.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:07:05.573+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:07:05.572+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:07:07.845+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:07:07.835+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:07:07.847+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:07:07.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.336 seconds
[2025-06-02T10:07:38.773+0000] {processor.py:161} INFO - Started process (PID=803) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:07:38.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:07:38.781+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:07:38.780+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:07:42.996+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:07:42.838+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:07:43.013+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:07:43.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.462 seconds
[2025-06-02T10:08:13.989+0000] {processor.py:161} INFO - Started process (PID=817) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:08:14.068+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:08:14.073+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:08:14.072+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:08:18.049+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:08:18.041+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:08:18.051+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:08:18.107+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.081 seconds
[2025-06-02T10:08:48.410+0000] {processor.py:161} INFO - Started process (PID=835) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:08:48.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:08:48.418+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:08:48.417+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:08:50.859+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:08:50.843+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:08:50.861+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:08:50.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.569 seconds
[2025-06-02T10:09:21.447+0000] {processor.py:161} INFO - Started process (PID=847) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:09:21.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:09:21.453+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:09:21.452+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:09:23.237+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:09:23.202+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:09:23.263+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:09:23.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.963 seconds
[2025-06-02T10:09:54.490+0000] {processor.py:161} INFO - Started process (PID=865) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:09:54.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:09:54.496+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:09:54.495+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:09:55.852+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:09:55.844+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:09:55.858+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:09:55.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.449 seconds
[2025-06-02T10:10:26.377+0000] {processor.py:161} INFO - Started process (PID=877) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:10:26.378+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:10:26.385+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:10:26.384+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:10:27.794+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:10:27.789+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:10:27.796+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:10:27.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.466 seconds
[2025-06-02T10:10:58.512+0000] {processor.py:161} INFO - Started process (PID=895) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:10:58.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:10:58.517+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:10:58.517+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:11:00.594+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:11:00.586+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:11:00.595+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:11:00.636+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.134 seconds
[2025-06-02T10:11:30.960+0000] {processor.py:161} INFO - Started process (PID=907) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:11:30.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:11:30.977+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:11:30.976+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:11:36.249+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:11:36.125+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:11:36.251+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:11:36.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.416 seconds
[2025-06-02T10:12:06.600+0000] {processor.py:161} INFO - Started process (PID=925) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:12:06.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:12:06.608+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:12:06.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:12:08.731+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:12:08.724+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:12:08.732+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:12:08.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.206 seconds
[2025-06-02T10:12:38.944+0000] {processor.py:161} INFO - Started process (PID=943) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:12:38.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:12:38.950+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:12:38.949+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:12:40.780+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:12:40.775+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:12:40.781+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:12:40.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.923 seconds
[2025-06-02T10:13:11.956+0000] {processor.py:161} INFO - Started process (PID=955) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:13:11.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:13:11.980+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:13:11.979+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:13:15.258+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:13:15.251+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:13:15.260+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:13:15.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.369 seconds
[2025-06-02T10:13:45.635+0000] {processor.py:161} INFO - Started process (PID=973) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:13:45.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:13:45.651+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:13:45.650+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:13:48.809+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:13:48.802+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:13:48.813+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:13:48.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.216 seconds
[2025-06-02T10:14:19.041+0000] {processor.py:161} INFO - Started process (PID=985) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:14:19.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:14:19.046+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:14:19.045+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:14:21.375+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:14:21.246+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:14:21.381+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:14:21.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.464 seconds
[2025-06-02T10:14:52.316+0000] {processor.py:161} INFO - Started process (PID=1003) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:14:52.318+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:14:52.322+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:14:52.321+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:14:53.506+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:14:53.499+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:14:53.508+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:14:53.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.239 seconds
[2025-06-02T10:15:24.459+0000] {processor.py:161} INFO - Started process (PID=1015) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:15:24.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:15:24.476+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:15:24.475+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:15:27.740+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:15:27.668+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:15:27.753+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:15:27.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.405 seconds
[2025-06-02T10:15:58.441+0000] {processor.py:161} INFO - Started process (PID=1033) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:15:58.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:15:58.448+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:15:58.447+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:16:00.561+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:16:00.548+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:16:00.562+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:16:00.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.172 seconds
[2025-06-02T10:16:30.902+0000] {processor.py:161} INFO - Started process (PID=1045) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:16:30.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:16:30.911+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:16:30.910+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:16:33.152+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:16:33.146+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:16:33.153+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:16:33.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.301 seconds
[2025-06-02T10:17:03.953+0000] {processor.py:161} INFO - Started process (PID=1063) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:17:03.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:17:03.982+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:17:03.971+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:17:06.555+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:17:06.547+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:17:06.557+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:17:06.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.675 seconds
[2025-06-02T10:17:37.584+0000] {processor.py:161} INFO - Started process (PID=1081) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:17:37.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:17:37.589+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:17:37.588+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:17:39.306+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:17:39.230+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:17:39.316+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:17:39.393+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.820 seconds
[2025-06-02T10:18:10.402+0000] {processor.py:161} INFO - Started process (PID=1093) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:18:10.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:18:10.410+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:18:10.409+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:18:13.064+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:18:13.052+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:18:13.065+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:18:13.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.708 seconds
[2025-06-02T10:18:43.264+0000] {processor.py:161} INFO - Started process (PID=1111) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:18:43.265+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:18:43.270+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:18:43.269+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:18:45.252+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:18:45.238+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:18:45.254+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:18:45.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.082 seconds
[2025-06-02T10:19:15.740+0000] {processor.py:161} INFO - Started process (PID=1123) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:19:15.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:19:15.756+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:19:15.756+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:19:17.893+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:19:17.887+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:19:17.895+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:19:17.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.246 seconds
[2025-06-02T10:19:48.083+0000] {processor.py:161} INFO - Started process (PID=1141) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:19:48.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:19:48.089+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:19:48.088+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:19:49.237+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:19:49.224+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:19:49.239+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:19:49.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.212 seconds
[2025-06-02T10:20:19.468+0000] {processor.py:161} INFO - Started process (PID=1153) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:20:19.470+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:20:19.477+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:20:19.477+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:20:22.377+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:20:22.158+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:20:22.379+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:20:22.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.024 seconds
[2025-06-02T10:20:53.137+0000] {processor.py:161} INFO - Started process (PID=1171) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:20:53.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:20:53.143+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:20:53.142+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:20:54.960+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:20:54.953+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:20:54.963+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:20:55.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.884 seconds
[2025-06-02T10:21:25.583+0000] {processor.py:161} INFO - Started process (PID=1183) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:21:25.598+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:21:25.611+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:21:25.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:21:28.373+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:21:28.361+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:21:28.376+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:21:28.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.889 seconds
[2025-06-02T10:21:58.896+0000] {processor.py:161} INFO - Started process (PID=1201) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:21:58.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:21:58.910+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:21:58.909+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:22:00.186+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:22:00.161+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:22:00.187+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:22:00.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.347 seconds
[2025-06-02T10:22:30.767+0000] {processor.py:161} INFO - Started process (PID=1213) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:22:30.768+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:22:30.771+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:22:30.771+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:22:31.882+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:22:31.877+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:22:31.883+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:22:31.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.171 seconds
[2025-06-02T10:23:03.343+0000] {processor.py:161} INFO - Started process (PID=1231) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:23:03.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:23:03.359+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:23:03.358+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:23:04.995+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:23:04.990+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:23:04.996+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:23:05.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.725 seconds
[2025-06-02T10:23:35.695+0000] {processor.py:161} INFO - Started process (PID=1243) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:23:35.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:23:35.701+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:23:35.701+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:23:36.724+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:23:36.719+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:23:36.725+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:23:36.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.075 seconds
[2025-06-02T10:24:07.119+0000] {processor.py:161} INFO - Started process (PID=1260) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:24:07.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:24:07.125+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:24:07.124+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:24:08.803+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:24:08.797+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:24:08.804+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:24:08.839+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.730 seconds
[2025-06-02T10:24:39.690+0000] {processor.py:161} INFO - Started process (PID=1278) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:24:39.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:24:39.707+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:24:39.706+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:24:40.988+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:24:40.982+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:24:40.989+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:24:41.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.344 seconds
[2025-06-02T10:25:11.700+0000] {processor.py:161} INFO - Started process (PID=1290) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:25:11.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:25:11.707+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:25:11.706+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:25:13.637+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:25:13.621+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:25:13.639+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:25:13.752+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.069 seconds
[2025-06-02T10:25:43.871+0000] {processor.py:161} INFO - Started process (PID=1308) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:25:43.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:25:43.878+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:25:43.877+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:25:44.917+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:25:44.911+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:25:44.919+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:25:44.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.104 seconds
[2025-06-02T10:26:16.021+0000] {processor.py:161} INFO - Started process (PID=1320) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:26:16.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:26:16.036+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:26:16.035+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:26:17.654+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:26:17.645+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:26:17.657+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:26:17.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.725 seconds
[2025-06-02T10:26:48.278+0000] {processor.py:161} INFO - Started process (PID=1338) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:26:48.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:26:48.284+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:26:48.283+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:26:49.578+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:26:49.571+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:26:49.579+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:26:49.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.341 seconds
[2025-06-02T10:27:20.255+0000] {processor.py:161} INFO - Started process (PID=1350) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:27:20.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:27:20.261+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:27:20.261+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:27:22.272+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:27:22.265+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:27:22.274+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:27:22.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.081 seconds
[2025-06-02T10:27:52.961+0000] {processor.py:161} INFO - Started process (PID=1367) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:27:52.963+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:27:52.968+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:27:52.967+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:27:54.005+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:27:53.993+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:27:54.007+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:27:54.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.151 seconds
[2025-06-02T10:28:24.516+0000] {processor.py:161} INFO - Started process (PID=1379) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:28:24.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:28:24.521+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:28:24.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:28:25.892+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:28:25.882+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:28:25.893+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:28:25.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.426 seconds
[2025-06-02T10:28:56.330+0000] {processor.py:161} INFO - Started process (PID=1396) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:28:56.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:28:56.335+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:28:56.335+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:28:57.558+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:28:57.552+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:28:57.559+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:28:57.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.271 seconds
[2025-06-02T10:29:27.809+0000] {processor.py:161} INFO - Started process (PID=1408) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:29:27.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:29:27.814+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:29:27.814+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:29:30.523+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:29:30.513+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:29:30.530+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:29:30.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.780 seconds
[2025-06-02T10:30:01.763+0000] {processor.py:161} INFO - Started process (PID=1426) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:30:01.775+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:30:01.789+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:30:01.788+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:30:04.815+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:30:04.807+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:30:04.817+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:30:04.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.124 seconds
[2025-06-02T10:30:35.171+0000] {processor.py:161} INFO - Started process (PID=1438) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:30:35.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:30:35.200+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:30:35.199+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:30:37.519+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:30:37.512+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:30:37.520+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:30:37.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.424 seconds
[2025-06-02T10:31:08.365+0000] {processor.py:161} INFO - Started process (PID=1456) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:31:08.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:31:08.372+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:31:08.370+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:31:10.206+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:31:10.125+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:31:10.223+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:31:10.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.968 seconds
[2025-06-02T10:31:40.875+0000] {processor.py:161} INFO - Started process (PID=1474) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:31:40.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:31:40.882+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:31:40.881+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:31:43.383+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:31:43.233+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:31:43.389+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:31:43.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.636 seconds
[2025-06-02T10:32:14.029+0000] {processor.py:161} INFO - Started process (PID=1486) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:32:14.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:32:14.038+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:32:14.037+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:32:17.978+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:32:17.896+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:32:17.980+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:32:18.073+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.062 seconds
[2025-06-02T10:32:48.686+0000] {processor.py:161} INFO - Started process (PID=1504) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:32:48.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:32:48.692+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:32:48.691+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:32:50.501+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:32:50.485+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:32:50.503+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:32:50.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.883 seconds
[2025-06-02T10:33:20.907+0000] {processor.py:161} INFO - Started process (PID=1516) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:33:20.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:33:20.912+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:33:20.912+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:33:23.757+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:33:23.738+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:33:23.758+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:33:23.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.956 seconds
[2025-06-02T10:33:54.150+0000] {processor.py:161} INFO - Started process (PID=1534) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:33:54.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:33:54.156+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:33:54.155+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:33:55.474+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:33:55.466+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:33:55.475+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:33:55.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.383 seconds
[2025-06-02T10:34:25.760+0000] {processor.py:161} INFO - Started process (PID=1546) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:34:25.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:34:25.780+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:34:25.779+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:34:27.764+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:34:27.759+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:34:27.765+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:34:27.810+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.083 seconds
[2025-06-02T10:34:58.170+0000] {processor.py:161} INFO - Started process (PID=1564) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:34:58.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:34:58.177+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:34:58.176+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:34:59.221+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:34:59.216+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:34:59.223+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:34:59.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.100 seconds
[2025-06-02T10:35:29.524+0000] {processor.py:161} INFO - Started process (PID=1576) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:35:29.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:35:29.530+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:35:29.529+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:35:32.478+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:35:32.468+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:35:32.480+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:35:32.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.021 seconds
[2025-06-02T10:36:03.454+0000] {processor.py:161} INFO - Started process (PID=1594) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:36:03.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:36:03.459+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:36:03.459+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:36:05.026+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:36:05.018+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:36:05.029+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:36:05.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.649 seconds
[2025-06-02T10:36:35.564+0000] {processor.py:161} INFO - Started process (PID=1606) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:36:35.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:36:35.568+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:36:35.568+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:36:37.599+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:36:37.580+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:36:37.601+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:36:37.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.090 seconds
[2025-06-02T10:37:07.929+0000] {processor.py:161} INFO - Started process (PID=1624) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:37:07.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:37:07.933+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:37:07.932+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:37:09.408+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:37:09.397+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:37:09.410+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:37:09.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.556 seconds
[2025-06-02T10:37:39.931+0000] {processor.py:161} INFO - Started process (PID=1642) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:37:39.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:37:39.942+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:37:39.940+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:37:41.101+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:37:41.095+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:37:41.102+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:37:41.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.214 seconds
[2025-06-02T10:38:11.405+0000] {processor.py:161} INFO - Started process (PID=1654) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:38:11.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:38:11.413+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:38:11.412+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:38:12.895+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:38:12.886+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:38:12.897+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:38:12.940+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.550 seconds
[2025-06-02T10:38:43.465+0000] {processor.py:161} INFO - Started process (PID=1672) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:38:43.467+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:38:43.470+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:38:43.469+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:38:44.213+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:38:44.206+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:38:44.214+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:38:44.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.797 seconds
[2025-06-02T10:39:14.949+0000] {processor.py:161} INFO - Started process (PID=1684) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:39:14.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:39:14.962+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:39:14.961+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:39:15.986+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:39:15.978+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:39:15.990+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:39:16.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.106 seconds
[2025-06-02T10:39:46.590+0000] {processor.py:161} INFO - Started process (PID=1702) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:39:46.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:39:46.595+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:39:46.594+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:39:48.020+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:39:48.013+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:39:48.021+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:39:48.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.477 seconds
[2025-06-02T10:40:18.317+0000] {processor.py:161} INFO - Started process (PID=1714) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:40:18.318+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:40:18.324+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:40:18.324+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:40:19.287+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:40:19.280+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:40:19.289+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:40:19.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.015 seconds
[2025-06-02T10:40:49.925+0000] {processor.py:161} INFO - Started process (PID=1732) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:40:49.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:40:49.932+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:40:49.931+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:40:51.043+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:40:51.037+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:40:51.045+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:40:51.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.181 seconds
[2025-06-02T10:41:21.353+0000] {processor.py:161} INFO - Started process (PID=1744) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:41:21.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:41:21.359+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:41:21.358+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:41:23.098+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:41:23.078+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:41:23.100+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:41:23.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.804 seconds
[2025-06-02T10:41:54.268+0000] {processor.py:161} INFO - Started process (PID=1762) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:41:54.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:41:54.285+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:41:54.276+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:41:55.955+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:41:55.935+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:41:55.970+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:41:56.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.878 seconds
[2025-06-02T10:42:26.277+0000] {processor.py:161} INFO - Started process (PID=1774) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:42:26.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:42:26.284+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:42:26.283+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:42:28.024+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:42:28.013+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:42:28.028+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:42:28.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.797 seconds
[2025-06-02T10:42:58.733+0000] {processor.py:161} INFO - Started process (PID=1792) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:42:58.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:42:58.743+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:42:58.742+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:43:01.066+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:43:01.057+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:43:01.068+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:43:01.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.467 seconds
[2025-06-02T10:43:31.623+0000] {processor.py:161} INFO - Started process (PID=1808) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:43:31.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:43:31.629+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:43:31.628+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:43:33.659+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:43:33.649+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:43:33.670+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:43:33.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.137 seconds
[2025-06-02T10:44:04.363+0000] {processor.py:161} INFO - Started process (PID=1826) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:44:04.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:44:04.372+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:44:04.371+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:44:12.605+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:44:12.584+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:44:12.690+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:44:12.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 8.517 seconds
[2025-06-02T10:44:43.780+0000] {processor.py:161} INFO - Started process (PID=1846) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:44:43.788+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:44:43.803+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:44:43.802+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:44:45.024+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:44:45.015+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:44:45.026+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:44:45.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.357 seconds
[2025-06-02T10:45:15.764+0000] {processor.py:161} INFO - Started process (PID=1858) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:45:15.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:45:15.769+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:45:15.769+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:45:17.280+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:45:17.274+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:45:17.282+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:45:17.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.561 seconds
[2025-06-02T10:45:47.613+0000] {processor.py:161} INFO - Started process (PID=1876) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:45:47.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:45:47.617+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:45:47.617+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:45:48.506+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:45:48.499+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:45:48.508+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:45:48.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.937 seconds
[2025-06-02T10:46:19.175+0000] {processor.py:161} INFO - Started process (PID=1888) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:46:19.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:46:19.213+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:46:19.213+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:46:20.072+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:46:20.064+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:46:20.073+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:46:20.122+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.975 seconds
[2025-06-02T10:46:50.549+0000] {processor.py:161} INFO - Started process (PID=1906) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:46:50.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:46:50.558+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:46:50.557+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:46:51.730+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:46:51.723+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:46:51.731+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:46:51.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.235 seconds
[2025-06-02T10:47:22.250+0000] {processor.py:161} INFO - Started process (PID=1918) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:47:22.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:47:22.256+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:47:22.256+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:47:23.771+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:47:23.758+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:47:23.772+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:47:23.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.623 seconds
[2025-06-02T10:47:54.254+0000] {processor.py:161} INFO - Started process (PID=1935) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:47:54.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:47:54.286+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:47:54.285+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:47:55.450+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:47:55.442+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:47:55.452+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:47:55.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.299 seconds
[2025-06-02T10:48:25.877+0000] {processor.py:161} INFO - Started process (PID=1947) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:48:25.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:48:25.882+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:48:25.882+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:48:27.295+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:48:27.288+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:48:27.296+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:48:27.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.469 seconds
[2025-06-02T10:48:57.483+0000] {processor.py:161} INFO - Started process (PID=1965) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:48:57.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:48:57.489+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:48:57.489+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:48:58.705+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:48:58.696+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:48:58.706+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:48:58.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.273 seconds
[2025-06-02T10:49:29.652+0000] {processor.py:161} INFO - Started process (PID=1977) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:49:29.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:49:29.672+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:49:29.671+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:49:31.583+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:49:31.574+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:49:31.585+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:49:31.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.029 seconds
[2025-06-02T10:50:02.056+0000] {processor.py:161} INFO - Started process (PID=1996) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:50:02.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:50:02.063+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:50:02.062+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:50:03.547+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:50:03.541+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:50:03.548+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:50:03.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.547 seconds
[2025-06-02T10:50:33.735+0000] {processor.py:161} INFO - Started process (PID=2008) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:50:33.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:50:33.741+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:50:33.741+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:50:35.035+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:50:35.016+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:50:35.037+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:50:35.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.369 seconds
[2025-06-02T10:51:05.836+0000] {processor.py:161} INFO - Started process (PID=2026) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:51:05.838+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:51:05.842+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:51:05.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:51:06.683+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:51:06.676+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:51:06.684+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:51:06.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.898 seconds
[2025-06-02T10:51:37.122+0000] {processor.py:161} INFO - Started process (PID=2038) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:51:37.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:51:37.128+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:51:37.127+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:51:38.008+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:51:38.001+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:51:38.009+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:51:38.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.951 seconds
[2025-06-02T10:52:08.880+0000] {processor.py:161} INFO - Started process (PID=2056) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:52:08.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:52:08.889+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:52:08.887+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:52:10.647+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:52:10.632+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:52:10.650+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:52:10.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.032 seconds
[2025-06-02T10:52:41.303+0000] {processor.py:161} INFO - Started process (PID=2074) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:52:41.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:52:41.314+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:52:41.313+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:52:42.507+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:52:42.499+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:52:42.509+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:52:42.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.258 seconds
[2025-06-02T10:53:13.411+0000] {processor.py:161} INFO - Started process (PID=2086) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:53:13.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:53:13.417+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:53:13.416+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:53:14.463+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:53:14.456+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:53:14.464+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:53:14.511+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.114 seconds
[2025-06-02T10:53:45.186+0000] {processor.py:161} INFO - Started process (PID=2104) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:53:45.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:53:45.192+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:53:45.191+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:53:46.282+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:53:46.276+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:53:46.284+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:53:46.318+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.161 seconds
[2025-06-02T10:54:16.804+0000] {processor.py:161} INFO - Started process (PID=2116) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:54:16.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:54:16.808+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:54:16.808+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:54:18.147+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:54:18.139+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:54:18.149+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:54:18.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.398 seconds
[2025-06-02T10:54:48.828+0000] {processor.py:161} INFO - Started process (PID=2134) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:54:48.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:54:48.833+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:54:48.832+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:54:50.254+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:54:50.248+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:54:50.256+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:54:50.294+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.477 seconds
[2025-06-02T10:55:21.068+0000] {processor.py:161} INFO - Started process (PID=2146) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:55:21.070+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:55:21.074+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:55:21.073+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:55:22.304+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:55:22.297+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:55:22.306+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:55:22.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.289 seconds
[2025-06-02T10:55:52.946+0000] {processor.py:161} INFO - Started process (PID=2164) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:55:52.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:55:52.951+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:55:52.951+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:55:54.327+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:55:54.319+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:55:54.329+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:55:54.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.441 seconds
[2025-06-02T10:56:24.713+0000] {processor.py:161} INFO - Started process (PID=2176) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:56:24.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:56:24.721+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:56:24.720+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:56:26.080+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:56:26.072+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:56:26.081+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:56:26.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.426 seconds
[2025-06-02T10:56:56.426+0000] {processor.py:161} INFO - Started process (PID=2193) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:56:56.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:56:56.431+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:56:56.431+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:56:57.781+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:56:57.774+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:56:57.784+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:56:57.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.421 seconds
[2025-06-02T10:57:28.116+0000] {processor.py:161} INFO - Started process (PID=2205) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:57:28.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:57:28.120+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:57:28.120+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:57:30.242+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:57:30.227+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:57:30.247+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:57:30.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.212 seconds
[2025-06-02T10:58:00.844+0000] {processor.py:161} INFO - Started process (PID=2223) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:58:00.847+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:58:00.852+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:58:00.852+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:58:02.329+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:58:02.315+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:58:02.331+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:58:02.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.556 seconds
[2025-06-02T10:58:32.589+0000] {processor.py:161} INFO - Started process (PID=2235) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:58:32.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:58:32.595+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:58:32.594+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:58:34.365+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:58:34.355+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:58:34.369+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:58:34.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.852 seconds
[2025-06-02T10:59:05.121+0000] {processor.py:161} INFO - Started process (PID=2254) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:59:05.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:59:05.130+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:59:05.129+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:59:06.280+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:59:06.273+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:59:06.281+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:59:06.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.209 seconds
[2025-06-02T10:59:37.090+0000] {processor.py:161} INFO - Started process (PID=2266) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:59:37.092+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T10:59:37.096+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:59:37.096+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:59:38.275+0000] {logging_mixin.py:188} INFO - [2025-06-02T10:59:38.233+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T10:59:38.277+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T10:59:38.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.257 seconds
[2025-06-02T11:00:08.897+0000] {processor.py:161} INFO - Started process (PID=2284) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:00:08.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:00:08.904+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:00:08.903+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:00:10.821+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:00:10.797+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:00:10.826+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:00:10.909+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.029 seconds
[2025-06-02T11:00:41.854+0000] {processor.py:161} INFO - Started process (PID=2302) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:00:41.865+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:00:41.871+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:00:41.869+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:00:43.287+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:00:43.277+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:00:43.288+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:00:43.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.515 seconds
[2025-06-02T11:01:13.472+0000] {processor.py:161} INFO - Started process (PID=2314) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:01:13.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:01:13.479+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:01:13.478+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:01:14.759+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:01:14.753+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:01:14.761+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:01:14.788+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.331 seconds
[2025-06-02T11:01:45.235+0000] {processor.py:161} INFO - Started process (PID=2332) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:01:45.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:01:45.240+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:01:45.239+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:01:46.456+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:01:46.448+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:01:46.458+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:01:46.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.281 seconds
[2025-06-02T11:02:17.026+0000] {processor.py:161} INFO - Started process (PID=2344) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:02:17.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:02:17.038+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:02:17.038+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:02:18.624+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:02:18.618+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:02:18.626+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:02:18.664+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.662 seconds
[2025-06-02T11:02:49.075+0000] {processor.py:161} INFO - Started process (PID=2362) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:02:49.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:02:49.090+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:02:49.089+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:02:50.853+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:02:50.841+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:02:50.855+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:02:50.891+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.834 seconds
[2025-06-02T11:03:21.082+0000] {processor.py:161} INFO - Started process (PID=2374) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:03:21.088+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:03:21.095+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:03:21.093+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:03:22.756+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:03:22.717+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:03:22.761+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:03:22.892+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.845 seconds
[2025-06-02T11:03:53.542+0000] {processor.py:161} INFO - Started process (PID=2392) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:03:53.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:03:53.547+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:03:53.547+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:03:54.593+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:03:54.586+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:03:54.594+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:03:54.625+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.099 seconds
[2025-06-02T11:04:25.444+0000] {processor.py:161} INFO - Started process (PID=2404) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:04:25.446+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:04:25.451+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:04:25.450+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:04:26.980+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:04:26.971+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:04:26.982+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:04:27.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.584 seconds
[2025-06-02T11:04:57.299+0000] {processor.py:161} INFO - Started process (PID=2422) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:04:57.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:04:57.305+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:04:57.304+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:04:58.686+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:04:58.679+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:04:58.688+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:04:58.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.437 seconds
[2025-06-02T11:05:29.344+0000] {processor.py:161} INFO - Started process (PID=2434) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:05:29.346+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:05:29.351+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:05:29.350+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:05:30.972+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:05:30.964+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:05:30.973+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:05:31.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.683 seconds
[2025-06-02T11:06:01.296+0000] {processor.py:161} INFO - Started process (PID=2451) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:06:01.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:06:01.303+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:06:01.302+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:06:02.470+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:06:02.463+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:06:02.471+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:06:02.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.253 seconds
[2025-06-02T11:06:33.001+0000] {processor.py:161} INFO - Started process (PID=2463) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:06:33.003+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:06:33.007+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:06:33.006+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:06:34.281+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:06:34.275+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:06:34.283+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:06:34.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.325 seconds
[2025-06-02T11:07:04.986+0000] {processor.py:161} INFO - Started process (PID=2481) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:07:04.988+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:07:04.991+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:07:04.990+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:07:06.013+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:07:06.006+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:07:06.015+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:07:06.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.084 seconds
[2025-06-02T11:07:36.628+0000] {processor.py:161} INFO - Started process (PID=2493) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:07:36.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:07:36.633+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:07:36.632+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:07:37.718+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:07:37.711+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:07:37.719+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:07:37.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.136 seconds
[2025-06-02T11:08:08.125+0000] {processor.py:161} INFO - Started process (PID=2512) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:08:08.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:08:08.134+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:08:08.133+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:08:09.204+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:08:09.195+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:08:09.206+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:08:09.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.210 seconds
[2025-06-02T11:08:40.281+0000] {processor.py:161} INFO - Started process (PID=2524) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:08:40.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:08:40.324+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:08:40.323+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:08:41.620+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:08:41.614+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:08:41.621+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:08:41.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.420 seconds
[2025-06-02T11:09:12.600+0000] {processor.py:161} INFO - Started process (PID=2542) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:09:12.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:09:12.615+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:09:12.614+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:09:13.942+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:09:13.936+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:09:13.944+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:09:13.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.406 seconds
[2025-06-02T11:09:44.560+0000] {processor.py:161} INFO - Started process (PID=2559) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:09:44.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:09:44.571+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:09:44.570+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:09:45.803+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:09:45.797+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:09:45.804+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:09:45.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.311 seconds
[2025-06-02T11:10:16.553+0000] {processor.py:161} INFO - Started process (PID=2571) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:10:16.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:10:16.559+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:10:16.558+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:10:17.908+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:10:17.899+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:10:17.910+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:10:17.956+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.418 seconds
[2025-06-02T11:10:48.511+0000] {processor.py:161} INFO - Started process (PID=2589) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:10:48.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:10:48.516+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:10:48.515+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:10:50.116+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:10:50.093+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:10:50.118+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:10:50.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.701 seconds
[2025-06-02T11:11:20.872+0000] {processor.py:161} INFO - Started process (PID=2601) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:11:20.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:11:20.877+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:11:20.876+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:11:22.186+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:11:22.177+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:11:22.187+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:11:22.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.360 seconds
[2025-06-02T11:11:52.726+0000] {processor.py:161} INFO - Started process (PID=2619) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:11:52.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:11:52.732+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:11:52.731+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:11:54.038+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:11:54.031+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:11:54.040+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:11:54.073+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.359 seconds
[2025-06-02T11:12:24.258+0000] {processor.py:161} INFO - Started process (PID=2631) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:12:24.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:12:24.263+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:12:24.262+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:12:25.814+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:12:25.567+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:12:25.822+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:12:25.890+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.643 seconds
[2025-06-02T11:12:56.500+0000] {processor.py:161} INFO - Started process (PID=2649) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:12:56.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:12:56.507+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:12:56.506+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:12:57.555+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:12:57.550+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:12:57.557+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:12:57.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.099 seconds
[2025-06-02T11:13:28.082+0000] {processor.py:161} INFO - Started process (PID=2661) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:13:28.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:13:28.087+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:13:28.087+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:13:30.740+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:13:30.686+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:13:30.744+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:13:30.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.763 seconds
[2025-06-02T11:14:01.457+0000] {processor.py:161} INFO - Started process (PID=2679) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:14:01.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:14:01.463+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:14:01.462+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:14:02.965+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:14:02.957+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:14:02.966+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:14:03.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.557 seconds
[2025-06-02T11:14:33.649+0000] {processor.py:161} INFO - Started process (PID=2691) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:14:33.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:14:33.655+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:14:33.654+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:14:35.464+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:14:35.455+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:14:35.467+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:14:35.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.872 seconds
[2025-06-02T11:15:06.311+0000] {processor.py:161} INFO - Started process (PID=2709) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:15:06.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:15:06.316+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:15:06.316+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:15:07.719+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:15:07.712+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:15:07.720+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:15:07.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.474 seconds
[2025-06-02T11:15:38.341+0000] {processor.py:161} INFO - Started process (PID=2721) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:15:38.347+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:15:38.352+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:15:38.351+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:15:40.571+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:15:40.560+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:15:40.574+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:15:40.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.325 seconds
[2025-06-02T11:16:11.142+0000] {processor.py:161} INFO - Started process (PID=2739) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:16:11.154+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:16:11.162+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:16:11.161+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:16:12.513+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:16:12.506+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:16:12.514+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:16:12.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.443 seconds
[2025-06-02T11:16:42.680+0000] {processor.py:161} INFO - Started process (PID=2757) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:16:42.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:16:42.689+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:16:42.689+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:16:44.342+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:16:44.336+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:16:44.343+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:16:44.392+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.727 seconds
[2025-06-02T11:17:14.578+0000] {processor.py:161} INFO - Started process (PID=2769) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:17:14.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:17:14.585+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:17:14.585+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:17:16.142+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:17:16.135+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:17:16.144+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:17:16.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.618 seconds
[2025-06-02T11:17:46.830+0000] {processor.py:161} INFO - Started process (PID=2787) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:17:46.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:17:46.838+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:17:46.837+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:17:48.572+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:17:48.565+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:17:48.573+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:17:48.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.813 seconds
[2025-06-02T11:18:19.328+0000] {processor.py:161} INFO - Started process (PID=2799) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:18:19.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:18:19.346+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:18:19.337+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:18:21.670+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:18:21.661+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:18:21.672+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:18:21.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.417 seconds
[2025-06-02T11:18:52.349+0000] {processor.py:161} INFO - Started process (PID=2817) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:18:52.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:18:52.366+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:18:52.364+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:18:53.778+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:18:53.769+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:18:53.780+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:18:53.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.606 seconds
[2025-06-02T11:19:24.562+0000] {processor.py:161} INFO - Started process (PID=2829) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:19:24.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:19:24.568+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:19:24.568+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:19:26.678+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:19:26.670+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:19:26.680+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:19:26.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.181 seconds
[2025-06-02T11:19:56.960+0000] {processor.py:161} INFO - Started process (PID=2847) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:19:56.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:19:56.967+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:19:56.966+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:19:58.385+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:19:58.376+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:19:58.387+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:19:58.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.499 seconds
[2025-06-02T11:20:29.277+0000] {processor.py:161} INFO - Started process (PID=2859) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:20:29.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:20:29.284+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:20:29.283+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:20:33.185+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:20:32.964+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:20:33.188+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:20:33.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.975 seconds
[2025-06-02T11:21:03.881+0000] {processor.py:161} INFO - Started process (PID=2877) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:21:03.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:21:03.900+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:21:03.899+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:21:05.521+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:21:05.514+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:21:05.522+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:21:05.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.728 seconds
[2025-06-02T11:21:36.669+0000] {processor.py:161} INFO - Started process (PID=2889) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:21:36.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:21:36.691+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:21:36.689+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:21:38.816+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:21:38.810+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:21:38.818+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:21:38.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.215 seconds
[2025-06-02T11:22:09.278+0000] {processor.py:161} INFO - Started process (PID=2907) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:22:09.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:22:09.338+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:22:09.337+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:22:11.467+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:22:11.460+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:22:11.468+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:22:11.502+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.259 seconds
[2025-06-02T11:22:41.798+0000] {processor.py:161} INFO - Started process (PID=2919) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:22:41.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:22:41.803+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:22:41.802+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:22:44.250+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:22:44.239+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:22:44.253+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:22:44.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.523 seconds
[2025-06-02T11:23:14.600+0000] {processor.py:161} INFO - Started process (PID=2937) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:23:14.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:23:14.605+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:23:14.604+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:23:16.054+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:23:16.047+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:23:16.055+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:23:16.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.500 seconds
[2025-06-02T11:23:46.731+0000] {processor.py:161} INFO - Started process (PID=2955) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:23:46.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:23:46.736+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:23:46.736+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:23:48.824+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:23:48.814+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:23:48.826+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:23:48.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.161 seconds
[2025-06-02T11:24:19.263+0000] {processor.py:161} INFO - Started process (PID=2967) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:24:19.265+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:24:19.270+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:24:19.269+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:24:20.615+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:24:20.605+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:24:20.616+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:24:20.650+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.402 seconds
[2025-06-02T11:24:50.943+0000] {processor.py:161} INFO - Started process (PID=2985) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:24:50.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:24:50.960+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:24:50.959+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:24:52.543+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:24:52.529+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:24:52.544+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:24:52.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.661 seconds
[2025-06-02T11:25:23.324+0000] {processor.py:161} INFO - Started process (PID=2997) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:25:23.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:25:23.329+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:25:23.329+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:25:24.760+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:25:24.754+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:25:24.761+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:25:24.805+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.493 seconds
[2025-06-02T11:25:55.172+0000] {processor.py:161} INFO - Started process (PID=3015) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:25:55.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:25:55.188+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:25:55.187+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:25:58.041+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:25:58.034+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:25:58.043+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:25:58.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.975 seconds
[2025-06-02T11:26:28.435+0000] {processor.py:161} INFO - Started process (PID=3027) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:26:28.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:26:28.440+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:26:28.440+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:26:29.741+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:26:29.733+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:26:29.743+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:26:29.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.361 seconds
[2025-06-02T11:26:59.946+0000] {processor.py:161} INFO - Started process (PID=3045) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:26:59.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:26:59.952+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:26:59.951+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:27:02.400+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:27:02.390+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:27:02.402+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:27:02.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.519 seconds
[2025-06-02T11:27:33.436+0000] {processor.py:161} INFO - Started process (PID=3057) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:27:33.442+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:27:33.459+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:27:33.458+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:27:35.019+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:27:35.011+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:27:35.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:27:35.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.652 seconds
[2025-06-02T11:28:05.853+0000] {processor.py:161} INFO - Started process (PID=3074) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:28:05.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:28:05.860+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:28:05.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:28:07.875+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:28:07.867+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:28:07.877+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:28:07.933+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.092 seconds
[2025-06-02T11:28:38.662+0000] {processor.py:161} INFO - Started process (PID=3086) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:28:38.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:28:38.669+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:28:38.668+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:28:39.883+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:28:39.876+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:28:39.884+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:28:39.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.271 seconds
[2025-06-02T11:29:10.500+0000] {processor.py:161} INFO - Started process (PID=3104) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:29:10.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:29:10.506+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:29:10.506+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:29:12.818+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:29:12.810+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:29:12.820+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:29:12.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.366 seconds
[2025-06-02T11:29:43.840+0000] {processor.py:161} INFO - Started process (PID=3116) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:29:43.843+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:29:43.855+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:29:43.853+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:29:45.380+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:29:45.373+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:29:45.381+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:29:45.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.599 seconds
[2025-06-02T11:30:16.129+0000] {processor.py:161} INFO - Started process (PID=3134) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:30:16.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:30:16.151+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:30:16.150+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:30:17.454+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:30:17.448+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:30:17.456+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:30:17.494+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.401 seconds
[2025-06-02T11:30:47.824+0000] {processor.py:161} INFO - Started process (PID=3152) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:30:47.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:30:47.831+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:30:47.830+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:30:49.443+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:30:49.437+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:30:49.444+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:30:49.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.679 seconds
[2025-06-02T11:31:20.492+0000] {processor.py:161} INFO - Started process (PID=3164) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:31:20.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:31:20.506+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:31:20.503+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:31:22.513+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:31:22.505+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:31:22.514+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:31:22.556+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.106 seconds
[2025-06-02T11:31:52.914+0000] {processor.py:161} INFO - Started process (PID=3182) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:31:52.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:31:52.919+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:31:52.918+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:31:54.496+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:31:54.487+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:31:54.498+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:31:54.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.642 seconds
[2025-06-02T11:32:24.900+0000] {processor.py:161} INFO - Started process (PID=3194) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:32:24.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:32:24.908+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:32:24.907+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:32:25.953+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:32:25.941+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:32:25.955+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:32:25.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.108 seconds
[2025-06-02T11:32:56.582+0000] {processor.py:161} INFO - Started process (PID=3212) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:32:56.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:32:56.592+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:32:56.591+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:32:58.185+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:32:58.178+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:32:58.187+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:32:58.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.674 seconds
[2025-06-02T11:33:29.149+0000] {processor.py:161} INFO - Started process (PID=3224) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:33:29.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:33:29.159+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:33:29.159+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:33:30.551+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:33:30.539+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:33:30.552+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:33:30.615+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.528 seconds
[2025-06-02T11:34:01.106+0000] {processor.py:161} INFO - Started process (PID=3242) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:34:01.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:34:01.112+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:34:01.111+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:34:02.630+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:34:02.623+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:34:02.631+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:34:02.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.575 seconds
[2025-06-02T11:34:33.131+0000] {processor.py:161} INFO - Started process (PID=3254) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:34:33.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:34:33.138+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:34:33.138+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:34:34.855+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:34:34.847+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:34:34.856+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:34:34.904+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.798 seconds
[2025-06-02T11:35:05.472+0000] {processor.py:161} INFO - Started process (PID=3272) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:35:05.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:35:05.479+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:35:05.478+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:35:06.818+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:35:06.811+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:35:06.819+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:35:06.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.406 seconds
[2025-06-02T11:35:37.390+0000] {processor.py:161} INFO - Started process (PID=3284) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:35:37.393+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:35:37.398+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:35:37.397+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:35:38.750+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:35:38.730+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:35:38.752+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:35:38.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.423 seconds
[2025-06-02T11:36:08.903+0000] {processor.py:161} INFO - Started process (PID=3302) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:36:08.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:36:08.909+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:36:08.908+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:36:10.191+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:36:10.183+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:36:10.193+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:36:10.237+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.345 seconds
[2025-06-02T11:36:40.763+0000] {processor.py:161} INFO - Started process (PID=3314) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:36:40.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:36:40.768+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:36:40.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:36:42.331+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:36:42.324+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:36:42.333+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:36:42.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.627 seconds
[2025-06-02T11:37:13.105+0000] {processor.py:161} INFO - Started process (PID=3332) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:37:13.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:37:13.113+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:37:13.112+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:37:16.039+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:37:16.029+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:37:16.042+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:37:16.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.004 seconds
[2025-06-02T11:37:46.548+0000] {processor.py:161} INFO - Started process (PID=3350) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:37:46.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:37:46.562+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:37:46.560+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:37:48.052+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:37:48.046+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:37:48.054+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:37:48.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.549 seconds
[2025-06-02T11:38:18.715+0000] {processor.py:161} INFO - Started process (PID=3362) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:38:18.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:38:18.723+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:38:18.722+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:38:20.738+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:38:20.698+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:38:20.740+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:38:20.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.169 seconds
[2025-06-02T11:38:51.526+0000] {processor.py:161} INFO - Started process (PID=3380) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:38:51.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:38:51.547+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:38:51.546+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:38:53.193+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:38:53.187+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:38:53.195+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:38:53.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.721 seconds
[2025-06-02T11:39:24.079+0000] {processor.py:161} INFO - Started process (PID=3392) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:39:24.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:39:24.084+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:39:24.084+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:39:26.212+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:39:26.195+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:39:26.219+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:39:26.296+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.228 seconds
[2025-06-02T11:39:56.981+0000] {processor.py:161} INFO - Started process (PID=3410) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:39:56.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:39:56.988+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:39:56.987+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:39:58.673+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:39:58.664+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:39:58.675+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:39:58.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.751 seconds
[2025-06-02T11:40:29.769+0000] {processor.py:161} INFO - Started process (PID=3422) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:40:29.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:40:29.775+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:40:29.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:40:32.634+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:40:32.625+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:40:32.636+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:40:32.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.922 seconds
[2025-06-02T11:41:03.067+0000] {processor.py:161} INFO - Started process (PID=3440) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:41:03.070+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:41:03.076+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:41:03.075+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:41:05.238+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:41:05.166+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:41:05.240+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:41:05.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.264 seconds
[2025-06-02T11:41:35.834+0000] {processor.py:161} INFO - Started process (PID=3452) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:41:35.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:41:35.856+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:41:35.856+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:41:37.481+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:41:37.469+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:41:37.483+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:41:37.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.780 seconds
[2025-06-02T11:42:08.424+0000] {processor.py:161} INFO - Started process (PID=3470) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:42:08.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:42:08.428+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:42:08.428+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:42:11.275+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:42:11.258+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:42:11.277+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:42:11.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.942 seconds
[2025-06-02T11:42:42.183+0000] {processor.py:161} INFO - Started process (PID=3482) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:42:42.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:42:42.199+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:42:42.198+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:42:44.193+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:42:44.184+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:42:44.201+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:42:44.262+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.125 seconds
[2025-06-02T11:43:14.654+0000] {processor.py:161} INFO - Started process (PID=3500) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:43:14.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:43:14.661+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:43:14.660+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:43:17.441+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:43:17.433+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:43:17.443+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:43:17.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.844 seconds
[2025-06-02T11:43:47.779+0000] {processor.py:161} INFO - Started process (PID=3518) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:43:47.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:43:47.788+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:43:47.787+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:43:49.385+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:43:49.377+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:43:49.386+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:43:49.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.691 seconds
[2025-06-02T11:44:19.694+0000] {processor.py:161} INFO - Started process (PID=3530) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:44:19.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:44:19.702+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:44:19.701+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:44:21.860+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:44:21.846+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:44:21.863+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:44:21.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.252 seconds
[2025-06-02T11:44:52.451+0000] {processor.py:161} INFO - Started process (PID=3553) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:44:52.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:44:52.458+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:44:52.457+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:44:54.406+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:44:54.396+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:44:54.408+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:44:54.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.023 seconds
[2025-06-02T11:45:24.910+0000] {processor.py:161} INFO - Started process (PID=3565) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:45:24.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:45:24.931+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:45:24.927+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:45:27.023+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:45:27.017+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:45:27.024+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:45:27.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.168 seconds
[2025-06-02T11:45:57.375+0000] {processor.py:161} INFO - Started process (PID=3583) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:45:57.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:45:57.381+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:45:57.380+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:45:58.468+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:45:58.459+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:45:58.471+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:45:58.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.243 seconds
[2025-06-02T11:46:29.191+0000] {processor.py:161} INFO - Started process (PID=3595) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:46:29.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:46:29.204+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:46:29.203+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:46:30.475+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:46:30.466+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:46:30.477+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:46:30.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.354 seconds
[2025-06-02T11:47:00.721+0000] {processor.py:161} INFO - Started process (PID=3612) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:47:00.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:47:00.727+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:47:00.726+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:47:02.535+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:47:02.529+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:47:02.537+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:47:02.563+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.861 seconds
[2025-06-02T11:47:33.025+0000] {processor.py:161} INFO - Started process (PID=3626) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:47:33.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:47:33.033+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:47:33.032+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:47:34.329+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:47:34.323+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:47:34.330+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:47:34.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.368 seconds
[2025-06-02T11:48:04.689+0000] {processor.py:161} INFO - Started process (PID=3642) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:48:04.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:48:04.710+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:48:04.709+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:48:05.990+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:48:05.959+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:48:06.003+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:48:06.097+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.447 seconds
[2025-06-02T11:48:36.580+0000] {processor.py:161} INFO - Started process (PID=3654) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:48:36.583+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:48:36.589+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:48:36.588+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:48:37.977+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:48:37.969+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:48:37.978+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:48:38.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.473 seconds
[2025-06-02T11:49:08.239+0000] {processor.py:161} INFO - Started process (PID=3671) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:49:08.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:49:08.247+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:49:08.246+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:49:09.857+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:49:09.846+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:49:09.859+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:49:09.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.697 seconds
[2025-06-02T11:49:40.577+0000] {processor.py:161} INFO - Started process (PID=3683) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:49:40.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:49:40.608+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:49:40.604+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:49:43.271+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:49:43.263+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:49:43.272+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:49:43.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.788 seconds
[2025-06-02T11:50:13.730+0000] {processor.py:161} INFO - Started process (PID=3703) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:50:13.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:50:13.736+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:50:13.735+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:50:15.079+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:50:15.070+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:50:15.081+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:50:15.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.415 seconds
[2025-06-02T11:50:45.477+0000] {processor.py:161} INFO - Started process (PID=3713) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:50:45.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:50:45.528+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:50:45.527+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:50:47.378+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:50:47.370+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:50:47.379+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:50:47.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.984 seconds
[2025-06-02T11:51:17.893+0000] {processor.py:161} INFO - Started process (PID=3730) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:51:17.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:51:17.899+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:51:17.899+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:51:19.929+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:51:19.918+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:51:19.931+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:51:19.986+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.113 seconds
[2025-06-02T11:51:50.409+0000] {processor.py:161} INFO - Started process (PID=3748) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:51:50.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:51:50.416+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:51:50.415+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:51:51.851+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:51:51.844+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:51:51.853+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:51:51.892+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.497 seconds
[2025-06-02T11:52:22.038+0000] {processor.py:161} INFO - Started process (PID=3760) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:52:22.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:52:22.044+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:52:22.043+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:52:24.363+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:52:24.358+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:52:24.364+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:52:24.398+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.374 seconds
[2025-06-02T11:52:55.028+0000] {processor.py:161} INFO - Started process (PID=3778) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:52:55.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:52:55.053+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:52:55.052+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:52:58.618+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:52:58.607+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:52:58.621+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:52:58.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.720 seconds
[2025-06-02T11:53:29.191+0000] {processor.py:161} INFO - Started process (PID=3790) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:53:29.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:53:29.224+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:53:29.223+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:53:30.900+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:53:30.891+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:53:30.902+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:53:30.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.801 seconds
[2025-06-02T11:54:01.512+0000] {processor.py:161} INFO - Started process (PID=3808) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:54:01.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:54:01.532+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:54:01.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:54:03.186+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:54:03.177+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:54:03.187+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:54:03.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.759 seconds
[2025-06-02T11:54:33.360+0000] {processor.py:161} INFO - Started process (PID=3822) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:54:33.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:54:33.365+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:54:33.364+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:54:35.423+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:54:35.413+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:54:35.425+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:54:35.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.148 seconds
[2025-06-02T11:55:06.013+0000] {processor.py:161} INFO - Started process (PID=3840) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:55:06.014+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:55:06.018+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:55:06.017+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:55:07.644+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:55:07.628+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:55:07.646+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:55:07.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.695 seconds
[2025-06-02T11:55:38.154+0000] {processor.py:161} INFO - Started process (PID=3852) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:55:38.156+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:55:38.159+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:55:38.159+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:55:39.937+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:55:39.930+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:55:39.938+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:55:39.971+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.829 seconds
[2025-06-02T11:56:10.147+0000] {processor.py:161} INFO - Started process (PID=3870) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:56:10.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:56:10.155+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:56:10.154+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:56:11.540+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:56:11.446+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:56:11.544+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:56:11.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.521 seconds
[2025-06-02T11:56:42.249+0000] {processor.py:161} INFO - Started process (PID=3882) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:56:42.251+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:56:42.255+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:56:42.254+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:56:44.323+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:56:44.316+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:56:44.324+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:56:44.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.113 seconds
[2025-06-02T11:57:14.735+0000] {processor.py:161} INFO - Started process (PID=3900) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:57:14.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:57:14.753+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:57:14.752+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:57:16.419+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:57:16.392+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:57:16.424+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:57:16.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.831 seconds
[2025-06-02T11:57:47.266+0000] {processor.py:161} INFO - Started process (PID=3912) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:57:47.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:57:47.299+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:57:47.284+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:57:48.547+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:57:48.538+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:57:48.548+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:57:48.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.352 seconds
[2025-06-02T11:58:19.421+0000] {processor.py:161} INFO - Started process (PID=3930) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:58:19.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:58:19.440+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:58:19.439+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:58:20.612+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:58:20.606+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:58:20.613+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:58:20.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.275 seconds
[2025-06-02T11:58:51.162+0000] {processor.py:161} INFO - Started process (PID=3948) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:58:51.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:58:51.170+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:58:51.169+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:58:53.800+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:58:53.792+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:58:53.802+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:58:53.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.707 seconds
[2025-06-02T11:59:24.829+0000] {processor.py:161} INFO - Started process (PID=3960) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:59:24.831+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:59:24.847+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:59:24.835+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:59:25.925+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:59:25.917+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:59:25.926+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:59:25.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.199 seconds
[2025-06-02T11:59:56.542+0000] {processor.py:161} INFO - Started process (PID=3978) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:59:56.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T11:59:56.547+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:59:56.546+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:59:58.112+0000] {logging_mixin.py:188} INFO - [2025-06-02T11:59:58.103+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T11:59:58.113+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T11:59:58.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.630 seconds
[2025-06-02T12:00:29.130+0000] {processor.py:161} INFO - Started process (PID=3990) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:00:29.132+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:00:29.137+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:00:29.136+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:00:30.735+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:00:30.723+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:00:30.737+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:00:30.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.691 seconds
[2025-06-02T12:01:01.285+0000] {processor.py:161} INFO - Started process (PID=4008) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:01:01.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:01:01.290+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:01:01.290+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:01:03.944+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:01:03.937+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:01:03.946+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:01:03.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.706 seconds
[2025-06-02T12:01:34.155+0000] {processor.py:161} INFO - Started process (PID=4020) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:01:34.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:01:34.169+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:01:34.168+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:01:36.528+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:01:36.461+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:01:36.531+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:01:36.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.499 seconds
[2025-06-02T12:02:07.224+0000] {processor.py:161} INFO - Started process (PID=4038) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:02:07.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:02:07.233+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:02:07.232+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:02:08.918+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:02:08.910+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:02:08.919+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:02:08.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.783 seconds
[2025-06-02T12:02:39.606+0000] {processor.py:161} INFO - Started process (PID=4050) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:02:39.607+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:02:39.611+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:02:39.610+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:02:41.032+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:02:41.025+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:02:41.034+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:02:41.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.534 seconds
[2025-06-02T12:03:11.420+0000] {processor.py:161} INFO - Started process (PID=4068) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:03:11.423+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:03:11.429+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:03:11.428+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:03:14.235+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:03:14.226+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:03:14.237+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:03:14.267+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.870 seconds
[2025-06-02T12:03:44.646+0000] {processor.py:161} INFO - Started process (PID=4080) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:03:44.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:03:44.651+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:03:44.650+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:03:45.698+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:03:45.690+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:03:45.699+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:03:45.735+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.100 seconds
[2025-06-02T12:04:16.672+0000] {processor.py:161} INFO - Started process (PID=4098) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:04:16.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:04:16.687+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:04:16.686+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:04:17.873+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:04:17.865+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:04:17.874+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:04:17.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.282 seconds
[2025-06-02T12:04:48.280+0000] {processor.py:161} INFO - Started process (PID=4116) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:04:48.282+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:04:48.287+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:04:48.286+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:04:49.249+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:04:49.240+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:04:49.250+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:04:49.288+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.026 seconds
[2025-06-02T12:05:19.472+0000] {processor.py:161} INFO - Started process (PID=4128) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:05:19.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:05:19.479+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:05:19.478+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:05:20.396+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:05:20.388+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:05:20.397+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:05:20.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.992 seconds
[2025-06-02T12:05:50.987+0000] {processor.py:161} INFO - Started process (PID=4146) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:05:51.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:05:51.065+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:05:51.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:05:52.657+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:05:52.651+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:05:52.658+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:05:52.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.791 seconds
[2025-06-02T12:06:23.479+0000] {processor.py:161} INFO - Started process (PID=4158) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:06:23.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:06:23.488+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:06:23.486+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:06:24.909+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:06:24.903+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:06:24.910+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:06:24.948+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.491 seconds
[2025-06-02T12:06:55.274+0000] {processor.py:161} INFO - Started process (PID=4176) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:06:55.276+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:06:55.281+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:06:55.280+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:06:56.593+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:06:56.580+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:06:56.595+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:06:56.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.389 seconds
[2025-06-02T12:07:27.010+0000] {processor.py:161} INFO - Started process (PID=4188) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:07:27.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:07:27.039+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:07:27.034+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:07:28.223+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:07:28.217+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:07:28.225+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:07:28.262+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.277 seconds
[2025-06-02T12:07:58.552+0000] {processor.py:161} INFO - Started process (PID=4206) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:07:58.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:07:58.612+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:07:58.611+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:08:00.252+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:08:00.232+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:08:00.255+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:08:00.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.827 seconds
[2025-06-02T12:08:31.186+0000] {processor.py:161} INFO - Started process (PID=4218) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:08:31.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:08:31.209+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:08:31.208+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:08:32.796+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:08:32.790+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:08:32.798+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:08:32.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.669 seconds
[2025-06-02T12:09:03.433+0000] {processor.py:161} INFO - Started process (PID=4235) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:09:03.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:09:03.471+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:09:03.470+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:09:04.647+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:09:04.641+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:09:04.649+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:09:04.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.284 seconds
[2025-06-02T12:09:35.354+0000] {processor.py:161} INFO - Started process (PID=4247) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:09:35.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:09:35.372+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:09:35.371+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:09:37.880+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:09:37.872+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:09:37.882+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:09:37.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.660 seconds
[2025-06-02T12:10:08.236+0000] {processor.py:161} INFO - Started process (PID=4265) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:10:08.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:10:08.241+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:10:08.241+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:10:09.062+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:10:09.051+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:10:09.064+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:10:09.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.914 seconds
[2025-06-02T12:10:39.879+0000] {processor.py:161} INFO - Started process (PID=4277) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:10:39.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:10:39.886+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:10:39.885+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:10:40.847+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:10:40.841+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:10:40.848+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:10:40.886+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.038 seconds
[2025-06-02T12:11:11.408+0000] {processor.py:161} INFO - Started process (PID=4295) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:11:11.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:11:11.416+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:11:11.415+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:11:12.525+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:11:12.518+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:11:12.526+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:11:12.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.203 seconds
[2025-06-02T12:11:42.825+0000] {processor.py:161} INFO - Started process (PID=4307) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:11:42.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:11:42.836+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:11:42.836+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:11:44.787+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:11:44.779+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:11:44.789+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:11:44.827+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.022 seconds
[2025-06-02T12:12:15.428+0000] {processor.py:161} INFO - Started process (PID=4325) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:12:15.430+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:12:15.433+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:12:15.433+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:12:16.809+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:12:16.784+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:12:16.815+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:12:16.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.512 seconds
[2025-06-02T12:12:47.235+0000] {processor.py:161} INFO - Started process (PID=4337) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:12:47.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:12:47.262+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:12:47.261+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:12:48.468+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:12:48.462+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:12:48.469+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:12:48.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.299 seconds
[2025-06-02T12:13:19.062+0000] {processor.py:161} INFO - Started process (PID=4355) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:13:19.065+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:13:19.071+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:13:19.069+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:13:20.683+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:13:20.676+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:13:20.685+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:13:20.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.677 seconds
[2025-06-02T12:13:51.091+0000] {processor.py:161} INFO - Started process (PID=4373) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:13:51.093+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:13:51.099+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:13:51.098+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:13:52.645+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:13:52.638+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:13:52.646+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:13:52.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.610 seconds
[2025-06-02T12:14:24.137+0000] {processor.py:161} INFO - Started process (PID=4385) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:14:24.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:14:24.163+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:14:24.156+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:14:25.510+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:14:25.502+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:14:25.512+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:14:25.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.463 seconds
[2025-06-02T12:14:56.205+0000] {processor.py:161} INFO - Started process (PID=4403) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:14:56.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:14:56.216+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:14:56.215+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:14:57.453+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:14:57.447+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:14:57.455+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:14:57.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.338 seconds
[2025-06-02T12:15:27.827+0000] {processor.py:161} INFO - Started process (PID=4415) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:15:27.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:15:27.835+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:15:27.834+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:15:29.465+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:15:29.457+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:15:29.467+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:15:29.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.712 seconds
[2025-06-02T12:16:00.293+0000] {processor.py:161} INFO - Started process (PID=4433) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:16:00.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:16:00.307+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:16:00.306+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:16:01.427+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:16:01.421+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:16:01.428+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:16:01.466+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.191 seconds
[2025-06-02T12:16:31.679+0000] {processor.py:161} INFO - Started process (PID=4445) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:16:31.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:16:31.686+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:16:31.685+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:16:32.814+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:16:32.804+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:16:32.816+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:16:32.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.198 seconds
[2025-06-02T12:17:03.056+0000] {processor.py:161} INFO - Started process (PID=4463) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:17:03.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:17:03.063+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:17:03.062+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:17:04.711+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:17:04.702+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:17:04.713+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:17:04.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.737 seconds
[2025-06-02T12:17:35.214+0000] {processor.py:161} INFO - Started process (PID=4475) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:17:35.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:17:35.244+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:17:35.243+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:17:36.556+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:17:36.546+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:17:36.558+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:17:36.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.421 seconds
[2025-06-02T12:18:06.874+0000] {processor.py:161} INFO - Started process (PID=4493) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:18:06.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:18:06.890+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:18:06.889+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:18:08.457+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:18:08.449+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:18:08.458+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:18:08.511+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.675 seconds
[2025-06-02T12:18:39.091+0000] {processor.py:161} INFO - Started process (PID=4505) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:18:39.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:18:39.098+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:18:39.098+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:18:40.528+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:18:40.522+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:18:40.530+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:18:40.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.508 seconds
[2025-06-02T12:19:11.273+0000] {processor.py:161} INFO - Started process (PID=4523) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:19:11.276+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:19:11.280+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:19:11.279+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:19:12.113+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:19:12.104+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:19:12.116+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:19:12.164+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.908 seconds
[2025-06-02T12:19:42.788+0000] {processor.py:161} INFO - Started process (PID=4535) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:19:42.791+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:19:42.796+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:19:42.795+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:19:44.090+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:19:44.081+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:19:44.092+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:19:44.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.380 seconds
[2025-06-02T12:20:14.725+0000] {processor.py:161} INFO - Started process (PID=4553) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:20:14.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:20:14.742+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:20:14.741+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:20:16.114+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:20:16.107+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:20:16.116+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:20:16.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.474 seconds
[2025-06-02T12:20:46.885+0000] {processor.py:161} INFO - Started process (PID=4565) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:20:46.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:20:46.893+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:20:46.892+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:20:48.093+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:20:48.087+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:20:48.094+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:20:48.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.268 seconds
[2025-06-02T12:21:18.977+0000] {processor.py:161} INFO - Started process (PID=4583) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:21:19.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:21:19.040+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:21:19.039+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:21:20.450+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:21:20.441+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:21:20.454+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:21:20.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.536 seconds
[2025-06-02T12:21:51.296+0000] {processor.py:161} INFO - Started process (PID=4601) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:21:51.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:21:51.333+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:21:51.332+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:21:52.306+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:21:52.283+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:21:52.308+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:21:52.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.101 seconds
[2025-06-02T12:22:23.124+0000] {processor.py:161} INFO - Started process (PID=4613) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:22:23.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:22:23.152+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:22:23.151+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:22:24.645+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:22:24.639+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:22:24.646+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:22:24.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.584 seconds
[2025-06-02T12:22:54.925+0000] {processor.py:161} INFO - Started process (PID=4631) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:22:54.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:22:54.957+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:22:54.956+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:22:56.475+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:22:56.461+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:22:56.477+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:22:56.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.653 seconds
[2025-06-02T12:23:27.618+0000] {processor.py:161} INFO - Started process (PID=4643) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:23:27.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:23:27.636+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:23:27.635+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:23:28.530+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:23:28.524+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:23:28.532+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:23:28.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.970 seconds
[2025-06-02T12:23:59.660+0000] {processor.py:161} INFO - Started process (PID=4661) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:23:59.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:23:59.669+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:23:59.668+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:24:00.779+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:24:00.712+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:24:00.781+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:24:00.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.213 seconds
[2025-06-02T12:24:31.117+0000] {processor.py:161} INFO - Started process (PID=4673) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:24:31.118+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:24:31.122+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:24:31.121+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:24:32.418+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:24:32.403+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:24:32.421+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:24:32.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.392 seconds
[2025-06-02T12:25:03.003+0000] {processor.py:161} INFO - Started process (PID=4691) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:25:03.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:25:03.014+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:25:03.013+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:25:04.655+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:25:04.647+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:25:04.657+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:25:04.700+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.717 seconds
[2025-06-02T12:25:35.113+0000] {processor.py:161} INFO - Started process (PID=4703) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:25:35.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:25:35.121+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:25:35.120+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:25:36.559+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:25:36.550+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:25:36.560+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:25:36.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.538 seconds
[2025-06-02T12:26:07.120+0000] {processor.py:161} INFO - Started process (PID=4721) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:26:07.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:26:07.135+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:26:07.135+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:26:08.741+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:26:08.736+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:26:08.743+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:26:08.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.685 seconds
[2025-06-02T12:26:39.222+0000] {processor.py:161} INFO - Started process (PID=4733) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:26:39.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:26:39.228+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:26:39.228+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:26:40.075+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:26:40.068+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:26:40.076+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:26:40.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.911 seconds
[2025-06-02T12:27:10.286+0000] {processor.py:161} INFO - Started process (PID=4751) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:27:10.288+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:27:10.297+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:27:10.296+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:27:11.475+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:27:11.465+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:27:11.477+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:27:11.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.265 seconds
[2025-06-02T12:27:41.839+0000] {processor.py:161} INFO - Started process (PID=4763) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:27:41.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:27:41.858+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:27:41.857+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:27:43.661+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:27:43.653+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:27:43.663+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:27:43.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.955 seconds
[2025-06-02T12:28:14.476+0000] {processor.py:161} INFO - Started process (PID=4781) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:28:14.482+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:28:14.496+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:28:14.494+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:28:15.814+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:28:15.808+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:28:15.815+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:28:15.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.417 seconds
[2025-06-02T12:28:46.454+0000] {processor.py:161} INFO - Started process (PID=4793) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:28:46.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:28:46.470+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:28:46.469+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:28:49.060+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:28:49.036+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:28:49.077+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:28:49.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.834 seconds
[2025-06-02T12:29:19.534+0000] {processor.py:161} INFO - Started process (PID=4811) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:29:19.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:29:19.540+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:29:19.539+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:29:21.310+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:29:21.303+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:29:21.312+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:29:21.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.866 seconds
[2025-06-02T12:29:52.219+0000] {processor.py:161} INFO - Started process (PID=4829) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:29:52.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:29:52.250+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:29:52.250+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:29:53.913+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:29:53.905+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:29:53.915+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:29:53.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.767 seconds
[2025-06-02T12:30:24.927+0000] {processor.py:161} INFO - Started process (PID=4841) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:30:24.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:30:24.952+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:30:24.951+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:30:26.136+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:30:26.129+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:30:26.138+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:30:26.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.295 seconds
[2025-06-02T12:30:56.517+0000] {processor.py:161} INFO - Started process (PID=4859) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:30:56.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:30:56.525+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:30:56.524+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:30:57.944+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:30:57.936+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:30:57.946+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:30:57.991+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.503 seconds
[2025-06-02T12:31:28.471+0000] {processor.py:161} INFO - Started process (PID=4871) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:31:28.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:31:28.478+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:31:28.477+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:31:29.833+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:31:29.826+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:31:29.835+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:31:29.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.416 seconds
[2025-06-02T12:32:00.490+0000] {processor.py:161} INFO - Started process (PID=4889) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:32:00.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:32:00.515+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:32:00.512+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:32:02.001+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:32:01.995+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:32:02.003+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:32:02.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.628 seconds
[2025-06-02T12:32:32.649+0000] {processor.py:161} INFO - Started process (PID=4901) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:32:32.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:32:32.658+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:32:32.657+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:32:34.316+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:32:34.308+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:32:34.318+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:32:34.447+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.814 seconds
[2025-06-02T12:33:04.662+0000] {processor.py:161} INFO - Started process (PID=4922) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:33:04.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:33:04.675+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:33:04.669+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:33:05.735+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:33:05.728+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:33:05.737+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:33:05.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.143 seconds
[2025-06-02T12:33:36.527+0000] {processor.py:161} INFO - Started process (PID=4931) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:33:36.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:33:36.535+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:33:36.534+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:33:37.945+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:33:37.938+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:33:37.947+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:33:37.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.479 seconds
[2025-06-02T12:34:08.845+0000] {processor.py:161} INFO - Started process (PID=4949) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:34:08.848+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:34:08.853+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:34:08.852+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:34:10.384+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:34:10.378+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:34:10.385+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:34:10.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.631 seconds
[2025-06-02T12:34:40.770+0000] {processor.py:161} INFO - Started process (PID=4961) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:34:40.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:34:40.778+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:34:40.777+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:34:42.054+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:34:41.991+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:34:42.056+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:34:42.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.393 seconds
[2025-06-02T12:35:12.806+0000] {processor.py:161} INFO - Started process (PID=4983) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:35:12.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:35:12.824+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:35:12.823+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:35:13.970+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:35:13.963+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:35:13.971+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:35:14.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.248 seconds
[2025-06-02T12:35:44.433+0000] {processor.py:161} INFO - Started process (PID=4991) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:35:44.438+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T12:35:44.461+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:35:44.460+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:35:47.579+0000] {logging_mixin.py:188} INFO - [2025-06-02T12:35:47.571+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T12:35:47.581+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T12:35:47.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.257 seconds
[2025-06-02T16:17:10.685+0000] {processor.py:161} INFO - Started process (PID=5010) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:17:10.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:17:10.718+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:17:10.717+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:17:16.368+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:17:16.352+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:17:16.371+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:17:16.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.838 seconds
[2025-06-02T16:17:47.512+0000] {processor.py:161} INFO - Started process (PID=5025) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:17:47.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:17:47.531+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:17:47.530+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:17:51.925+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:17:51.903+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:17:51.930+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:17:52.023+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.555 seconds
[2025-06-02T16:18:22.440+0000] {processor.py:161} INFO - Started process (PID=5044) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:18:22.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:18:22.448+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:18:22.447+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:18:25.806+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:18:25.796+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:18:25.808+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:18:25.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.477 seconds
[2025-06-02T16:18:56.419+0000] {processor.py:161} INFO - Started process (PID=5058) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:18:56.426+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:18:56.436+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:18:56.435+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:18:59.004+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:18:58.993+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:18:59.007+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:18:59.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.650 seconds
[2025-06-02T16:19:29.322+0000] {processor.py:161} INFO - Started process (PID=5076) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:19:29.329+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:19:29.335+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:19:29.334+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:19:30.897+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:19:30.890+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:19:30.899+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:19:30.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.679 seconds
[2025-06-02T16:20:01.864+0000] {processor.py:161} INFO - Started process (PID=5088) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:20:01.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:20:01.890+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:20:01.890+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:20:05.427+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:20:05.417+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:20:05.430+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:20:05.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.642 seconds
[2025-06-02T16:20:36.212+0000] {processor.py:161} INFO - Started process (PID=5106) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:20:36.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:20:36.216+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:20:36.216+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:20:37.246+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:20:37.241+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:20:37.248+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:20:37.283+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.079 seconds
[2025-06-02T16:21:08.073+0000] {processor.py:161} INFO - Started process (PID=5124) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:21:08.076+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:21:08.081+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:21:08.080+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:21:09.064+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:21:09.057+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:21:09.066+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:21:09.159+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.109 seconds
[2025-06-02T16:21:39.871+0000] {processor.py:161} INFO - Started process (PID=5136) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:21:39.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:21:39.876+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:21:39.875+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:21:40.653+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:21:40.644+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:21:40.655+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:21:40.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.880 seconds
[2025-06-02T16:22:11.531+0000] {processor.py:161} INFO - Started process (PID=5154) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:22:11.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:22:11.537+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:22:11.536+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:22:13.912+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:22:13.905+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:22:13.914+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:22:13.968+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.449 seconds
[2025-06-02T16:22:44.268+0000] {processor.py:161} INFO - Started process (PID=5166) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:22:44.270+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:22:44.274+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:22:44.273+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:22:45.374+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:22:45.368+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:22:45.376+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:22:45.410+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.151 seconds
[2025-06-02T16:23:15.580+0000] {processor.py:161} INFO - Started process (PID=5184) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:23:15.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:23:15.586+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:23:15.585+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:23:16.409+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:23:16.402+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:23:16.411+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:23:16.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.885 seconds
[2025-06-02T16:23:46.653+0000] {processor.py:161} INFO - Started process (PID=5196) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:23:46.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:23:46.657+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:23:46.656+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:23:47.361+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:23:47.354+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:23:47.362+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:23:47.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.746 seconds
[2025-06-02T16:24:18.303+0000] {processor.py:161} INFO - Started process (PID=5214) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:24:18.304+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:24:18.308+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:24:18.307+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:24:19.120+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:24:19.113+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:24:19.122+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:24:19.200+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.909 seconds
[2025-06-02T16:24:49.420+0000] {processor.py:161} INFO - Started process (PID=5226) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:24:49.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:24:49.428+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:24:49.427+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:24:50.389+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:24:50.384+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:24:50.390+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:24:50.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.019 seconds
[2025-06-02T16:25:20.847+0000] {processor.py:161} INFO - Started process (PID=5244) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:25:20.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:25:20.853+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:25:20.853+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:25:22.476+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:25:22.467+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:25:22.477+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:25:22.500+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.665 seconds
[2025-06-02T16:25:53.338+0000] {processor.py:161} INFO - Started process (PID=5256) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:25:53.401+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:25:53.410+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:25:53.409+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:25:54.620+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:25:54.614+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:25:54.622+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:25:54.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.351 seconds
[2025-06-02T16:26:25.519+0000] {processor.py:161} INFO - Started process (PID=5274) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:26:25.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:26:25.683+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:26:25.683+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:26:27.998+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:26:27.993+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:26:27.999+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:26:28.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.556 seconds
[2025-06-02T16:26:58.403+0000] {processor.py:161} INFO - Started process (PID=5286) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:26:58.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:26:58.418+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:26:58.418+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:26:59.406+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:26:59.398+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:26:59.407+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:26:59.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.055 seconds
[2025-06-02T16:27:30.181+0000] {processor.py:161} INFO - Started process (PID=5304) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:27:30.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:27:30.190+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:27:30.189+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:27:31.582+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:27:31.569+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:27:31.584+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:27:31.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.468 seconds
[2025-06-02T16:28:02.182+0000] {processor.py:161} INFO - Started process (PID=5316) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:28:02.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:28:02.189+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:28:02.188+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:28:04.396+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:28:04.346+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:28:04.407+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:28:04.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.293 seconds
[2025-06-02T16:28:34.713+0000] {processor.py:161} INFO - Started process (PID=5334) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:28:34.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:28:34.719+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:28:34.718+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:28:35.682+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:28:35.644+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:28:35.688+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:28:35.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.028 seconds
[2025-06-02T16:29:06.095+0000] {processor.py:161} INFO - Started process (PID=5352) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:29:06.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:29:06.106+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:29:06.106+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:29:08.764+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:29:08.752+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:29:08.765+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:29:08.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.758 seconds
[2025-06-02T16:29:39.158+0000] {processor.py:161} INFO - Started process (PID=5364) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:29:39.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:29:39.164+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:29:39.163+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:29:40.828+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:29:40.820+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:29:40.830+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:29:40.870+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.724 seconds
[2025-06-02T16:30:11.190+0000] {processor.py:161} INFO - Started process (PID=5382) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:30:11.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:30:11.195+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:30:11.194+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:30:12.620+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:30:12.607+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:30:12.623+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:30:12.665+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.487 seconds
[2025-06-02T16:30:43.302+0000] {processor.py:161} INFO - Started process (PID=5394) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:30:43.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:30:43.317+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:30:43.316+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:30:44.981+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:30:44.974+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:30:44.982+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:30:45.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.744 seconds
[2025-06-02T16:31:15.249+0000] {processor.py:161} INFO - Started process (PID=5412) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:31:15.251+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:31:15.255+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:31:15.254+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:31:17.342+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:31:17.317+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:31:17.343+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:31:17.424+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.195 seconds
[2025-06-02T16:31:47.805+0000] {processor.py:161} INFO - Started process (PID=5424) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:31:47.808+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:31:47.813+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:31:47.812+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:31:48.941+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:31:48.935+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:31:48.942+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:31:48.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.179 seconds
[2025-06-02T16:32:19.140+0000] {processor.py:161} INFO - Started process (PID=5441) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:32:19.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:32:19.154+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:32:19.153+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:32:20.448+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:32:20.389+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:32:20.500+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:32:20.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.499 seconds
[2025-06-02T16:32:51.250+0000] {processor.py:161} INFO - Started process (PID=5453) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:32:51.251+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:32:51.254+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:32:51.253+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:32:52.189+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:32:52.178+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:32:52.191+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:32:52.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.024 seconds
[2025-06-02T16:33:22.591+0000] {processor.py:161} INFO - Started process (PID=5471) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:33:22.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:33:22.596+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:33:22.595+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:33:24.271+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:33:24.264+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:33:24.272+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:33:24.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.720 seconds
[2025-06-02T16:33:54.793+0000] {processor.py:161} INFO - Started process (PID=5483) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:33:54.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:33:54.797+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:33:54.797+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:33:56.047+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:33:56.038+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:33:56.048+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:33:56.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.298 seconds
[2025-06-02T16:34:27.262+0000] {processor.py:161} INFO - Started process (PID=5501) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:34:27.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:34:27.268+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:34:27.267+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:34:29.269+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:34:29.261+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:34:29.271+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:34:29.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.077 seconds
[2025-06-02T16:34:59.862+0000] {processor.py:161} INFO - Started process (PID=5513) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:34:59.864+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:34:59.867+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:34:59.867+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:35:01.145+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:35:01.138+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:35:01.146+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:35:01.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.348 seconds
[2025-06-02T16:35:31.882+0000] {processor.py:161} INFO - Started process (PID=5531) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:35:31.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:35:31.886+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:35:31.885+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:35:33.297+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:35:33.291+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:35:33.298+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:35:33.329+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.457 seconds
[2025-06-02T16:36:03.857+0000] {processor.py:161} INFO - Started process (PID=5543) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:36:03.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:36:03.861+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:36:03.861+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:36:04.972+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:36:04.966+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:36:04.974+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:36:05.005+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.157 seconds
[2025-06-02T16:36:35.742+0000] {processor.py:161} INFO - Started process (PID=5561) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:36:35.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:36:35.749+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:36:35.747+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:36:36.903+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:36:36.895+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:36:36.904+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:36:36.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.238 seconds
[2025-06-02T16:37:07.634+0000] {processor.py:161} INFO - Started process (PID=5579) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:37:07.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:37:07.685+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:37:07.685+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:37:10.033+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:37:10.026+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:37:10.034+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:37:10.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.527 seconds
[2025-06-02T16:37:41.134+0000] {processor.py:161} INFO - Started process (PID=5591) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:37:41.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:37:41.141+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:37:41.140+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:37:43.091+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:37:43.075+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:37:43.093+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:37:43.167+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.047 seconds
[2025-06-02T16:38:13.855+0000] {processor.py:161} INFO - Started process (PID=5609) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:38:13.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:38:13.888+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:38:13.887+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:38:15.641+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:38:15.602+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:38:15.643+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:38:15.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.885 seconds
[2025-06-02T16:38:45.945+0000] {processor.py:161} INFO - Started process (PID=5621) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:38:45.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:38:45.951+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:38:45.950+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:38:47.042+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:38:47.026+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:38:47.052+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:38:47.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.216 seconds
[2025-06-02T16:39:17.790+0000] {processor.py:161} INFO - Started process (PID=5639) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:39:17.791+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:39:17.795+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:39:17.794+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:39:18.661+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:39:18.646+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:39:18.663+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:39:18.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.939 seconds
[2025-06-02T16:39:49.666+0000] {processor.py:161} INFO - Started process (PID=5651) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:39:49.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:39:49.702+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:39:49.701+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:39:51.239+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:39:51.231+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:39:51.242+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:39:51.275+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.646 seconds
[2025-06-02T16:40:22.037+0000] {processor.py:161} INFO - Started process (PID=5669) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:40:22.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:40:22.053+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:40:22.052+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:40:24.168+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:40:24.162+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:40:24.170+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:40:24.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.206 seconds
[2025-06-02T16:40:54.694+0000] {processor.py:161} INFO - Started process (PID=5681) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:40:54.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:40:54.714+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:40:54.713+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:40:55.963+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:40:55.957+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:40:55.964+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:40:55.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.321 seconds
[2025-06-02T16:41:26.222+0000] {processor.py:161} INFO - Started process (PID=5699) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:41:26.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:41:26.227+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:41:26.227+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:41:27.509+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:41:27.497+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:41:27.511+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:41:27.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.330 seconds
[2025-06-02T16:41:57.990+0000] {processor.py:161} INFO - Started process (PID=5711) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:41:57.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:41:57.995+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:41:57.994+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:41:58.980+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:41:58.953+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:41:58.984+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:41:59.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.086 seconds
[2025-06-02T16:42:29.408+0000] {processor.py:161} INFO - Started process (PID=5729) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:42:29.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:42:29.426+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:42:29.425+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:42:31.599+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:42:31.593+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:42:31.601+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:42:31.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.242 seconds
[2025-06-02T16:43:02.336+0000] {processor.py:161} INFO - Started process (PID=5741) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:43:02.351+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:43:02.361+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:43:02.355+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:43:04.929+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:43:04.923+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:43:04.931+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:43:04.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.671 seconds
[2025-06-02T16:43:35.356+0000] {processor.py:161} INFO - Started process (PID=5759) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:43:35.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:43:35.365+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:43:35.364+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:43:36.435+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:43:36.427+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:43:36.437+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:43:36.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.142 seconds
[2025-06-02T16:44:07.004+0000] {processor.py:161} INFO - Started process (PID=5771) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:44:07.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:44:07.011+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:44:07.010+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:44:09.278+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:44:09.209+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:44:09.280+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:44:09.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.436 seconds
[2025-06-02T16:44:39.644+0000] {processor.py:161} INFO - Started process (PID=5788) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:44:39.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:44:39.648+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:44:39.648+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:44:40.619+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:44:40.604+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:44:40.624+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:44:40.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.100 seconds
[2025-06-02T16:45:10.991+0000] {processor.py:161} INFO - Started process (PID=5806) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:45:10.992+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:45:10.995+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:45:10.994+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:45:12.445+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:45:12.375+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:45:12.451+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:45:12.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.545 seconds
[2025-06-02T16:45:43.149+0000] {processor.py:161} INFO - Started process (PID=5818) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:45:43.152+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:45:43.156+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:45:43.155+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:45:44.263+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:45:44.257+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:45:44.264+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:45:44.292+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.185 seconds
[2025-06-02T16:46:14.569+0000] {processor.py:161} INFO - Started process (PID=5836) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:46:14.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:46:14.574+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:46:14.573+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:46:15.944+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:46:15.939+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:46:15.945+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:46:15.991+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.440 seconds
[2025-06-02T16:46:46.089+0000] {processor.py:161} INFO - Started process (PID=5848) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:46:46.091+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:46:46.094+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:46:46.093+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:46:47.197+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:46:47.187+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:46:47.201+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:46:47.319+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.239 seconds
[2025-06-02T16:47:17.960+0000] {processor.py:161} INFO - Started process (PID=5866) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:47:17.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:47:17.979+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:47:17.979+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:47:20.689+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:47:20.680+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:47:20.691+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:47:20.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.803 seconds
[2025-06-02T16:47:51.224+0000] {processor.py:161} INFO - Started process (PID=5878) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:47:51.226+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:47:51.229+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:47:51.228+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:47:52.473+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:47:52.455+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:47:52.475+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:47:52.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.308 seconds
[2025-06-02T16:48:23.234+0000] {processor.py:161} INFO - Started process (PID=5896) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:48:23.237+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:48:23.241+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:48:23.240+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:48:24.646+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:48:24.637+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:48:24.654+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:48:24.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.509 seconds
[2025-06-02T16:48:55.108+0000] {processor.py:161} INFO - Started process (PID=5908) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:48:55.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:48:55.114+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:48:55.113+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:48:56.196+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:48:56.190+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:48:56.198+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:48:56.232+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.133 seconds
[2025-06-02T16:49:26.646+0000] {processor.py:161} INFO - Started process (PID=5926) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:49:26.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:49:26.651+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:49:26.650+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:49:27.771+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:49:27.767+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:49:27.772+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:49:27.804+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.170 seconds
[2025-06-02T16:49:57.927+0000] {processor.py:161} INFO - Started process (PID=5938) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:49:57.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:49:57.931+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:49:57.930+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:49:59.043+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:49:59.037+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:49:59.045+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:49:59.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.152 seconds
[2025-06-02T16:50:29.839+0000] {processor.py:161} INFO - Started process (PID=5956) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:50:29.851+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:50:29.864+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:50:29.856+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:50:32.243+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:50:32.235+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:50:32.245+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:50:32.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.478 seconds
[2025-06-02T16:51:02.695+0000] {processor.py:161} INFO - Started process (PID=5968) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:51:02.706+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:51:02.705+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:51:02.705+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:51:04.384+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:51:04.345+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:51:04.386+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:51:04.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.815 seconds
[2025-06-02T16:51:35.281+0000] {processor.py:161} INFO - Started process (PID=5986) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:51:35.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:51:35.290+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:51:35.289+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:51:36.221+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:51:36.216+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:51:36.222+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:51:36.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.988 seconds
[2025-06-02T16:52:06.654+0000] {processor.py:161} INFO - Started process (PID=5998) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:52:06.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:52:06.676+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:52:06.675+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:52:08.333+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:52:08.327+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:52:08.334+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:52:08.374+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.754 seconds
[2025-06-02T16:52:38.920+0000] {processor.py:161} INFO - Started process (PID=6016) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:52:38.923+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:52:38.929+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:52:38.928+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:52:40.757+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:52:40.751+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:52:40.758+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:52:40.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.891 seconds
[2025-06-02T16:53:11.309+0000] {processor.py:161} INFO - Started process (PID=6034) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:53:11.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:53:11.404+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:53:11.403+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:53:16.820+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:53:16.740+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:53:16.862+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:53:17.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.759 seconds
[2025-06-02T16:53:47.562+0000] {processor.py:161} INFO - Started process (PID=6046) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:53:47.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:53:47.567+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:53:47.566+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:53:48.414+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:53:48.399+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:53:48.415+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:53:48.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.955 seconds
[2025-06-02T16:54:19.131+0000] {processor.py:161} INFO - Started process (PID=6064) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:54:19.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:54:19.151+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:54:19.151+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:54:22.169+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:54:22.160+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:54:22.171+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:54:22.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.126 seconds
[2025-06-02T16:54:53.041+0000] {processor.py:161} INFO - Started process (PID=6076) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:54:53.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:54:53.045+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:54:53.045+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:54:53.989+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:54:53.983+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:54:53.991+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:54:54.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.990 seconds
[2025-06-02T16:55:24.221+0000] {processor.py:161} INFO - Started process (PID=6094) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:55:24.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:55:24.226+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:55:24.225+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:55:25.600+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:55:25.592+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:55:25.601+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:55:25.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.427 seconds
[2025-06-02T16:55:55.715+0000] {processor.py:161} INFO - Started process (PID=6106) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:55:55.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:55:55.719+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:55:55.718+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:55:56.932+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:55:56.923+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:55:56.934+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:55:56.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.270 seconds
[2025-06-02T16:56:27.164+0000] {processor.py:161} INFO - Started process (PID=6124) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:56:27.166+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:56:27.171+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:56:27.170+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:56:30.158+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:56:29.931+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:56:30.207+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:56:30.387+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.246 seconds
[2025-06-02T16:57:00.690+0000] {processor.py:161} INFO - Started process (PID=6136) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:57:00.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:57:00.705+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:57:00.704+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:57:02.777+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:57:02.765+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:57:02.779+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:57:02.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.207 seconds
[2025-06-02T16:57:33.049+0000] {processor.py:161} INFO - Started process (PID=6155) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:57:33.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:57:33.053+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:57:33.053+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:57:34.117+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:57:34.111+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:57:34.119+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:57:34.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.131 seconds
[2025-06-02T16:58:04.673+0000] {processor.py:161} INFO - Started process (PID=6167) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:58:04.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:58:04.678+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:58:04.678+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:58:06.378+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:58:06.368+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:58:06.380+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:58:06.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.783 seconds
[2025-06-02T16:58:36.723+0000] {processor.py:161} INFO - Started process (PID=6185) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:58:36.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:58:36.727+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:58:36.727+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:58:37.695+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:58:37.689+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:58:37.696+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:58:37.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.012 seconds
[2025-06-02T16:59:08.098+0000] {processor.py:161} INFO - Started process (PID=6197) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:59:08.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:59:08.109+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:59:08.108+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:59:11.191+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:59:11.178+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:59:11.193+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:59:11.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.180 seconds
[2025-06-02T16:59:41.493+0000] {processor.py:161} INFO - Started process (PID=6215) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:59:41.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T16:59:41.500+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:59:41.499+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:59:43.352+0000] {logging_mixin.py:188} INFO - [2025-06-02T16:59:43.345+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T16:59:43.353+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T16:59:43.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.922 seconds
[2025-06-02T17:00:13.676+0000] {processor.py:161} INFO - Started process (PID=6233) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:00:13.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T17:00:13.692+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:00:13.691+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:00:16.879+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:00:16.736+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T17:00:16.904+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:00:17.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.355 seconds
[2025-06-02T17:00:47.614+0000] {processor.py:161} INFO - Started process (PID=6245) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:00:47.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T17:00:47.618+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:00:47.618+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:00:49.080+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:00:49.064+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T17:00:49.083+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:00:49.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.537 seconds
[2025-06-02T17:01:19.552+0000] {processor.py:161} INFO - Started process (PID=6263) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:01:19.556+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T17:01:19.566+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:01:19.561+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:01:21.480+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:01:21.473+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T17:01:21.482+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:01:21.571+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.040 seconds
[2025-06-02T17:01:51.937+0000] {processor.py:161} INFO - Started process (PID=6275) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:01:51.940+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T17:01:51.944+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:01:51.943+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:01:54.230+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:01:54.208+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T17:01:54.235+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:01:54.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.459 seconds
[2025-06-02T17:02:25.103+0000] {processor.py:161} INFO - Started process (PID=6293) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:02:25.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T17:02:25.130+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:02:25.129+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:02:28.243+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:02:28.234+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T17:02:28.250+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:02:28.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.244 seconds
[2025-06-02T17:02:58.844+0000] {processor.py:161} INFO - Started process (PID=6305) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:02:58.847+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T17:02:58.850+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:02:58.850+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:03:02.303+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:03:02.286+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T17:03:02.304+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:03:02.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.582 seconds
[2025-06-02T17:03:33.532+0000] {processor.py:161} INFO - Started process (PID=6323) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:03:33.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T17:03:33.542+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:03:33.541+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:03:34.595+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:03:34.586+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T17:03:34.600+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:03:34.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.140 seconds
[2025-06-02T17:04:05.141+0000] {processor.py:161} INFO - Started process (PID=6335) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:04:05.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T17:04:05.160+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:04:05.159+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:04:07.392+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:04:07.385+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T17:04:07.394+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:04:07.426+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.309 seconds
[2025-06-02T17:04:38.035+0000] {processor.py:161} INFO - Started process (PID=6359) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:04:38.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T17:04:38.039+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:04:38.039+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:04:39.063+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:04:39.057+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T17:04:39.064+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:04:39.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.075 seconds
[2025-06-02T17:05:12.735+0000] {processor.py:161} INFO - Started process (PID=6374) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:05:12.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T17:05:12.753+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:05:12.752+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:05:18.837+0000] {logging_mixin.py:188} INFO - [2025-06-02T17:05:16.938+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T17:05:18.851+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T17:05:19.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.490 seconds
[2025-06-02T20:05:55.788+0000] {processor.py:161} INFO - Started process (PID=6382) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T20:05:55.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T20:05:55.822+0000] {logging_mixin.py:188} INFO - [2025-06-02T20:05:55.820+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:07:01.024+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:07:01.019+0000] {timeout.py:68} ERROR - Process timed out, PID: 6382
[2025-06-02T22:06:58.602+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:06:58.310+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T22:06:58.628+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:06:58.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 41.297 seconds
[2025-06-02T22:07:30.418+0000] {processor.py:161} INFO - Started process (PID=6400) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:07:30.423+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:07:30.438+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:07:30.437+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:07:40.665+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:07:39.474+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T22:07:40.750+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:07:40.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 10.613 seconds
[2025-06-02T22:08:12.221+0000] {processor.py:161} INFO - Started process (PID=6424) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:08:12.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:08:12.240+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:08:12.239+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:08:18.587+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:08:18.485+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T22:08:18.590+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:08:18.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.545 seconds
[2025-06-02T22:08:49.645+0000] {processor.py:161} INFO - Started process (PID=6436) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:08:49.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:08:49.677+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:08:49.676+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:08:51.259+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:08:51.252+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T22:08:51.261+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:08:51.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.701 seconds
[2025-06-02T22:09:21.955+0000] {processor.py:161} INFO - Started process (PID=6454) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:09:22.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:09:22.059+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:09:22.058+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:09:26.430+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:09:26.409+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/postgres_to_bigquery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_to_bigquery_dag.py", line 40, in <module>
    credentials = service_account.Credentials.from_service_account_file(f"/opt/airflow/data/key/{getenv('key')}")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/oauth2/service_account.py", line 259, in from_service_account_file
    info, signer = _service_account_info.from_filename(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_service_account_info.py", line 78, in from_filename
    with io.open(filename, "r", encoding="utf-8") as json_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/key/None'
[2025-06-02T22:09:26.445+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:09:26.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.678 seconds
[2025-06-02T22:15:17.831+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:15:17.847+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:15:17.866+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:15:17.865+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:15:30.408+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:15:31.481+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:15:31.479+0000] {override.py:1858} INFO - Created Permission View: can delete on DAG:postgres_to_bigquery
[2025-06-02T22:15:31.634+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:15:31.634+0000] {override.py:1858} INFO - Created Permission View: can read on DAG:postgres_to_bigquery
[2025-06-02T22:15:31.727+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:15:31.726+0000] {override.py:1858} INFO - Created Permission View: can edit on DAG:postgres_to_bigquery
[2025-06-02T22:15:31.745+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:15:31.745+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:15:31.853+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:15:31.853+0000] {dag.py:3111} INFO - Creating ORM DAG for postgres_to_bigquery
[2025-06-02T22:15:31.958+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:15:31.958+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-05-31 00:00:00+00:00, run_after=2025-06-01 00:00:00+00:00
[2025-06-02T22:15:32.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 14.389 seconds
[2025-06-02T22:16:02.974+0000] {processor.py:161} INFO - Started process (PID=185) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:16:02.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:16:02.990+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:16:02.989+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:16:06.003+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:16:06.070+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:16:06.069+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:16:06.129+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:16:06.128+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-05-31 00:00:00+00:00, run_after=2025-06-01 00:00:00+00:00
[2025-06-02T22:16:06.242+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.297 seconds
[2025-06-02T22:16:37.527+0000] {processor.py:161} INFO - Started process (PID=201) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:16:37.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:16:37.560+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:16:37.548+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:16:44.222+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:16:44.382+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:16:44.367+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:16:44.543+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:16:44.543+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-05-31 00:00:00+00:00, run_after=2025-06-01 00:00:00+00:00
[2025-06-02T22:16:44.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 7.229 seconds
[2025-06-02T22:17:15.361+0000] {processor.py:161} INFO - Started process (PID=222) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:17:15.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:17:15.383+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:17:15.382+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:17:22.509+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:17:22.675+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:17:22.673+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:17:22.819+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:17:22.818+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-05-31 00:00:00+00:00, run_after=2025-06-01 00:00:00+00:00
[2025-06-02T22:17:22.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 7.611 seconds
[2025-06-02T22:17:54.107+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:17:54.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:17:54.200+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:17:54.199+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:17:59.182+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:17:59.311+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:17:59.310+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:17:59.464+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:17:59.464+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:17:59.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.525 seconds
[2025-06-02T22:18:29.877+0000] {processor.py:161} INFO - Started process (PID=257) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:18:29.878+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:18:29.886+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:18:29.886+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:18:31.171+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:18:31.231+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:18:31.230+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:18:31.342+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:18:31.341+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:18:31.562+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.698 seconds
[2025-06-02T22:19:02.444+0000] {processor.py:161} INFO - Started process (PID=269) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:19:02.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:19:02.452+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:19:02.451+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:19:04.524+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:19:04.586+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:19:04.586+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:19:04.634+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:19:04.633+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:19:04.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.263 seconds
[2025-06-02T22:19:42.065+0000] {processor.py:161} INFO - Started process (PID=287) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:19:42.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:19:42.112+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:19:42.111+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:19:48.606+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:19:48.766+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:19:48.765+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:19:48.895+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:19:48.894+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:19:48.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.943 seconds
[2025-06-02T22:20:19.820+0000] {processor.py:161} INFO - Started process (PID=305) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:20:19.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:20:19.839+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:20:19.838+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:20:25.593+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:20:25.757+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:20:25.755+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:20:25.887+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:20:25.887+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:20:25.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.204 seconds
[2025-06-02T22:20:56.462+0000] {processor.py:161} INFO - Started process (PID=317) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:20:56.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:20:56.471+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:20:56.470+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:20:59.927+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:21:00.005+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:21:00.003+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:21:00.138+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:21:00.137+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:21:00.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.846 seconds
[2025-06-02T22:21:30.719+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:21:30.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:21:30.729+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:21:30.728+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:21:32.753+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:21:32.816+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:21:32.816+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:21:32.853+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:21:32.853+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:21:32.893+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.193 seconds
[2025-06-02T22:22:03.548+0000] {processor.py:161} INFO - Started process (PID=347) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:22:03.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:22:03.557+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:22:03.556+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:22:05.719+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:22:05.767+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:22:05.766+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:22:05.803+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:22:05.802+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:22:05.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.318 seconds
[2025-06-02T22:22:36.533+0000] {processor.py:161} INFO - Started process (PID=365) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:22:36.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:22:36.543+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:22:36.542+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:22:38.336+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:22:38.419+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:22:38.418+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:22:38.476+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:22:38.475+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:22:38.568+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.058 seconds
[2025-06-02T22:23:09.805+0000] {processor.py:161} INFO - Started process (PID=389) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:23:09.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:23:09.813+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:23:09.812+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:23:11.650+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:23:11.710+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:23:11.709+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:23:11.750+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:23:11.750+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:23:11.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.053 seconds
[2025-06-02T22:23:42.716+0000] {processor.py:161} INFO - Started process (PID=401) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:23:42.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:23:42.721+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:23:42.721+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:23:44.655+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:23:44.726+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:23:44.725+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:23:44.780+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:23:44.780+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:23:44.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.136 seconds
[2025-06-02T22:24:15.425+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:24:15.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:24:15.432+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:24:15.431+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:24:17.346+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:24:17.425+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:24:17.424+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:24:17.485+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:24:17.484+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:24:17.537+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.124 seconds
[2025-06-02T22:24:47.902+0000] {processor.py:161} INFO - Started process (PID=431) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:24:47.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:24:47.909+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:24:47.908+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:24:50.562+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:24:50.643+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:24:50.641+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:24:50.698+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:24:50.697+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:24:50.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.917 seconds
[2025-06-02T22:25:21.684+0000] {processor.py:161} INFO - Started process (PID=449) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:25:21.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:25:21.744+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:25:21.744+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:25:23.528+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:25:23.571+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:25:23.571+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:25:23.605+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:25:23.605+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:25:23.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.995 seconds
[2025-06-02T22:25:54.254+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:25:54.268+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:25:54.272+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:25:54.271+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:25:55.480+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:25:55.521+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:25:55.520+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:25:55.556+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:25:55.555+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:25:55.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.365 seconds
[2025-06-02T22:26:26.378+0000] {processor.py:161} INFO - Started process (PID=480) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:26:26.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:26:26.392+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:26:26.392+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:26:27.689+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:26:27.731+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:26:27.730+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:26:27.765+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:26:27.765+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:26:27.810+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.453 seconds
[2025-06-02T22:26:58.526+0000] {processor.py:161} INFO - Started process (PID=492) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:26:58.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:26:58.545+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:26:58.544+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:27:00.605+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:27:00.647+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:27:00.646+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:27:00.682+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:27:00.682+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:27:00.724+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.251 seconds
[2025-06-02T22:27:31.400+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:27:31.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:27:31.406+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:27:31.405+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:27:33.438+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:27:33.482+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:27:33.481+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:27:33.540+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:27:33.539+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:27:33.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.212 seconds
[2025-06-02T22:28:04.379+0000] {processor.py:161} INFO - Started process (PID=522) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:28:04.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:28:04.386+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:28:04.384+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:28:05.906+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:28:05.959+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:28:05.958+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:28:05.999+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:28:05.999+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:28:06.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.679 seconds
[2025-06-02T22:28:36.922+0000] {processor.py:161} INFO - Started process (PID=539) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:28:36.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:28:36.929+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:28:36.928+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:28:38.083+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:28:38.132+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:28:38.131+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:28:38.165+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:28:38.165+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:28:38.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.329 seconds
[2025-06-02T22:29:08.649+0000] {processor.py:161} INFO - Started process (PID=551) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:29:08.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:29:08.660+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:29:08.659+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:29:10.367+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:29:10.413+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:29:10.412+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:29:10.450+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:29:10.450+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:29:10.494+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.867 seconds
[2025-06-02T22:29:40.622+0000] {processor.py:161} INFO - Started process (PID=569) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:29:40.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:29:40.629+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:29:40.628+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:29:42.463+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:29:42.505+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:29:42.505+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:29:42.539+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:29:42.539+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:29:42.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.988 seconds
[2025-06-02T22:30:12.835+0000] {processor.py:161} INFO - Started process (PID=588) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:30:12.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:30:12.842+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:30:12.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:30:15.210+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:30:15.270+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:30:15.269+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:30:15.327+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:30:15.326+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:30:15.374+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.562 seconds
[2025-06-02T22:30:45.851+0000] {processor.py:161} INFO - Started process (PID=600) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:30:45.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:30:45.858+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:30:45.857+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:30:47.453+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:30:47.510+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:30:47.509+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:30:47.546+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:30:47.546+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:30:47.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.744 seconds
[2025-06-02T22:31:17.873+0000] {processor.py:161} INFO - Started process (PID=618) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:31:17.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:31:17.882+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:31:17.881+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:31:19.964+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:31:20.028+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:31:20.027+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:31:20.073+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:31:20.072+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:31:20.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.255 seconds
[2025-06-02T22:31:50.733+0000] {processor.py:161} INFO - Started process (PID=630) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:31:50.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:31:50.738+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:31:50.738+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:31:52.653+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:31:52.713+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:31:52.711+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:31:52.763+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:31:52.763+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:31:52.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.125 seconds
[2025-06-02T22:32:23.372+0000] {processor.py:161} INFO - Started process (PID=648) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:32:23.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:32:23.378+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:32:23.377+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:32:25.847+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:32:25.906+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:32:25.905+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:32:25.965+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:32:25.964+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:32:26.008+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.649 seconds
[2025-06-02T22:32:56.464+0000] {processor.py:161} INFO - Started process (PID=660) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:32:56.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:32:56.469+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:32:56.468+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:32:58.376+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:32:58.456+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:32:58.455+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:32:58.509+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:32:58.508+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:32:58.562+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.112 seconds
[2025-06-02T22:33:29.523+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:33:29.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:33:29.545+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:33:29.544+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:33:30.734+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:33:30.773+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:33:30.772+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:33:30.805+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:33:30.805+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:33:30.845+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.354 seconds
[2025-06-02T22:34:01.829+0000] {processor.py:161} INFO - Started process (PID=690) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:34:01.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:34:01.851+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:34:01.850+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:34:03.288+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:34:03.327+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:34:03.326+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:34:03.366+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:34:03.366+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:34:03.405+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.616 seconds
[2025-06-02T22:34:33.520+0000] {processor.py:161} INFO - Started process (PID=708) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:34:33.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:34:33.527+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:34:33.526+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:34:35.363+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:34:35.422+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:34:35.421+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:34:35.458+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:34:35.458+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:34:35.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.982 seconds
[2025-06-02T22:35:06.061+0000] {processor.py:161} INFO - Started process (PID=720) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:35:06.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:35:06.067+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:35:06.066+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:35:07.646+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:35:07.690+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:35:07.690+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:35:07.725+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:35:07.725+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:35:07.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.723 seconds
[2025-06-02T22:35:38.529+0000] {processor.py:161} INFO - Started process (PID=738) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:35:38.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:35:38.537+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:35:38.536+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:35:40.957+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:35:41.039+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:35:41.038+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:35:41.092+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:35:41.092+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:35:41.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.643 seconds
[2025-06-02T22:36:11.495+0000] {processor.py:161} INFO - Started process (PID=756) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:36:11.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:36:11.505+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:36:11.502+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:36:13.197+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:36:13.238+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:36:13.237+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:36:13.281+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:36:13.281+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:36:13.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.874 seconds
[2025-06-02T22:36:44.574+0000] {processor.py:161} INFO - Started process (PID=768) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:36:44.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:36:44.591+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:36:44.590+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:36:47.526+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:36:47.578+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:36:47.577+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:36:47.616+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:36:47.615+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:36:47.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.110 seconds
[2025-06-02T22:37:17.987+0000] {processor.py:161} INFO - Started process (PID=786) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:37:17.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:37:17.997+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:37:17.996+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:37:20.095+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:37:20.137+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:37:20.135+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:37:20.190+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:37:20.189+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:37:20.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.276 seconds
[2025-06-02T22:37:50.613+0000] {processor.py:161} INFO - Started process (PID=798) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:37:50.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:37:50.621+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:37:50.620+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:37:53.116+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:37:53.177+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:37:53.176+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:37:53.220+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:37:53.219+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:37:53.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.676 seconds
[2025-06-02T22:38:23.909+0000] {processor.py:161} INFO - Started process (PID=821) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:38:23.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:38:23.917+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:38:23.917+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:38:26.488+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:38:26.542+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:38:26.540+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:38:26.586+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:38:26.586+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:38:26.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.739 seconds
[2025-06-02T22:38:57.525+0000] {processor.py:161} INFO - Started process (PID=834) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:38:57.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:38:57.531+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:38:57.530+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:38:59.460+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:38:59.613+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:38:59.599+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:38:59.725+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:38:59.725+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:38:59.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.306 seconds
[2025-06-02T22:39:30.420+0000] {processor.py:161} INFO - Started process (PID=852) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:39:30.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:39:30.432+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:39:30.431+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:39:32.067+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:39:32.154+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:39:32.153+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:39:32.256+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:39:32.255+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:39:32.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.936 seconds
[2025-06-02T22:40:02.875+0000] {processor.py:161} INFO - Started process (PID=864) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:40:02.878+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:40:02.895+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:40:02.894+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:40:07.669+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:40:07.799+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:40:07.798+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:40:07.899+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:40:07.897+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:40:07.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.144 seconds
[2025-06-02T22:40:38.345+0000] {processor.py:161} INFO - Started process (PID=882) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:40:38.347+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:40:38.351+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:40:38.350+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:40:44.033+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:40:44.220+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:40:44.219+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:40:44.300+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:40:44.300+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:40:44.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.024 seconds
[2025-06-02T22:41:15.288+0000] {processor.py:161} INFO - Started process (PID=900) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:41:15.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:41:15.368+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:41:15.367+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:41:19.082+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:41:19.243+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:41:19.242+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:41:19.407+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:41:19.407+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:41:19.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.532 seconds
[2025-06-02T22:41:50.478+0000] {processor.py:161} INFO - Started process (PID=912) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:41:50.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:41:50.509+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:41:50.507+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:41:52.775+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:41:52.882+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:41:52.881+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:41:53.050+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:41:53.050+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:41:53.230+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.813 seconds
[2025-06-02T22:42:23.896+0000] {processor.py:161} INFO - Started process (PID=930) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:42:23.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:42:23.902+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:42:23.901+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:42:26.511+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:42:26.651+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:42:26.650+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:42:26.767+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:42:26.767+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:42:26.839+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.955 seconds
[2025-06-02T22:42:57.982+0000] {processor.py:161} INFO - Started process (PID=942) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:42:57.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:42:57.995+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:42:57.994+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:43:01.220+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:43:01.267+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:43:01.266+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:43:01.314+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:43:01.314+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:43:01.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.431 seconds
[2025-06-02T22:43:31.575+0000] {processor.py:161} INFO - Started process (PID=960) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:43:31.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:43:31.580+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:43:31.580+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:43:33.459+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:43:33.509+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:43:33.507+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:43:33.551+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:43:33.551+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:43:33.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.037 seconds
[2025-06-02T22:44:04.276+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:44:04.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:44:04.283+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:44:04.282+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:44:05.559+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:44:05.626+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:44:05.625+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:44:05.723+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:44:05.723+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:44:05.849+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.587 seconds
[2025-06-02T22:44:37.309+0000] {processor.py:161} INFO - Started process (PID=990) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:44:37.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:44:37.326+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:44:37.325+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:44:39.590+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:44:39.706+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:44:39.705+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:44:39.824+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:44:39.823+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:44:39.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.683 seconds
[2025-06-02T22:45:10.446+0000] {processor.py:161} INFO - Started process (PID=1002) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:45:10.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:45:10.476+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:45:10.475+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:45:17.314+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:45:17.499+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:45:17.499+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:45:17.686+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:45:17.685+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:45:17.849+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 7.455 seconds
[2025-06-02T22:45:49.178+0000] {processor.py:161} INFO - Started process (PID=1020) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:45:49.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:45:49.196+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:45:49.195+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:45:54.796+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:45:55.092+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:45:55.077+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:45:55.315+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:45:55.314+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:45:55.441+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 6.307 seconds
[2025-06-02T22:46:25.835+0000] {processor.py:161} INFO - Started process (PID=1038) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:46:25.838+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:46:25.843+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:46:25.842+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:46:28.490+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:46:28.539+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:46:28.538+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:46:28.575+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:46:28.575+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:46:28.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.801 seconds
[2025-06-02T22:46:59.219+0000] {processor.py:161} INFO - Started process (PID=1050) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:46:59.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:46:59.224+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:46:59.224+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:47:01.174+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:47:01.297+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:47:01.293+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:47:01.352+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:47:01.352+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:47:01.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.196 seconds
[2025-06-02T22:47:32.063+0000] {processor.py:161} INFO - Started process (PID=1068) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:47:32.065+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:47:32.068+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:47:32.068+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:47:33.566+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:47:33.631+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:47:33.630+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:47:33.718+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:47:33.718+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:47:33.767+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.718 seconds
[2025-06-02T22:48:04.369+0000] {processor.py:161} INFO - Started process (PID=1080) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:48:04.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:48:04.379+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:48:04.378+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:48:06.970+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:48:07.103+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:48:07.101+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:48:07.162+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:48:07.162+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:48:07.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.888 seconds
[2025-06-02T22:48:38.377+0000] {processor.py:161} INFO - Started process (PID=1098) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:48:38.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:48:38.382+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:48:38.382+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:48:40.922+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:48:41.124+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:48:41.123+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:48:41.286+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:48:41.285+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:48:41.446+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.091 seconds
[2025-06-02T22:49:12.125+0000] {processor.py:161} INFO - Started process (PID=1110) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:49:12.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:49:12.134+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:49:12.133+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:49:14.478+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:49:14.541+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:49:14.540+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:49:14.606+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:49:14.606+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:49:14.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.561 seconds
[2025-06-02T22:49:45.817+0000] {processor.py:161} INFO - Started process (PID=1128) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:49:45.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:49:45.842+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:49:45.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:49:49.438+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:49:49.523+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:49:49.518+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:49:49.685+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:49:49.685+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:49:49.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.075 seconds
[2025-06-02T22:50:20.496+0000] {processor.py:161} INFO - Started process (PID=1146) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:50:20.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:50:20.508+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:50:20.507+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:50:25.773+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:50:25.983+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:50:25.967+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:50:26.208+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:50:26.208+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:50:26.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.864 seconds
[2025-06-02T22:50:57.495+0000] {processor.py:161} INFO - Started process (PID=1158) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:50:57.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:50:57.519+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:50:57.518+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:50:59.644+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:50:59.758+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:50:59.757+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:50:59.885+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:50:59.884+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:50:59.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.527 seconds
[2025-06-02T22:51:30.408+0000] {processor.py:161} INFO - Started process (PID=1176) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:51:30.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:51:30.422+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:51:30.420+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:51:32.122+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:51:32.157+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:51:32.156+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:51:32.184+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:51:32.184+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:51:32.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.838 seconds
[2025-06-02T22:52:02.575+0000] {processor.py:161} INFO - Started process (PID=1188) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:52:02.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:52:02.582+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:52:02.581+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:52:04.303+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:52:04.339+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:52:04.338+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:52:04.372+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:52:04.372+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:52:04.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.853 seconds
[2025-06-02T22:52:34.571+0000] {processor.py:161} INFO - Started process (PID=1210) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:52:34.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:52:34.580+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:52:34.579+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:52:36.656+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:52:36.709+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:52:36.708+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:52:36.744+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:52:36.744+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:52:36.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.241 seconds
[2025-06-02T22:53:07.043+0000] {processor.py:161} INFO - Started process (PID=1222) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:53:07.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:53:07.052+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:53:07.051+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:53:10.079+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:53:10.135+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:53:10.134+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:53:10.244+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:53:10.238+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:53:10.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.285 seconds
[2025-06-02T22:53:41.187+0000] {processor.py:161} INFO - Started process (PID=1240) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:53:41.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:53:41.193+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:53:41.192+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:53:43.464+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:53:43.501+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:53:43.501+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:53:43.552+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:53:43.551+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:53:43.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.430 seconds
[2025-06-02T22:54:14.399+0000] {processor.py:161} INFO - Started process (PID=1260) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:54:14.403+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:54:14.408+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:54:14.407+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:54:16.746+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:54:16.795+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:54:16.794+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:54:16.837+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:54:16.836+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:54:16.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.594 seconds
[2025-06-02T22:54:47.321+0000] {processor.py:161} INFO - Started process (PID=1272) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:54:47.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:54:47.326+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:54:47.325+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:54:48.994+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:54:49.040+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:54:49.040+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:54:49.074+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:54:49.073+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:54:49.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.806 seconds
[2025-06-02T22:55:20.167+0000] {processor.py:161} INFO - Started process (PID=1290) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:55:20.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:55:20.175+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:55:20.174+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:55:24.948+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:55:25.076+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:55:25.075+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:55:25.225+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:55:25.224+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:55:25.326+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 5.177 seconds
[2025-06-02T22:55:55.813+0000] {processor.py:161} INFO - Started process (PID=1302) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:55:55.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:55:55.831+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:55:55.829+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:55:58.666+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:55:58.813+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:55:58.812+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:55:59.034+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:55:59.033+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:55:59.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.477 seconds
[2025-06-02T22:56:29.636+0000] {processor.py:161} INFO - Started process (PID=1320) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:56:29.638+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:56:29.643+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:56:29.642+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:56:33.771+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:56:34.037+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:56:34.035+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:56:34.249+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:56:34.249+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:56:34.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 4.794 seconds
[2025-06-02T22:57:04.834+0000] {processor.py:161} INFO - Started process (PID=1332) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:57:04.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:57:04.840+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:57:04.839+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:57:07.546+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:57:07.651+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:57:07.650+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:57:07.745+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:57:07.744+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:57:07.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 3.047 seconds
[2025-06-02T22:57:38.753+0000] {processor.py:161} INFO - Started process (PID=1350) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:57:38.756+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:57:38.761+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:57:38.760+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:57:40.568+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:57:40.621+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:57:40.620+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:57:40.676+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:57:40.676+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:57:40.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.997 seconds
[2025-06-02T22:58:11.672+0000] {processor.py:161} INFO - Started process (PID=1362) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:58:11.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:58:11.683+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:58:11.682+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:58:13.049+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:58:13.095+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:58:13.095+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:58:13.160+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:58:13.160+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:58:13.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.590 seconds
[2025-06-02T22:58:43.578+0000] {processor.py:161} INFO - Started process (PID=1380) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:58:43.580+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:58:43.585+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:58:43.584+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:58:44.983+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:58:45.018+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:58:45.017+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:58:45.047+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:58:45.046+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:58:45.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.522 seconds
[2025-06-02T22:59:15.658+0000] {processor.py:161} INFO - Started process (PID=1398) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:59:15.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:59:15.664+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:59:15.663+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:59:17.383+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:59:17.435+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:59:17.433+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:59:17.480+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:59:17.480+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:59:17.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.885 seconds
[2025-06-02T22:59:48.398+0000] {processor.py:161} INFO - Started process (PID=1410) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:59:48.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T22:59:48.406+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:59:48.405+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:59:49.634+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T22:59:49.679+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:59:49.678+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T22:59:49.708+0000] {logging_mixin.py:188} INFO - [2025-06-02T22:59:49.708+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T22:59:49.740+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.367 seconds
[2025-06-02T23:00:20.099+0000] {processor.py:161} INFO - Started process (PID=1428) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:00:20.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:00:20.105+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:00:20.104+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:00:21.414+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:00:21.451+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:00:21.450+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:00:21.483+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:00:21.483+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:00:21.530+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.445 seconds
[2025-06-02T23:00:52.015+0000] {processor.py:161} INFO - Started process (PID=1440) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:00:52.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:00:52.019+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:00:52.019+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:00:53.344+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:00:53.417+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:00:53.416+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:00:53.494+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:00:53.492+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:00:53.558+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.553 seconds
[2025-06-02T23:01:24.269+0000] {processor.py:161} INFO - Started process (PID=1458) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:01:24.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:01:24.274+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:01:24.274+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:01:25.641+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:01:25.695+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:01:25.694+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:01:25.725+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:01:25.724+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:01:25.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.533 seconds
[2025-06-02T23:01:56.049+0000] {processor.py:161} INFO - Started process (PID=1470) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:01:56.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:01:56.058+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:01:56.057+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:01:57.689+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:01:57.728+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:01:57.728+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:01:57.762+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:01:57.762+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:01:57.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.769 seconds
[2025-06-02T23:02:28.122+0000] {processor.py:161} INFO - Started process (PID=1488) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:02:28.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:02:28.127+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:02:28.126+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:02:29.500+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:02:29.540+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:02:29.539+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:02:29.571+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:02:29.570+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:02:29.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.501 seconds
[2025-06-02T23:03:00.308+0000] {processor.py:161} INFO - Started process (PID=1500) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:03:00.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:03:00.314+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:03:00.314+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:03:01.319+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:03:01.354+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:03:01.353+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:03:01.382+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:03:01.382+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:03:01.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.132 seconds
[2025-06-02T23:03:32.062+0000] {processor.py:161} INFO - Started process (PID=1518) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:03:32.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:03:32.068+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:03:32.067+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:03:34.125+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:03:34.189+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:03:34.187+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:03:34.239+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:03:34.239+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:03:34.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.237 seconds
[2025-06-02T23:04:04.659+0000] {processor.py:161} INFO - Started process (PID=1530) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:04:04.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:04:04.681+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:04:04.679+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:04:05.837+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:04:05.894+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:04:05.893+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:04:05.946+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:04:05.946+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:04:06.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.394 seconds
[2025-06-02T23:04:36.820+0000] {processor.py:161} INFO - Started process (PID=1548) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:04:36.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:04:36.826+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:04:36.825+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:04:37.989+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:04:38.039+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:04:38.037+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:04:38.083+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:04:38.082+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:04:38.154+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.347 seconds
[2025-06-02T23:05:08.871+0000] {processor.py:161} INFO - Started process (PID=1560) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:05:08.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:05:08.878+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:05:08.877+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:05:09.863+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:05:09.905+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:05:09.904+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:05:09.942+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:05:09.941+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:05:09.971+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.115 seconds
[2025-06-02T23:05:40.154+0000] {processor.py:161} INFO - Started process (PID=1577) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:05:40.156+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:05:40.161+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:05:40.160+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:05:41.181+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:05:41.219+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:05:41.218+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:05:41.250+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:05:41.250+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:05:41.288+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.143 seconds
[2025-06-02T23:06:11.971+0000] {processor.py:161} INFO - Started process (PID=1589) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:06:11.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:06:11.980+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:06:11.979+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:06:13.119+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:06:13.162+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:06:13.161+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:06:13.191+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:06:13.190+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:06:13.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.281 seconds
[2025-06-02T23:06:44.498+0000] {processor.py:161} INFO - Started process (PID=1607) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:06:44.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:06:44.528+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:06:44.522+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:06:45.777+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:06:45.818+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:06:45.817+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:06:45.845+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:06:45.844+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:06:45.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.439 seconds
[2025-06-02T23:07:16.152+0000] {processor.py:161} INFO - Started process (PID=1625) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:07:16.154+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:07:16.159+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:07:16.158+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:07:17.923+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:07:17.959+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:07:17.958+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:07:18.024+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:07:18.024+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:07:18.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.926 seconds
[2025-06-02T23:07:48.704+0000] {processor.py:161} INFO - Started process (PID=1637) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:07:48.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:07:48.717+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:07:48.714+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:07:50.015+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:07:50.054+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:07:50.053+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:07:50.085+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:07:50.085+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:07:50.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.427 seconds
[2025-06-02T23:08:21.059+0000] {processor.py:161} INFO - Started process (PID=1655) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:08:21.065+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:08:21.070+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:08:21.069+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:08:22.701+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:08:22.737+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:08:22.736+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:08:22.766+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:08:22.766+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:08:22.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.784 seconds
[2025-06-02T23:08:53.498+0000] {processor.py:161} INFO - Started process (PID=1667) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:08:53.501+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:08:53.512+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:08:53.508+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:08:54.696+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:08:54.736+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:08:54.735+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:08:54.767+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:08:54.767+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:08:54.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.339 seconds
[2025-06-02T23:09:25.238+0000] {processor.py:161} INFO - Started process (PID=1685) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:09:25.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:09:25.244+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:09:25.243+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:09:26.806+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:09:26.878+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:09:26.876+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:09:26.924+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:09:26.924+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:09:26.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.748 seconds
[2025-06-02T23:09:57.753+0000] {processor.py:161} INFO - Started process (PID=1697) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:09:57.756+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:09:57.760+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:09:57.759+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:09:59.301+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:09:59.379+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:09:59.378+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:09:59.436+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:09:59.436+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:09:59.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.760 seconds
[2025-06-02T23:10:29.629+0000] {processor.py:161} INFO - Started process (PID=1715) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:10:29.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:10:29.636+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:10:29.635+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:10:30.711+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:10:30.759+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:10:30.758+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:10:30.813+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:10:30.812+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:10:30.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.251 seconds
[2025-06-02T23:11:01.500+0000] {processor.py:161} INFO - Started process (PID=1727) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:11:01.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:11:01.506+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:11:01.505+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:11:02.327+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:11:02.371+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:11:02.370+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:11:02.402+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:11:02.402+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:11:02.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.960 seconds
[2025-06-02T23:11:33.195+0000] {processor.py:161} INFO - Started process (PID=1745) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:11:33.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:11:33.200+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:11:33.200+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:11:34.571+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:11:34.628+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:11:34.626+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:11:34.668+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:11:34.667+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:11:34.733+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.552 seconds
[2025-06-02T23:12:05.542+0000] {processor.py:161} INFO - Started process (PID=1757) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:12:05.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:12:05.549+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:12:05.548+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:12:06.974+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:12:07.104+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:12:07.102+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:12:07.201+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:12:07.200+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:12:07.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.769 seconds
[2025-06-02T23:12:37.562+0000] {processor.py:161} INFO - Started process (PID=1775) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:12:37.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:12:37.581+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:12:37.579+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:12:38.679+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:12:38.723+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:12:38.723+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:12:38.752+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:12:38.752+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:12:38.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.284 seconds
[2025-06-02T23:13:09.097+0000] {processor.py:161} INFO - Started process (PID=1787) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:13:09.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:13:09.108+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:13:09.106+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:13:10.399+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:13:10.489+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:13:10.488+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:13:10.544+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:13:10.544+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:13:10.613+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.526 seconds
[2025-06-02T23:13:41.427+0000] {processor.py:161} INFO - Started process (PID=1805) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:13:41.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:13:41.437+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:13:41.435+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:13:42.338+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:13:42.384+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:13:42.383+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:13:42.414+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:13:42.414+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:13:42.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.067 seconds
[2025-06-02T23:14:13.110+0000] {processor.py:161} INFO - Started process (PID=1817) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:14:13.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:14:13.145+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:14:13.144+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:14:14.652+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:14:14.721+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:14:14.720+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:14:14.780+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:14:14.780+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:14:14.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.743 seconds
[2025-06-02T23:14:45.277+0000] {processor.py:161} INFO - Started process (PID=1835) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:14:45.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:14:45.290+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:14:45.288+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:14:46.129+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:14:46.175+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:14:46.175+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:14:46.205+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:14:46.205+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:14:46.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 0.992 seconds
[2025-06-02T23:15:17.042+0000] {processor.py:161} INFO - Started process (PID=1853) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:15:17.052+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:15:17.060+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:15:17.060+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:15:18.638+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:15:18.687+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:15:18.687+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:15:18.729+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:15:18.728+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:15:19.021+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 2.017 seconds
[2025-06-02T23:15:49.749+0000] {processor.py:161} INFO - Started process (PID=1865) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:15:49.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:15:49.755+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:15:49.754+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:15:50.598+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:15:50.638+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:15:50.638+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:15:50.857+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:15:50.857+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:15:50.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.172 seconds
[2025-06-02T23:16:21.556+0000] {processor.py:161} INFO - Started process (PID=1883) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:16:21.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:16:21.577+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:16:21.574+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:16:22.461+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:16:22.504+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:16:22.504+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-02T23:16:22.535+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:16:22.535+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-02 00:00:00+00:00, run_after=2025-06-03 00:00:00+00:00
[2025-06-02T23:16:22.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 1.073 seconds
[2025-06-02T23:16:53.444+0000] {processor.py:161} INFO - Started process (PID=1895) to work on /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-02T23:16:53.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/postgres_to_bigquery_dag.py for tasks to queue
[2025-06-02T23:16:53.492+0000] {logging_mixin.py:188} INFO - [2025-06-02T23:16:53.479+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-03T02:17:07.030+0000] {processor.py:840} INFO - DAG(s) 'postgres_to_bigquery' retrieved from /opt/airflow/dags/postgres_to_bigquery_dag.py
[2025-06-03T02:17:07.261+0000] {logging_mixin.py:188} INFO - [2025-06-03T02:17:07.259+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2025-06-03T02:17:07.489+0000] {logging_mixin.py:188} INFO - [2025-06-03T02:17:07.488+0000] {dag.py:3947} INFO - Setting next_dagrun for postgres_to_bigquery to 2025-06-03 00:00:00+00:00, run_after=2025-06-04 00:00:00+00:00
[2025-06-03T02:17:07.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/postgres_to_bigquery_dag.py took 14.806 seconds
